\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[L7x]{fontenc}
\usepackage[left=3.25cm,right=3.25cm]{geometry}
\usepackage[lithuanian]{babel}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amssymb,amsmath}
\usepackage{theorem}
\usepackage{calc}
\usepackage{color}
\usepackage{bm}
\usepackage{verbatim}
\usepackage{soul}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{makeidx}
\usepackage{float}
\usepackage{dsfont}
\usepackage{bbm}
\usepackage[toc,page]{appendix}
\usepackage{longtable}
\usepackage{lipsum}
\usepackage{tocbibind}
\usepackage{listings}
\usepackage{rotating}
\usepackage{rotfloat}
\usepackage{enumerate}
\oddsidemargin=0cm
%\topmargin=1cm
\headsep=0pt
\textwidth 6.5in
\textheight 9.00in
%\headheight=0pt
%\textwidth=440pt
%\textheight=640pt
%\footskip=40pt
\makeatletter
\renewcommand\paragraph{%
\@startsection{paragraph}{4}{0mm}%
{-\baselineskip}%
{.5\baselineskip}%
{\normalfont\normalsize\bfseries}}
\makeatother

\newcommand{\R}{{\mathbb R}}
\begin{document}

\begin{titlepage}
\vskip 20pt
\centerline{\bf \large VILNIAUS UNIVERSITETAS}
\bigskip
\centerline{\large \textbf{MATEMATIKOS IR INFORMATIKOS FAKULTETAS}}

\vskip 120pt
\centerline{\bf \Large \textbf{Magistro darbas}}
\vskip 50pt
\begin{center}
{\bf \LARGE Dviejų lygių HLM modelių vertinimo metodų palyginimas MC simuliacijų būdu: REML vs MINQUE}
\end{center}
\bigskip
\begin{center}
{\bf \Large Comparison of Two-Level HLM Estimators via MC Simulations: REML vs MINQUE}
\end{center}
\bigskip
\centerline{\Large Eglė Kaleckaitė}
\vskip 90pt
\vskip 120pt
\centerline{\large \textbf{VILNIUS 2016}}
\end{titlepage}
\begin{titlepage}

\centerline {\bf EKONOMETRINĖS ANALIZĖS KATEDRA}


\vskip 120pt
\large Darbo vadovas prof. Vydas Čekanavičius

\large Darbo recenzentas dr. Jūratė Šliogerė
\vskip 150pt

{\large Darbas apgintas \underline{ 2016 m. sausio  14   d. }}

\large Darbas įvertintas \underline{\hskip 132pt }

\vskip 120pt

{\large Registravimo NR. \underline{111000-9.1-5/\hskip 50pt }

Atidavimo į katedrą data \underline{2016-01-04\hskip 23pt} }

\end{titlepage}

\newpage
\pagestyle{plain}
\tableofcontents

\newpage

\begin{center}{\large\textbf{Dviejų lygių HLM modelių vertinimo metodų palyginimas MC simuliacijų būdu: REML vs MINQUE}}\end{center}

\begin{small}
\vspace{2\baselineskip}
\begin{center}\textbf{Santrauka}\end{center}


\vspace{\baselineskip}

\noindent\textbf{Raktiniai žodžiai:}
TIMSS, PWIGLS, HLM, MINQUE
\end{small}
\vspace{\baselineskip}
\thispagestyle{empty}

\begin{center}{\large\textbf{Comparison of Two-Level HLM Estimators via MC Simulations: REML vs MINQUE}}\end{center}

\begin{small}
\vspace{2\baselineskip}
\begin{center}\textbf{Abstract}\end{center}


\vspace{\baselineskip}

\noindent\textbf{Key words:}
TIMSS, PWIGLS, HLM, MINQUE
\end{small}
\vspace{\baselineskip}

\newpage
\section{ĮVADAS}

\indent Hierarchiniai tiesiniai modeliai (\textit{angl. Hierarchical Linear Models}) naudojami tirti tokias struktūras, kuomet vieni individai yra suskirstyti į kelias nesikertančias grupes, o šios yra dar didesnių grupių pogrupiai. Tipinis pavyzdys: mokyklų duomenys, kai mokiniai yra klasėse, o klasės mokyklose; arba organizcijos, kurių darbuotojai dirba skirtinguose padaliniuose. Šie modeliai naudojami ekonomikoje, biologijoje ir dar daug kur.

\indent HLM modeliai yra platesnės mišrių efektų modelių klasės dalis. Dažniausiai sutinkama vertinimo procedūra yra REML - apribotas didžiausio tikėtinumo metodas (\textit{angl. Restricted Maximum Likelihood}), kurio log-tikėtinumo funkcija sudaryta darnt prielaidą, jog modelio paklaidos yra iš normaliojo skirstinio. 1970-1972 metais Rao išleido straipsnių ciklą, kur pristatė naują mišrių efektų modelių vertinimo procedūrą, nereikalaujančią jokių žinių apie paklaidų pasiskirtymą, MINQUE - nepaslinktą mažiausios kvadratinės normos įvertinį (\textit{Minimum Norm Quadratic Unbiased Estimator}). 
%Tiesa, prie tam tikrų sąlygų ši procedūra yra identiška REML. 
1992 metais Bagaka's pritaikė MINQUE dviejų lygių HLM modeliams su atsitiktiniu postūmiu vertinti. Kadangi MINQUE procedūrai nebuvo apibrėžtas standartinių paklaidų skaičiavimas, Bagaka's tam panaudojo savirankos metodą (\textit{angl. bootstrap}). 2006 metais Delpish savo daktaro disertacijoje simuliacijų būdu nustatė, jog MINQUE su saviranka duoda tikslesnius rezultatus nei REML (parenmas normalumo prielaida). Vienas iš šio magistro darbo tikslų yra Monte Carlo simuliacijų būdu nustatyti, ar TIMSS duomenų struktųrai MINQUE metodas gali potencialiai duoti geresnius rezultatus.

\indent HLM neretai naudojamas ir TIMSS - tarptautinio matematikos ir gamtos mokslų tyrimo (\textit{angl. Trends in International Mathematics and Science Study}) - duomenims tirti. Šie duomenys ypatingi tuo, jog regresoriai yra indeksai, kategoriniai kintamieji bei sveikieji skaičiai (pvz.: mokinių skaičius mokykloje). Modeliams su tokiomis struktūromis normalumas dažnai negali būti garantuotas. 

\indent TIMSS imtys yra sudaromos informatyviai ir yra pateikiami imties svoriai kiekvienam lygiui. HLM su imties svoriais vertinti naudojamas PWIGLS - iteratyvus tikimybėmis pasvertas apibendrintasis mažiausių kvadratų metodas (\textit{angl. Posibility Weighted Iterative General Least Squares}), kuris kaip ir REML reikalauja paklaidų normalumo. Vertinimui dažniausiai naudojami paketai yra \textit{SAS}, \textit{SPSS}, \textit{HLM7}, \textit{MLwiN} ir k.t.. Tačiau šie paketai yra mokami ir galima legaliai gauti tik trumpalaikes apribotas versijas. Mokslinėje visuomenėje yra paplitęs nemokamas ir laisvai prieinamas statistinės analizės paketas $\R$. Nors hierarchinių modelių vertinimo su svoriais metodas nėra realizuotas, šiame darbe naudotas $\R$ statistinės analizės paketas. Tad, šio darbo tikslas yra sukurti $\R$ funkcijas skirtas dviejų lygių HLM modeliams vertinti MINQUE metodu bei realizuoti šiam metodui svėrimą tikimybėmis. Galiausiai, sudaryti dviejų lygių hierarchinį tiesinį modelį TIMSS duomenims ir jį įvertinti tirtais metodais.


\indent Šis magistro darbo struktūra išvardinta žemiau:
\begin{itemize}
\item \ref{sec:hlm} skyriuje aprašoma hierarchinių tiesinių modelių teorija.
\item \ref{sec:vert} skyrius skirtas hierarchinių tiesinių modelių parametrų vertinimo metodams. Aptariamas MINQUE metodas ir jo realizacija $\R$ aplinkoje.
\item \ref{sec:simul} skyrius skiriamas empirinėms parametrų vertinimo skirtingais metodais simuliacijoms.
\item \ref{sec:timss} skyriuje aprašomas TIMSS tyrimas, sudaromas bei įvertinamas modelis Lietuvos TIMSS duomenims atsižvelgiant į \ref{sec:simul} skyriaus rezultatus.
\item Pagrindiniai šio magistro darbo rezultatai dar kartą trumpai aptariami išvadose.
\end{itemize}

\newpage
\section{HIERARCHINIAI TIESINIAI MODELIAI} \label{sec:hlm}
\indent Šiame skyriuje pateikiamas HLM aprašymas, trumpai apžvelgiamos modelio parinkimo statistikos bei indeksai.

\subsection{Hierarchinio tiesinio modelio aprašymas}
\indent Hierarchinis tiesinis modelis (toliau HLM) - metodas, kuris atsižvelgia į hierarchinę duomenų struktūrą ir galimą paklaidų heteroskedastiškumą. Literatūroje šis modelis dar vadinamas atsitiktinių efektų arba kovariacijų (dispersijos) komponenčių modeliu ir yra apibendrintų mišrių tiesinių modelių klasės dalis\cite{hlmmixed}.

\indent HLM modeliai gali būti 2 ir daugiau lygių, tačiau kuo daugiau lygių, tuo vertinimo specifikacija ir vertinimo procedūra sudėtingesnė. Nors TIMSS (plačiau \ref{subsec:timss1} skyrelyje) pateikia duomenis šalių, mokyklų, klasių (mokytojų) bei mokinių lygiuose, šiame darbe bus nagrinėjami tik dviejų (mokyklos ir mokinių) lygių HLM modeliai. Plačiau apie HLM modelius galima rasti Čekanavičiaus ir Murausko statistikos vadovėlyje \cite{cek}.

\indent Sakykime, jog turime $J$ mokyklų, kuriose mokosi po $n_j$, $j = 1,\dots,J$ mokinių. Tuomet dviejų lygių modelio pavidalas:

\begin{equation} \label{eq:2lvl}
\left\{
\begin{array}{l}
Y_{ij} = \beta_{0j}+\sum^P_{p = 1} \beta_{pj}\times X_{pij}+\varepsilon_{ij}; \\
\beta_{pj} = \gamma_{p0} + \sum^{Q_p}_{q=1}\gamma_{pq}\times W_{pqj}+u_{pj};\ \forall p = 0 , \dots, P,
\end{array} \right.
\end{equation}
kur\\
$j$ - j-otoji mokykla;\\
$ij$ - i-tasis mokinys j-tojoje mokykloje;\\
$\beta_{0j}$ - atsitiktinis postūmis;\\
$\beta_{pj}$ - atsitiktinis posvyris;\\
$\gamma_{pq}$ - fiksuoti efektai;\\
$X_{pij}$ - mokinio lygio kintamieji;\\
$W_{pqj}$ - mokyklos lygio kintamieji;\\
$Y_{ij}$ - aiškinamasis kintamasis - mokinio matematinio raštingumo rezultatas.\\

\indent Įstačius antrą modelio (\ref{eq:2lvl}) lygtį į pirmąją, gaunama jungtinė lygtis:
\begin{equation} \label{eq:2lvljung}
Y_{ij} =\sum^P_{p = 0} \sum^{Q_p}_{q=0}\gamma_{pq}\times X_{pij}\times W_{pqj}+\sum^P_{p = 0} X_{pij}\times u_{pj}+\epsilon_{ij}.
\end{equation}

Tegu turime $N$ mokinių, kurie yra natūraliai suskaidyti į $J$ mokyklų ir $\sum^J_{j=1} n_j = N$. Tuomet (\ref{eq:2lvl}) modelį galime užrašyti
\begin{equation}
\mathbf{Y}_j=\mathbf{Z}_j\boldsymbol{\beta}_j+\boldsymbol{\varepsilon}_j;
\end{equation}
\begin{equation}
\boldsymbol{\beta}_{j}=\mathbf{W}_{j}\boldsymbol{\gamma}_{j}+\mathbf{u}_{j},
\end{equation}
čia
\[
\mathbf{Y}_{j} =
\begin{pmatrix}
Y_{1j} \\
Y_{2j} \\
\vdots \\
Y_{n_jj}
\end{pmatrix};
\mathbf{Z}_{j} =
\begin{pmatrix}
1 & X_{11j} & \cdots & X_{P1j} \\
1 & X_{12j} & \cdots & X_{P2j} \\
\vdots & \vdots & \ddots & \vdots \\
1 & X_{1n_jj} & \cdots & X_{Pn_jj}
\end{pmatrix};
\boldsymbol{\beta}_{j} =
\begin{pmatrix}
\beta_{0j} \\
\beta_{1j} \\
\vdots \\
\beta_{Pj}
\end{pmatrix};
\boldsymbol{\varepsilon}_{j} =
\begin{pmatrix}
\varepsilon_{1j} \\
\varepsilon_{2j} \\
\vdots \\
\varepsilon_{n_jj}
\end{pmatrix};
\]
\[
\mathbf{W}_{j} =
\begin{pmatrix}
1& W_{1j} & \cdots & W_{Q_Pj} & 0 & 0 & \cdots & 0 & \cdots & 0\\
0 &0 & \cdots & 0 &1 & W_{1j} & \cdots & W_{Q_Pj} & \cdots &0\\
\vdots & \vdots & \ddots & \vdots & \vdots & \vdots & \ddots & \vdots & \ddots & \vdots\\
0 &0 & \cdots & 0 & 0& 0&\cdots & 0& \cdots & 0
\end{pmatrix};
\boldsymbol{\gamma}=
\begin{pmatrix}
\gamma_{00} \\
\vdots\\
\gamma_{0Q_0} \\
\gamma_{10}\\
\vdots\\
\gamma_{1Q_1} \\
\vdots \\
\gamma_{PQ_P}
\end{pmatrix};
\mathbf{u}_{j} =
\begin{pmatrix}
u_{0j} \\
u_{1j} \\
\vdots \\
u_{Pj}
\end{pmatrix}.
\]
Tegu $X_{ij}=Z_{ij}\mathbf{W}_j$ ir $\mathbf{X}_j = (X'_{1j}, \cdots, X'_{n_jj})'$, tada matricinis bendrojo HLM modelio pavidalas yra
\begin{equation} \label{eq:bendrasHLM}
\mathbf{Y}=\mathbf{X}\boldsymbol{\gamma}+\mathbf{Z}\mathbf{u}+\boldsymbol{\varepsilon},
\end{equation}
kur
\[
\mathbf{Z}=
\begin{pmatrix}
\mathbf{Z}_1 & 0 & \cdots & 0 \\
0 & \mathbf{Z}_2 & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots \\
0&0 & \cdots & \mathbf{Z}_J
\end{pmatrix}.
\]

\noindent Modelio prielaidos:
\begin{itemize}
\item $\varepsilon_{ij} \sim \mathcal{N}(0, \sigma^2\mathbf{I}_{n_j})$;
\item $\mathbb{C}ov(X_{ij},\varepsilon_{ij})=0, \forall i$;
\item $\mathbb{C}ov(\boldsymbol{\varepsilon}_j,\boldsymbol{\varepsilon}_j')=0, \forall j\neq j'$;
\item $\mathbf{u}_j = (u_{0j}, u_{1j}, \dots, u_{Pj})' \overset{iid}{\sim} \mathcal{N}(0,T)$;
\item $\mathbb{C}ov(\mathbf{W}_{j}, \mathbf{u}_j)=0$;
\item $\mathbb{C}ov(\boldsymbol{\varepsilon}_j, \mathbf{u}_j)=0$;
\item $\mathbb{C}ov(\mathbf{X}_j, \mathbf{u}_j)=0$;
\item $\mathbb{C}ov(\mathbf{W}_j, \boldsymbol{\varepsilon}_j)=0$.
\end{itemize}
Visos modelio paklaidos $u_{ij}$, $\varepsilon_{ij}$ yra nepriklausomos ir vienodai pasiskirstę pagal normalųjį skirtstinį, t.y.
\[\mathbb{E}\begin{pmatrix}
\mathbf{u} \\
\boldsymbol{\varepsilon}
\end{pmatrix}=
\begin{pmatrix}
\mathbf{0} \\
\mathbf{0}
\end{pmatrix};
\mathbb{C}ov\begin{pmatrix}
\mathbf{u} \\
\boldsymbol{\varepsilon}
\end{pmatrix}=
\begin{pmatrix}
\mathbf{\Sigma}&\mathbf{0} \\
\mathbf{0}&\mathbf{R}
\end{pmatrix},
\mathbf{\Sigma}=
\begin{pmatrix}
\mathbf{T} & 0 & \cdots & 0 \\
0 & \mathbf{T} & \cdots & 0\\
\vdots & \vdots & \ddots & \vdots \\
0&0 & \cdots & \mathbf{T}
\end{pmatrix},
\]
kur $\mathbf{R}$ vektoriaus $\boldsymbol{\varepsilon}$ kovariacijų matrica, dažniausiai $\mathbf{R}=\sigma^2\mathbf{I}$. Nesunkiai galima parodyti, jog $\mathbb{E}(\mathbf{Y})=\mathbf{X}\boldsymbol{\gamma}$ ir
\begin{equation} \label{eq:var}
\mathbb{V}ar(\mathbf{Y})=\mathbf{V}=\mathbf{Z\Sigma Z}'+\mathbf{R}
\end{equation}
arba
\begin{equation} \label{eq:varj}
\mathbb{V}ar(\mathbf{Y_j})=\mathbf{V_j}=\mathbf{Z_jTZ_j}'+\mathbf{R_j}
\end{equation}


\subsection{Modelio parinkimas} \label{subsec:parink}
\indent Hierarchinių tiesinių modelių sudarymas yra sudėtinga procedūra ir tai galima padaryti įvairiais būdais bei gauti labai skirtingus rezultatus.

\indent Pradžioje visuomet skaičiuojamas nulinis (besąlyginis) modelis:

\begin{equation}\label{eq:null}
\left\{
\begin{array}{l}
Y_{ij}=\beta_{0j}+\varepsilon_{ij}, \ \varepsilon_{ij}\sim \mathcal{N}(0, \sigma^2);\\
\beta_{0j}=\gamma_{00}+u_{0j}, \ u_{0j}\sim \mathcal{N}(0, \tau_{00}).
\end{array} \right.
\end{equation}
\indent Gavus (\ref{eq:null}) įverčius $\hat{\gamma}_{00}, \ \hat{\sigma}^2,\ \hat{\tau_{00}}$, nustatoma, ar turima hierarchinė struktūra, ar visgi užtenka paprasto tiesinio modelio. Tikrinama hipotezė, ar gautas įvertis nelygus 0. Taip pat, kiek bendrą skirtumą paaiškina individų, o kiek grupių skirtumai - skaičiuojamas \hyperlink{icc}{ICC} koeficientas. Toliau toks modelis naudojamas sudėtingesnių modelių parinkime kaip atspirties taškas - skaičiuojamos \hyperlink{r2}{$R^2$} statistikos. (Remiamasi \cite{cek})

\subparagraph{ICC} \hypertarget{icc} - tarpklasinės koreliacijos koeficientas (\textit{angl. Intraclass Correlation Coefficient}), kuris parodo grupių rezultatų ir rezultatų grupėse skirtumą \cite{cek}. Dar gali būti interpretuojamas kaip dviejų individų toje pačioje grupėje rezultatų koreliaciją. Šis koeficientas skaičiuojamas taip:
\begin{equation}\label{eq:icc}
ICC = \frac{\tau_{00}}{\sigma^2+\tau_{00}}.
\end{equation}
Shackman savo 2001 metų darbe\cite{icc} pabrėžė: kuo mažesnis ICC koeficientas, tuo patikimesni bus modelio įverčiai. Tačiau, pasak jo, ICC nėra toks svarbus daugialygiuose modeliuose kaip DEFF - dizaino efektas (\textit{ang. Design Effect}), kuris parodo kiek efektyvumo prarandama renkant imtis iš lizdų, o ne visiškai atsitiktinai parenkant individus. Šio koeficiento ryšys su ICC:
\begin{equation}
DEFF \approx 1 + (n - 1) \times ICC,
\end{equation}
kur $n$ yra vidutinis imties grupės dydis. Simuliacijų būdu, buvo nustatyta, jog kol $DEFF <2$, tol modeliavimas viename lygmenyje nėra blogiau nei dviejuose.

\subparagraph{Statistika $\mathbf{R^2}$} \hypertarget{r2} dažnai naudojama ir vieno, ir kelių lygių modeliuose. Ji naudojama nustatyti ar įtrauktas kintamasis (įtraukti kintamieji) pagerina modeliuojamo kintamojo įverčio tikslumą. Hierarchiniuose modeliuose skaičiuojami atskiri $R^2$ kiekvienam lygiui. Pavyzdžiui, įtraukus pirmo lygio kintamąjį, imamas santykinis skirtumas $\frac{\hat{\sigma}^2_{(nul)}-\hat{\sigma}^2_1}{\hat{\sigma}^2_{(nul)}}$ ($\hat{\sigma}^2_{(nul)}$ - besąlyginio modelio, $\hat{\sigma}^2_1$ - sąlyginio modelio) ir žiūrima, kiek skirtumo buvo paaiškinta. Įtraukus antro lygio kintamąjį analogiškai skaičiuojama $\frac{\hat{\tau}_{00(nul)}-\hat{\tau}_{00}}{\hat{\tau}_{00(nul)}}$. Šie koeficientai dar vadinami pirmo ir antro lygio $R^2$.

\indent Daugialygiuose modeliuose naudojamos ir kitokios aiškinamojo kintamojo įverčio tikslumo statistikos. Apie jas daugiau galima rasti 2008 metų Orien ir Edwards\cite{fixedTest} straipsnyje. Autoriai simuliacijų būdu nustatė geriausią fiksuotų efektų įtraukimo į modelį (arba atitikimo \textit{angl. goodness-of-fit}) matą, kurį pavadino $R^2_1$. Šią statistiką sukūrė Vonesh ir Chinchilli\cite{Rtest}. Ji atrodo taip:
\begin{equation} \label{eq:r2}
R^2_1=1-\dfrac{\sum^J_{j=1}\left(Y_{j}-\hat{Y}_{j}\right)'\left(Y_{j}-\hat{Y}_{j}\right)}{\sum^J_{j=1}\left(Y_{j}-\bar{Y}\times\mathbbm{1}_{n_j}\right)'\left(Y_{j}-\bar{Y}\times\mathbbm{1}_{n_j}\right)},
\end{equation}
čia $Y_j$ yra $n_j\times1$ vektorius su j-tosios grupės stebėjimais, $\bar{Y}$ - bendras visų stebėjimų vidurkis, $\hat{Y}_j=X_j\hat{\beta}+Z_j\hat{u}_j$, o $\mathbbm{1}_{n_j}$ - vienetukų stulpelis.

\subparagraph{Informaciniai indeksai.} Kaip jau buvo minėta, modelio parinkimas susideda iš dviejų modelių palyginimo (t.y. imamas paprastesnis ir sudėtingesnis modeliai), tam yra sukurti informaciniai indeksai, kurie paremti didžiausio tikėtinumo f-jos logaritmo maksimumu $l$. Daugiau apie juos Čekanavičiaus ir Murausko statistikos vadovėlyje \cite{cek}. Šiame magistro darbe remiamasi $AIC=-2l+2d$ kriterijumi, kur $d$ - atsitiktinio poveikio parametrų modelyje skaičius. Čia verta paminėti, jog informaciniai indeksai gali būti skaičiuojami tik vertinant \hyperlink{reml}{ML} metodu.

\newpage
\section{PARAMETRŲ VERTINIMO METODAI} \label{sec:vert}
\indent Praktikoje populiariausias hierarchinių tiesinių modelių parametrų vertinimo metodas -- REML -- apribotasis didžiausio tikėtinumo (\textit{angl. Restricted Maximum Likelihood}). Dažniausiai daroma prielaida, jog modelio paklaidos normaliai pasiskirstę, ir tuo remiantis gaunama log-tikėtinumo funkcija. Toliau REML su log-tikėtinumo funkcija normaliosioms paklaidoms vadinsime tiesiog REML. 

\indent Alternatyvus metodas MINQUE -- mažiausios kvadratinės normos nepaslinktas įvertinys (\textit{Minimum Quadratic Norm Unbiased Estimator}). Šis metodas nereikalauja žinių apie turimų duomenų pasiskirstymą ir yra nepaslinktas. Tačiau priklausomas nuo \textit{a priori} reikšmių. Išskiriami MINQUE(0), MINQUE(1) ir MINQUE($\theta$). Jei MINQUE($\theta$), $\theta$ apytiksliai atitinka tikrųjų parametrų reikšmių santykius, tai gauti įverčiai yra BLUE (???).

\indent Šiame skyrelyje pateikta vertinimo metodų literatūros apžvalga, aprašyti patys metodai ir pateiktas sukurtų funkcijų aprašymas.


???? Literatūroje nurodoma (Delphish 2006 \cite{delpish}), jog šis metodas duomenims, kurie netenkina normalumo prielaidos, duoda tikslesnius parametrų (dispersijos komponenčių) įverčius. Po ilgų paieškų $\R$ statistinės analizės programoje nepavyko rasti norimo MINQUE metodo hierarchiniams tiesiniams modeliams vertinti. Paketo \textit{varComp} funkcija \textit{minque} vertina tik centruotą aiškinamąjį kintamąjį. Paketo \textit{maanova} funkcija \textit{fitmaanova} vertina tik ANOVA mikro vektoriams. Paketas \textit{minque} pritaikytas labai mažoms imtims. Paketo \textit{CLME} funkcija \textit{minque} taikoma tik specininėms to paketo struktūroms. Paketo \textit{dmm} funcija \textit{minque} skirta  tik diadinio modelio lygtims (\textit{angl. dyadic model}). O Demidenko knygos \cite{mixedR} priede pateikta funkcija\\ \textit{lmevarMINQUE} vertina tik labai atskirą atvejį ir negalima pasirinkti \textit{a priori} reikšmių. Dėl šios priežasties žemiau aprašytas MINQUE vertinimo metodas buvo realizuotas $\R$ aplinkoje pačios šio magistro darbo autorės.

\subsection{Literatūros apžvalga}

\indent 1975 metais Horn ir kt. savo straipsnyje \cite{AUE} pristatė \textit{Beveik nepaslinktą įvertinį} (\textit{angl. Almost Unbiased Estimator - AUE}). Šis įvertinys nuo MINQUE skiriasi labai nedaug, bet užtikrina įverčių neneigiamumą. Nepaslinktumas užtikrinimas tik tuo atveju, jei \textit{a priori} reikšmės yra proporcingos tikrosioms reikšmėms. Išpildyti šią sąlygą beveik neįmanoma, tačiau autoriai teigia jog paslinktumas bus labai mažas. Iš čia ir kilo metodo pavadinimas. AUE linkęs duoti dispersijų įverčius, kurie yra kažkur tarp tikrosios reikšmės ir jų vidurkio, t.y. mažas reikšmes pervertina, o dideles nuvertina.

\indent Jei naudosime I-MINQUE dažniausiai prarasime nepaslinktumo savybę. Lucas straipsyje \cite{IAUE} pristato IAUE - iteratyvų AUE. Konvergavimo greitis priklauso nuo pradinių reikšmių, tačiau užtenka kelių iteracijų geriems rezultatams pasiekti. Šis metodas duos neneigiamus įverčius ir yra lengvai naudojamas su diagonalinėmis matricomis.

\indent Leithy ir k.t. straipsnyje \textit{On non-negative estimation of variance components in mixed linear models} \cite{MMINQUE} aptaria  modifikuotus MINQUE, IAUE ir REML metodus (MMINQUE, MIAUE ir MREML). Dispersijos komponenčių įverčiai apskaičiuoti straipsnyje aprašytu EM (lūkesčių minimizavimo --  \textit{angl. Expectation-Minimizaton}) algoritmu vadinamas MREML. Subramani \cite{MMIVQUE} pasiūlė vertinti dispersijos komponentes ne iš tiesinės kombinacijos, o naudoti lygčių sistemą (plačiau \cite{MMINQUE}). Kadangi sprendinys nėra vienintelis, Subramani pasiūlė du metodus -- MMINQUE1 ir MMINQUE2. Leithy ir k.t. pasinaudodami Subramani idėja išvedė MIAUE1 ir MIAUE2. Autoriai naudodami simuliacijas parodė, jog MINQUE, MMINQUE1 ir MMINQUE2 nesiskiria esant subalansuotam imties dizainui. REML yra geriausias mažiausio poslinkio prasme, o MREML vidutinės kvadratinės paklaidos (MSE) prasme. MINQUE, MMINQUE1 ir MMINQUE2 yra geresni mažesnio paslinktumo prasme nei IAUE, MIAUE1 ir MIAUE2 nesvarbu imties dydis ir nebalansuotumo laispsnis. Ir atvirkščiai, IAUE, MIAUE1 ir MIAUE2 geresn mažesniųi MSE prasme. IAUE visais atvejais labiau paslinktas nei MIAUE1 ar MIAUE2, bet turi mažesnes MSE nei MINQUE, MMINQUE1 ar MMINQUE. MMINQUE2 įverčiai dažniausiai buvo neigiami, kai REML neigiamų įverčių buvo mažiausiai. Svarbu, jog imties dydis turėjo stiprią įtaką mažinant gaunamus neigiamus įverčius. Grafiniu būdu buvo parodyta, jog MREML yra geriausias metodas iš visų. MMINQUE1 ir MINQUE įverčiai skiriasi labai nedaug, todėl naudosiu MINQUE. (Deja per vėlai pastebėjau šitą straipsnį ir sudėtinga realizuoti )

Savo diseraticoje \textit{Estimation of Genetic Variance Components in the General Mixed Model}\cite{zhu} Zhu Monte Carlo simuliacijų būdu palygino HEND3 (\textit{Henderono trečiasis metodas}), ML, REML, MINQUE(1) ir MINQUE($\theta$) metodų galią genetinėms dispersijos komponentėms vertinti. Kuomet duomenų dizainas subalansuotas, HEND3 metodo galia sutapo su likusiais metodais. Nesubalansuoto dizaino atveju REML, MINQUE(1) ir MINQUE($\theta$) galia skyrėsi. Kuomet dispersijos komponentės nenulinės visi trys metodai gali duoti nepalinktus įverčius su panašia galia. Kai yra nulinių komponenčių, MINQUE(1) ir MINQUE($\theta$) gali duoti įverčius panašius į tikrąją reikšmę, tačiau REML visuomet pervertina. Tad autorius siūlo MINQUE(1) ir MINQUE($\theta$) kaip tinkamus dispersijos - kovariacijos komponenčių vertinumui.


\indent MINQUE procedūra neužtikrina neneigiamų kovariacijos komponenčių įverčių. Vienas būdas - visiems neigiamiems įverčiams priskirti reikšmę 0. Kitas būdas, naudoti saviranką (Bagaka's \cite{bagaka}).


\subsection{Efektų vertinimas}
\indent Fiksuoti efektai dažniausiai vertinami taikant apibendrintąjį mažiausių kvadratų metodą (GLS):
\begin{equation}\label{eq:gamma}
\boldsymbol{\hat{\gamma}}=\mathbf{\left(X'V^{-1}X\right)^{-1}X'V^{-1}Y}.
\end{equation}

Taip pat ir atsitiktinio poveikio parametrų įverčiai:
\begin{equation} \label{eq:beta}
\boldsymbol{\hat{\beta}}_j=\left(\mathbf{Z}_j'\mathbf{R}^{-1}_j\mathbf{Z}_j\right)^{-1}\mathbf{Z}_j'\mathbf{R}^{-1}_j\mathbf{Y}_j;\ \mathbf{R}_j=\sigma^2\mathbf{I}.
\end{equation}

Atsitiktinės paklaidos $\mathbf{u}_j$ įvertis gaunamas (pagal \cite{EBi}) taip:
% į $\boldsymbol{\beta}_j=\mathbf{W}_j\boldsymbol{\gamma}+\mathbf{u}_j$ įstačius $\boldsymbol{\gamma}$ ir $\boldsymbol{\beta}_j$ įverčių išraiškas iš (\ref{eq:gamma}) ir (\ref{eq:beta}):
\begin{equation}
\mathbf{\hat{u}}_j=\mathbf{TZ}'_j\mathbf{\hat{V}^{-1}}_j\left(\mathbf{Y}_j-\mathbf{X}_j\boldsymbol{\hat{\gamma}}\right).
\end{equation}

$\boldsymbol{\beta}_j$ įvertinys (\ref{eq:beta}) turės didelę dispersiją, kai j-toji grupė maža, todėl įvertis gali būti visai nepanašus į tikrąją reikšmę. Dėl šios priežasties praktikoje dažnai naudojamas empirinis Bajaso įvertinys (EBS) dar vadinamas sutraukiančiuoju (\textit{angl. shrinkage}) įvertiniu (pagal \cite{shrinkage}):
\begin{equation}
\boldsymbol{\hat{\beta}}^*_{j}=\boldsymbol{\Theta}_j\boldsymbol{\hat{\beta}}_j+(\boldsymbol{I} - \boldsymbol{\Theta}_j)\mathbf{W}_j\boldsymbol{\hat{\gamma}},
\end{equation}
čia $\mathbf{\Theta}_j=T\left(T+\sigma^2(\mathbf{Z}'_j\mathbf{Z}_j)^{-1}\right)$. Visi aukščiau minimi įvertiniai remiasi tuo, jog $T$ ir $\sigma^2$ yra žinomi, tačiau praktikoje juos reikia įsivertinti. Dispersijos komponentėms vertinti yra ne vienas metodas, \hyperlink{reml}{žemiau} išvardinti keli iš jų.

\indent Dar skaičiuojamos ir standartinės paklaidos, kurios gaunamos iš $(\mathbb{C}ov(\boldsymbol{\hat{\gamma}}))^{\frac{1}{2}}$ ir $(\mathbb{C}ov(\mathbf{\hat{u}}_j))^{\frac{1}{2}}$:
\begin{equation}
\mathbb{C}ov(\boldsymbol{\hat{\gamma}})=\mathbf{(X'\hat{V}^{-1}X)^{-1}}
\end{equation}
arba sumuštinio principo įvertinys (pagal \cite{sandwich}):
\begin{equation}
\mathbb{C}ov(\boldsymbol{\hat{\gamma}})=\mathbf{(X'\hat{V}^{-1}X)^{-1}}\frac{N}{N-1}\left(\sum^J_{j=1}\mathbf{X}_j\mathbf{\hat{V}}^{-1}_j\mathbf{\hat{e}}_j\mathbf{\hat{e}}'_j \mathbf{\hat{V}}^{-1}_j\mathbf{X}'_j\right)\mathbf{(X'\hat{V}^{-1}X)^{-1}},
\end{equation}
kur $\mathbf{\hat{e}}_j=\mathbf{Y}_j-\mathbf{X}_j\boldsymbol{\hat{\gamma}}$, o $\mathbb{C}ov(\mathbf{\hat{u}}_j)$ gaunama taip:
\begin{equation}
\mathbb{C}ov(\mathbf{\hat{u}}_j)=\left(\sum^{n_j}_{i=1}\mathbf{Z}'_j\mathbf{\hat{V}}^{-1}_j\right) \left[\mathbf{V}_j-\mathbf{X}_j\mathbb{C}ov(\boldsymbol{\hat{\gamma}})\mathbf{X}_j\right]^{-1} \left(\sum^{n_j}_{i=1}\mathbf{Z}'_j\mathbf{\hat{V}}^{-1}_j\right)'.
\end{equation}

\indent Turint aukščiau išvardintus įverčius, galima gauti aiškinamojo kintamojo įvertį $\mathbf{\hat{Y}}=\mathbf{X}\boldsymbol{\hat{\gamma}}+\mathbf{Z\hat{u}}$ bei liekanas $\boldsymbol{\hat{\varepsilon}}=\mathbf{Y}-\mathbf{\hat{Y}}$.

\subsection{REML metodas}
\hypertarget{reml}
\indent Didžiausio tikėtinumo metodas -- ML (\textit{angl. Maximum Likelihood}) \cite{ml} -- vienas dažniausiai naudojamų metodų vertinti HLM modelius. Čia daroma prielaida jog modelio paklaidos yra pasiskirsčiusios pagal normalųjį skirstinį. Tuomet modelio (\ref{eq:bendrasHLM}) j-tosios grupės su dispersijų matrica (\ref{eq:varj}) didžiausio tikėtinumo f-jos logaritmas:
\begin{equation}
L_j(\sigma^2, \mathbf{T}, \boldsymbol{\gamma}) = -\frac{n_j}{2}\log(2\pi)-\frac{1}{2}\log|\mathbf{V} _j | -\frac{1}{2}(\mathbf{Y}_j-\mathbf{X}_j\boldsymbol{\gamma})'\mathbf{V}^{ -1}_j(\mathbf{Y}_j-\mathbf{X}_j\boldsymbol{\gamma})
\end{equation}
\indent Viso modelio log-tikėtinumas gali būti užrašytas kaip atskirų grupių suma $L(\sigma^2, \mathbf{T}, \boldsymbol{\gamma})=\sum^J_{j=1}L_j(\sigma^2, \mathbf{T}, \boldsymbol{\gamma})$. Taip pat naudojamas ir apribotasis didžiausio tikėtinumo metodas -- REML (\textit{angl. Restricted Maximum Likelihood}), kuris nuo ML skiriasi tuo, jog atskiria fiksuotų efektų dalį ir optimizuoja tik atsitiktinių efektų dalį:
\begin{equation}
L^R_j(\sigma^2, \mathbf{T}, \boldsymbol{\gamma}) = L_j(\sigma^2, \mathbf{T}, \boldsymbol{\gamma}) -\frac{1}{2}\log|\mathbf{X}_j'\mathbf{V}^{-1}_j\mathbf{X}_j|
\end{equation}

\indent Nors šios procedūros dažnai naudojamos vertinant HLM modelius, jos visgi reikalauja normalumo prielaidos, kuri negali būti garantuota, kai turime daug kategorinių aiškinančiųjų kintamųjų.

%\subsubsection{PWIGLS}
\subsection{MINQUE metodas}\label{subsec:minque}

\indent Savo straipsnių serijoje (1970\cite{rao1970}, 1971a\cite{rao1971a} , 1971b\cite{rao1971b} , 1972\cite{rao1972}) Rao pristatė dispersijos - kovariacijos matricų mišriuose tiesiniuose modeliuose vertinimo procedūrą, kurią pavadino mažiausios kvadratinės normos nepaslinktu įvertiniu - MINQUE (\textit{angl. Minimum Norm Quadratic Unbiased Estimator}). Šis įvertinys išskirtinis tuo, jog yra nepaslinktas, invariantiškas ir nereikalauja normalumo prielaidos ar žinių apie paklaidų ar atsitiktinių efektų pasiskirstymą. Tačiau įvertis priklauso nuo \textit{a priori} reikšmių ir keli žmonės turėdami tuos pačius duomenis, bet skirtingas pradines reikšmes gali gauti visiškai skirtingus parametrų įverčius ir visi jie bus mažiausi kvadratinės normos nepaslinkti įverčiai, tačiau tik prie pasirinktų \textit{a priori} reikšmių. Rao MINQUE procedūra bei jos pritaikymas HLM bus trumpai aprašyti šiame skyrelyje. Daugiau informacijos galima rasti minėtoje Rao straipsnių serijoje (\cite{rao1970}, \cite{rao1971a} , \cite{rao1971b} , \cite{rao1972}).

\indent Rao teorija remiasi Euklidinės normos minimizavimu. Pagal Rao, turime modelį $\mathbf{Y}=\mathbf{X}\boldsymbol{\gamma}+\mathbf{e}$, kur $\mathbf{e}=\mathbf{H\boldsymbol{\xi}}=\mathbf{\boldsymbol{H_1\xi_1+\cdots +H_k \xi_k}}$, $\boldsymbol{\xi_i}$-atsitiktiniai vektoriai, $\mathbf{H_i}$-lydinčiosios matricos. Imama kvadratinė forma $\mathbf{Y'AY}$ ir sakoma, kad ji yra mažiausias tiesinės f-jos $\sum^l_{r=1} g_r\theta_r$ (čia $\theta_r$ - dispersijos komponentės, o $g_r$ - lydintysis parametras) įvertinys su sąlygomis:
\begin{enumerate}
\item $\mathbf{AX=0}$ - invariantiškumas;
\item $\mathbb{E}\left(\mathbf{Y'AY}\right)=\sum^l_{r=1} g_r\theta_r$ - nepaslinktumas;
\item $\mathbb{V}ar\left(\mathbf{Y'AY}\right)=min$ pagal $\theta_1, \dots, \theta_l$.
\end{enumerate}

\indent Jei žinotume visus $\xi_i$, tai natūralus $\sum^l_{r=1} g_r\theta_r$ įvertinys būtų $\boldsymbol{\xi'R\xi}$, kur $\mathbf{R}$ - $k\times k$ matrica. Iš kitos pusės, pagal invariantiškumą, $\mathbf{Y'AY=\boldsymbol{\xi'H'AH'\xi}}$. Skirtumas tarp šių dviejų įvertinių yra $\boldsymbol{\xi'\left(H'AH-R\right)\xi}$. Norima gauti šį skirtumą kuo mažesnį, tam sudaroma Euklidinė norma $\|\boldsymbol{H'AH-R}\|^2$ ir ji yra minimizuojama.

\indent Tuomet tiesinės kombinacijos $g_1 \theta_1+\dots+g_l \theta_l$ MINQUE yra $\mathbf{Y'AY}$, jei matrica $\mathbf{A}$ gaunama išsprendus:
\[tr(\mathbf{AVAV}) \to min \ s.a. \ \mathbf{AX} = 0;\ tr(\mathbf{AQ}_r)=g_r\]
\indent Tada $\hat{\theta} = (\hat{\theta_1},\dots,\hat{\theta_l})'=S^{-1}q$, kur $S=\{s_{ij}\}$, $s_{ij}=tr(\mathbf{CQ}_i\mathbf{CQ}_j)$, o
$q=\{q_i\}$,

\noindent $q_i=\mathbf{Y'CQ}_i\mathbf{CY}$, $\mathbf{C} = \mathbf{\hat{V}}^{-1}\left(\mathbf{I}-\mathbf{X}\left(\mathbf{X' \hat{V}}^{-1}\mathbf{X}\right)^{-1}\mathbf{X \hat{V}}^{-1}\right)$, $\mathbf{\hat{V}}=\sum^l_{r=1}\alpha_r\mathbf{Q}_r$, $\alpha_r$ - \textit{a priori} reikšmės (gaunamos iš išorės, pvz.: tvirtai žinant apytiksles dispersijos komponenčių proporcijas). Fiksuotų parametrų įverčiai gaunami pagal GLS\cite{rao1972}:
\[\boldsymbol{\hat{\gamma}}=\mathbf{\left(X'\hat{V}^{-1}X\right)^{-1}}\mathbf{X'\hat{V}^{-1}Y}.\]

\subparagraph{I-MINQUE metodas}\hypertarget{iminque}yra iteratyvi MINQUE procedūra, kuri yra nejautri \textit{a priori} reikšmėms. Pavyzdžiui, paimkime $\alpha_0=\dots=\alpha_l=1$. Gauname $\mathbf{\hat{V}}_{(0)}=\sum^l_{r=0}\mathbf{Q}_r$, įsivertiname pagal MINQUE metodą $\boldsymbol{\hat{\theta}}_{(0)}=(\hat{\theta}_0,\hat{\theta}_1,\dots,\hat{\theta}_l)'_{(0)}$. Su naujomis $\theta$ reikšmėmis gaunamas $\mathbf{\hat{V}}_{(1)}$, o su juo įsivertiname $\boldsymbol{\hat{\theta}}_{(1)}=(\hat{\theta}_0,\hat{\theta}_1,\dots,\hat{\theta}_l)'_{(1)}$.  Šioje vietoje procedūrą galime nutraukti arba tęsti tol, kol $|\boldsymbol{\hat{\theta}}_{(i)}-\boldsymbol{\hat{\theta}}_{(i+1)}|<\delta$, kur $\delta$ yra pasirinktas konvergavimo tolerancijos parametras.

\subsubsection{MINQUE literatūros apžvalga????}



\indent ??? Delpish\cite{delpish} savo darbe naudoja tik du pirmuosius I-MINQUE žingsnius. Toks metodas bus naudojamas ir šiame darbe.  Skyriaus pradžioje buvo minėta, jog $\R$ statistinės analizės programoje nepavyko rasti reikiamos funkcijos minėtam metodui vertinti, todėl reikiamos funkcijos buvo parašytos pačios autorės. Kodas pateiktas šio darbo \hyperlink{appendix}{priede}. Rašant kodą buvo susidurta su viena (pagrindine) problema. Kai turimas mažas duomenų kiekis, aprašytas MINQUE metodas veikia gan efektyviai. Tačiau TIMSS atveju, kai turime apie 4 500 stebėjimų, tenka apversti ir sudauginti labai dideles matricas ir tai reikalauja daug kompiuterio resursų ir laiko. Pati $\R$ programa nėra pritaikyta tokio tipo skaičiavimas, tačiau egzistuoja paketai \textit{Matrix} ir \textit{matrixcalc}, kurie efektyviau vykdo matricų algebrą. Taip pat yra sukurtas $\R$ papildymas BLAS, kuris įdiegiamas rankiniu būdu ir paspartina didelius skaičiavimus išskaidydamas vykdomą procesą per kelis procesoriaus branduolius. Plačiau apie tai internetiniame tinklapyje \url{http://www.r-bloggers.com/faster-r-through-better-blas}.


\subparagraph{Pastabos.} Savo straipsnių serijoje Rao pristatė ir kitokius mažiausios kvadratinės normos įvertinius, pats bendriausias - MINQE, kuris neapriboja invariantiškumu ir nepaslinktumu. Daugiau MINQE(I) - su invariantikumo apribojimu, MINQE(U) - tik su nepaslinktumo reikalavimu, MINQE(U,I) - tapatus nagrinėjamam MINQUE, MINVQUE - sudarytas prie normalumo prielaidos ir minimizuoja dispersiją (MIVQUE prie normalumo = MINQUE). Teorijoje ir praktikoje naudojami įvairūs MINQUE metodai, daugiau apie juos - 1979 metų Rao straipsnyje \cite{minquereml3}. Kiekvienas iš šių metodų turi savo pliusų ir savo minusų. Rao, aukščiau minėtame straipsnyje, taip pat tiria ir MINQUE savybes ir parodo, jog REML pirmoji iteracija yra MINQUE, o REML įvertinys yra identiškas I-MINQUE, kai \textit{apriori} (pradinės) reikšmės sutampa. Todėl MINQUE yra dažnai naudojamas gauti pradinėms REML reikšmėms.


\subsubsection{MINQUE pritaikymas HLM modeliams.}
??? Bagakas, Delpish ir Mano???


 Literatūros apie MINQUE pritaikymą hierarchiniams tiesiniams modeliams nėra daug arba sunku tokią gauti. Delpish\cite{delpish} 2006 metų savo daktaro disertacijoje remiasi Bagaka's\cite{bagaka} darbu, kuriame pristatomas minėtasis MINQUE metodas ir jo pritaikymas dviejų lygių hierarchiniams modeliams su atsitiktiniu postūmiu. Pasak autorių, MINQUE neturi procedūros skaičiuoti standartinėms paklaidoms ir pasikliautinumo intervalams, tad šiam tikslui buvo pasitelktas savirankos metodas. Kita problema, MINQUE labai priklauso nuo \textit{a priori} reikšmių, tad praktikoje dažniau taikomas iteratyvus metodas, kuris aprašytas \hyperlink{iminque}{toliau}. Tačiau Bagaka's darbo nepavyko gauti, o Delpish savo darbe tik labai abstrakčiai pristato vertinimo metodą. Be to, pristatomas metodas tik atsitiktinio postūmio atveju, tačiau vertinami modeliai su atsitiktiniu postūmiu ir posvyriu. Delpish modelius vertina su SAS programos PROC MOXED paketu, apie šį paketą plačios informacijos taip pat nepavyko gauti. Dėl šių priežasčių teko MINQUE metodą dviejų lygių HLM modeliams su atsitiktiniu postūmiu ir posvyriu išsivesti pačiai.


\subsubsection{Bagaka's MINQUE}
1992 metais savo nepublikuotoje disertacijoje \textit{Two-level nested hierarchical linear model with random intercepts via the bootstrap}\cite{bagaka} Bagaka's išvedė MINQUE procedūrą dviejų lygių tiesiniams hierarchiniams modeliams. Jo tikslas buvo Monte Carlo simuliacijų būdu palyginti MINQUE ir MINQUE su saviranka metodų gerumą ventinant dviejų lygių tiesinį hierarchinį modelį su atsitiktiniu poslinkiu kai normalumo sąlyga negali būti užtikrinta bei pažiūrėti ar MINQUE su saviranka išsprendžia neigiamų variacijos komponenčių įverčių problemą. Savo disertacijoje Bagaka's suveda modelio su atsitiktiniu poslinkiu MINQUE vertinimo procedūrą į mažiau reikalaujančia didelių matricų operacijų, taip pat parodo, jog \textit{a priori} reikšmės šiuo atveju yra susisę su tarpklasinės koreliacijos koeficientu \ref{eq:icc}. Dispersijoms komponentėms $\sigma^2$ ir $\tau_{00}^2$ atitinkamai $w_0=1-ICC$ ir $w_1=ICC$.
\indent Šiems svoriams gauti Bagaka's pasiūlė naudoti ANOVA paremtas \textit{a priori} reikšmes. $\hat{\sigma}^2_{e}$ gaunamas paprastu mažiausių kvadratų metodu (\textit{angl. OLS - ordinary least squares}) vertinant modelį \ref{eq:bendrasHLM} be atsitiktinių efektų. Tuomet atsitiktinių efektų dispersijos komponentės įvertis gaunamas iš
\[
\hat{\tau_{00}}^2=\frac{w^*-(N-P)\hat{\sigma}_e^2}{N-T^*},
\]
čia $w^*$ - paklaidų kvadratų suma (SSR), $N$ - imties dydis, $P$ - fiksuotų parametrų skaičius, $T^*=\sum_{j=1}^J tr\{S_j(X'_jX_j)^{-1}S_j\}$, $S_j$ yra $X_j$ stulpelių suma. Taip gaunamas $\widehat{ICC} = \frac{\hat{\tau}_{00}}{\hat{\sigma}^2+\hat{\tau}_{00}}$ ir kaip \textit{a priori} reikšmės naudojamas $\hat{w}_0=1-\widehat{ICC}$ ir $\hat{w}_1=\widehat{ICC}$.
\indent Bagaka's MC būdu tiria tokį dviejų lygių atsitiktinio postūmio modelį:
\begin{equation}\label{eq:beqa}
\left\{
\begin{array}{l}
Y_{ij} = \beta^*_{0j}+ \beta \times X_{ij}+\varepsilon_{ij}; \\
\beta^*_{0j} = \mu+\alpha_k+u_{j};\\
\end{array} \right. 
\end{equation}
kurį galima suvesti į bendrąją formą:
\begin{equation}\label{eq:beq}
Y_{ij}=\mu+\alpha_k+\beta\times X_{ij}+u_j+\varepsilon_{ij}, 
\end{equation}
čia $u_j$ atsitiktinis efektas su vidurkiu 0 ir dispersija $\tau_00$ ir $\varepsilon_{ij}$ atsitiktinis efektas su vidurkiu 0 ir dispersija $\sigma^2$ pasiskirstę pagal normalųjį arba dvigubą eksponentinį dėsnį (\textit{angl. double exponential distribution}). $\alpha_k$ - $k$-tojo lygio efektas.

\subparagraph{Dvigubas eksponentinis skirstinys} \hypertarget{dexp} Pats paprasčiausias būdas sugeneruoti duomenis pasiskirsčiusius pagal dvigubą exsponentinį skirtinį yra sugeneruoti du tolygiuosius (\textit{angl. uniformly distributed}) kintamuosius $U_1$ ir $U_2$ iš intervalo $\left[0,1\right]$. Tuomet tegul $X_1=-ln\left(U_1\right)$ ir $X_2=-1$, kai $U_2< 0,5$ arba $X_2=1$, kai $U_2 \geq 0,5$. Tuomet $Y=\frac{1}{\sqrt{2}}X_1X_2$ bus pasiskirstęs pagal dvigubą eksponentinį skirstinį.

\subparagraph{Simuliacijų dizainas} \hypertarget{Bsimdiz} Nagrinėjamas atsitiktinis kintamasis $Y$ pasiskirstęs per $J=50$ lygių (pvz.: mokyklų). Fiksuoti faktoriai $\mu$ , $\alpha_k$ ir $\beta$ priskirti atitinkamai $-5,\ 2,\ 3,\ 1$. Kai $ICC$ mažas, dispersijos komponenčių įverčiai gali įgauti neigiamas reikšmes, tyriami trys $ICC$ variantai. Modelio \ref{eq:beq} $\sigma^2=100$ ir $\tau_{00}=\{1;5,26;25\}$, taip gaunama $ICC=\{0,01;0,05;0,2\}$. Aiškinantysis kintamasis $x_ij$ gaunamas $\left(75\times U\left[0,1\right]\right)+25$, kur $U$ žymi tolygųjį skirstinį. Vienetų priklausančių $j$-tajai grupei skaičius yra nevienodas ir kinta tarp $\{20,25,30,35, 40\}$, tačiau visais atvejais yra fiksuotas, tad čia nebus surašytas. Viso pirmo lygio vienetų yra $1500$. Kiekvienam iš šešių atvejų - trys $ICC$ reikšmės ir 2 galimi paklaidų pasiskirstymai - atliekama $400$ MC simuliacijų.Kiekvienai sukurtai populiacijai įvertinamas modelis \ref{eq:beq} MINQUE ir MINQUE su saviranka metodais. Bagaka's naudoja neparametrinį savirankos metodą, kur pirmu žingsniu parenkama $J$ antro lygio vienetų su lygiomis tikimybėmis ir grąžinimu iš $J$ pradinių vienetų. Iš kiekvieno parinkto antrojo lygio vienetų parenkama $n_j$ pirmojo lygio individų su grąžinimu. Taip gavus savirankos imtį vertinama MINQUE. Kiekvienai MC simuliacijai popoliacija perrenkama $B=200$ kartų. Visi skaičiavimai atlikti naudojant $SAS$ statistinės analizės paketą.

\subparagraph{Simuliacijų rezultatai} \hypertarget{Brez} Parametrų įverčių gerumas vertintas poslinkiu nuo tikrosios reikmės bei vidutine kvadratine paklaida nuo tikrosios reikšmės (\textit{angl. mean squared error - MSE}). Taip pat skaičiuotas poslinkis atimant MINQUE įverčio reikšmę iš MINQUE su saviranka virečio reikšmės bei šių įverčių santykiai. \\
\indent Kuomet $ICC=0,01$, $\hat{\tau}_{00_{boot}}$ ir $\hat{\tau}_{00_{MINQUE}}$ įverčiai yra labai netoli tikrosios reikšmės abiems nagrinėtiems pasiskirstymams (normaliajam ir dvigubam eksponentiniui), tačiau $\hat{\tau}_{00_{boot}}$ yra efektyvesni ir stabilesni, o $\hat{\tau}_{00_{MINQUE}}$ turi mažesnį poslinkį. $\hat{\sigma}^2_{boot}$ ir poslinkis, ir variacija nežymiai didesni nei  $\hat{\sigma}^2_{MINQUE}$ prie abiejų pasiskirstymų.\\
\indent Kai $ICC=0,05$, $\hat{\tau}_{00_{boot}}$ ir $\hat{\tau}_{00_{MINQUE}}$ esant normaliajam atsitinktinių efektų pasiskirstymui labai tikslūs ir šiek tiek labiau paslinkti prie dvigubo eksponentinio pasiskirstymo, bet skirtumas tarp pačių įverčių nėra didelis.  $\hat{\sigma}^2_{boot}$ ir  $\hat{\sigma}^2_{MINQUE}$ vėl labai panašūs.\\
\indent Tiksliausi $\tau$ įverčia gauti, kai $ICC=0,2$, $\hat{\tau}_{00_{boot}}$ neženkliai tikslesnis.  $\hat{\sigma}^2_{boot}$ poslinkis mažesnis prie normaliųjų atsitiktinių efektų ir didesnis prie dvigubo eksponentinio pasiskirstymo.\\
\indent $ICC$ įvertis gautas visiems šešiems MC simuliacijų atvejams gauti labai tikslūs ir effektyvūs, tam įtakos galėjo turėti pradinės reikšmės.\\
\indent Visų fiksuotų parametrų gauti įverčiai labai arti tikrųjų reikšmių su beveik nuliniu MSE. \\
\indent Bagaka's taip pat nagrinėjo ir parametrų įverčių pasikliautinuosius intervalus. Kai $ICC$ yra mažas, gaunami labai tikslūspasikliautiniai intervalai. Kuo didesnis tarpklasinės koreliacijos koeficientas, tuo įverčių tikslumas mažesnis, tačiau visvien labai tikslus.\\\
\indent \textbf{Išvados}:
\begin{enumerate}
\item MINQUE su saviranka kai kur duoda tikslesnius parametrų įverčius todėl gali būti naudojamas ir taškiniams ir intervalų įverčiams gauti.
\item Abu metodai buvo mažiau efektyvūs, kai atsitiktiniai efektai pasiskirstę pagal dvigubą eksponentinį skirstinį, ko ir buvo tikėtasi. Taip pat abu metodai tiksliau įvertinmo fiksuotus modelio parametrus nei atsitiktinių efektų parametrus.
\item Savirankos būdu gauti pasikliautiniai intervalai buvo sėkmingi, kai tarpklasinės koreliacijos koeficientas $ICC=0,01$, prie $ICC=0,2$ intervalų patengamumo tikimybės gautos gana mažos, tačiau prie $ICC=0,05$ patenkinamos.
\item MINQUE su saviranka parametrų įverčiai gauti gana tikslūs, taip pat ir pasikliautinųjų intervalų padengiamumas.
\end{enumerate}
Problemos, kurias matau aš:
\begin{enumerate}
\item Naudotas lb mažas MC skaičius, todėl rezultatai tikėtina yra nestabilūs ir nepatikimi
\item Labai įtartina suvesta MINQUE forma. Kad ir turime tik atsitiktinio postūmio modelį, visvien forma išlieka ta pati. (peržiūrėti Rao?!)
\item boot MINQUE neprideda tikslumo, nebent CI duoda. O kodėl negalima naudoti PWIGLS S.E.?
\end{enumerate}


\subsubsection{Delpish MINQUE}
\indent Remdamasi Bagaka's disertacija Delpish 2006 metais savo disertacijoje \cite{delpish} palygino du metodus HLM modeliams vertinti - REML ir MINQUE su saviranka. Naudotas MINQUE su saviranka metodas visiškai identiškas Bagaka's metodui. Nagrinėjamas šiek tiek sudėtingesnis dviejų lygių su atsitiktiniu poslinkiu ir posvyriu modelis:
\begin{equation} \label{eq:2lvldelpish}
\left\{
\begin{array}{l}
Y_{ij} = \beta_{0j}+ \beta_{1j}\times X_{ij}+\varepsilon_{ij}; \\
\beta_{0j} = \gamma_{00} +\gamma_{01}\times W_{j}+u_{0j};\\
\beta_{1j} = \gamma_{10} +\gamma_{11}\times W_{j}+u_{1j};\\
\end{array} \right.
\end{equation}
čia $\varepsilon_{ij}$ -modelio paklaidos su vidurkiu $0$ ir dispersija $\sigma^2$; $\left(u_{0j}, u_{1j}\right)$ - atsitiktiniai efektai su nuliniais vidurkias ir kovariacijos matrica $\mathbf{T}=\begin{pmatrix}
\tau_{00} & \tau_{01} \\
\tau_{10} & \tau_{11} \\
\end{pmatrix}$; $\gamma_{pq},\ p,g = \{0,1\}$ - fiksuoti modelio efektai. $W_j$ - antrojo lygio aiškinantysis kintamasis, o $X_{ij}$ - pirmojo lygio aiškinantysis kintamasis. Šį pavidalą galima suvesti į:
\begin{equation} \label{eq:deq}
Y_{ij} = \gamma_{00} +\gamma_{01}\times W_{j}+ \gamma_{10}\times X_{ij}+\gamma_{11}\times W_{j}\times X_{ij}+u_{0j}+u_{1j}\times X_{ij}+\varepsilon_{ij};
\end{equation}

\subparagraph{Dvimatis $\chi^2$ skirstinys} \hypertarget{chi} Delpish savo disertacijoje \cite{delpish} pateikė kaip sugeneruojami dydžiai pasiskirstę pagal dvimatį $\chi^2$ skirstinį su norima dispersija ir vidurkiu. Tai atliekama sugeneruojant dvimatį normalųjį atsitiktinį dydį su kovariacijų matrica $\begin{pmatrix}
1& \rho\\
\rho& 1 \\
\end{pmatrix}$, kur $\rho$ žymi koreliaciją. Taip gaunami normalieji atsitiktiniai dydžiai $N_1$ ir $N_2$. Kiekvieną jų pakeliam kvadratu ir gauname dydžius $X_1$ ir $X_2$ pasiskirsčiusius pagal $\chi^2_1$. Iš kiekvieno iš šių vektorių atimame $1$ ir padalinam iš $\sqrt{2}$ bei padalinam iš $\sqrt{\tau}$, kur $\tau$ yra norima dispersija. Taip gaunamas dvimatis atsitiktinis dydis $Y$ su nuliniu vidurkiu ir kovariacijos matrica $\begin{pmatrix}
\tau& \rho\times \tau\\
\rho\times \tau & \tau \\
\end{pmatrix}$.

\subparagraph{Simuliacijų dizainas} \hypertarget{Dsimdiz} Delpish nagrinėja atvejus, kuomet antro lygio grupių $J$ yra 30 arba 100, o $ICC$ priskiriamas 0,01 ir 0,2. Fiksuoti efektai priskiriami $\gamma_{00}=1$ ir $\gamma_{01}=\gamma_{10}=\gamma_{11}=0,3$. Modelio paklaidų dispersija priskiriama $\sigma^2=0,5$. Kovariacijos komponentės priskiariamos atitinkamai norimam $ICC$ ir lygios $\tau_{00}=\tau_{11}=\{0,005;0,125\}$ ir $\tau_{01}=\tau_{10}=\{0,0025;0,0625\}$. Tiriami du atsitiktinių efektų ir paklaidų pasiskirstymo atvejai - normalusis ir \hyperlink{chi}{modifikuotas $\chi^2_1$}. Aiškinantieji kintamieji $X$ ir $W$ sugeneruoti nepriklausomai iš normaliojo skirstynio taip, kad atitiktų modelį (\ref{eq:deq}). Kiekvienam atvejui atlikta 500 MC simuliacijų. Saviranka atlikta $B=1000$ kartų kiekvieni MC simuliacijai vertinant MINQUE su saviranka. Visi skaičiavimai atlikti naudojant $SAS$ statistinės analizės paketą.

\subparagraph{Simuliacijų rezultatai} \hypertarget{Drez}Atlikus simuliacijas gauti rezultatai buvo lyginami santikiniu poslinkiu (\textit{angl. relative bias}). Esant tiek normaliosioms, tiek $\chi^2$  paklaidoms fiksuotų ir atsitiktinių parametrų įverčių santykinis poslinkis mažesnis nei 0,05 ($<5\%$) visiems tirtiems atvejams. REML metodu gauti įverčiai turi didesnį santykinį poslinkį nei MINQUE su saviranka, bet visvien santykinis poslinkis mažesnis už $5\%$.\\
\indent Toliau tirtas CI padengiamumas. Esant normaliosioms paklaidoms ir mažam grupių skaičiui sukonstruoti REML antrojo lygmens atsitiktinių parametrų pasiklaiutinumo intervalai buvo persiauri, o tai reikškia, jog standartinės paklaidos nuvertintos. Grupių skaičius kitais atvejais įtakos neturėjo. $ICC$ dydis neturėjo jokios įtakos pasikliautinių intervalų tikslumui. Prie $\chi^2_1$ skirstinio fiksuotų parametrų CI buvo pakankamai tikslūs. Atsitiktinių efektų parametrų įverčių CI REML metodui stipriai nuvertinami ir standartinės paklais paslinktos. $ICC$ dydis neturėjo reikšmės REML intervalų padengiamumui, tačiau darė įtaką MINQUE su saviranka metodui.Tačiau bendu atveju MINQUE su saviranka davė geresnius pasikliautinių intervalų įverčius.





\subsubsection{Mano MINQUE???}
%Turėdami HLM išraišką iš anksčiau $Y=X\gamma+Zu+\varepsilon$, galim $Z$ išreikšti kaip $Z=(\tilde{Z_1}\vdots\cdots\vdots\tilde{Z_J})$ ir atitinkamai $u'=(u_1'\cdots u_J')$.
%Tada $V=\sum^J_{j=1}\tilde{Z_j}T\tilde{Z_j}'+\sigma^2I$.\\
Tegul turime bendrą HLM modelio išraišką pavidalu (\ref{eq:bendrasHLM}) su $\mathbf{Y}$'ko kovariacijų matrica $\mathbf{V}=\mathbf{ZTZ'}+\sigma^2\mathbf{I}$ . Kadangi $\mathbf{T}=\{\tau_{ij}\}^P_{i,j=0}$ galima išskaidyti į $l=\frac{P(P+1)}{2}$ elementų sumą, t.y.
$\mathbf{T}=\sum^l_{r=1}\theta_rT_r$, kur $\boldsymbol{\theta} = (\theta_1,\theta_2,\dots,\theta_l)'=(\tau_{00}, \tau_{01}, \dots, \tau_{0q}, \tau_{11},\dots, \tau_{q-1,q})'$ ir atitinkamai
\small
\[
T_1=
\begin{pmatrix}
1&0&\cdots&0 \\
0&0&\cdots&0 \\
\vdots&\vdots& \cdots &\vdots \\
0&0&\cdots&0
\end{pmatrix};
T_2=
\begin{pmatrix}
0&1&\cdots&0 \\
1&0&\cdots&0 \\
\vdots&\vdots& \cdots &\vdots \\
0&0&\cdots&0
\end{pmatrix};
\dots;
T_l=
\begin{pmatrix}
0&0&\cdots&0 \\
0&0&\cdots&0 \\
\vdots&\vdots& \cdots &\vdots \\
0&0&\cdots&1
\end{pmatrix}.
\]

Pažymėkime $\mathbf{Q}_r:= \mathbf{Z}T_r\mathbf{Z'}$. Tuomet galima užrašyti $\mathbf{V}=\sum^l_{r=1}\theta_r\mathbf{Q}_r+\sigma^2 \mathbf{I}$. Tegul $\theta_0 = \sigma^2$ ir $\mathbf{Q}_0=\mathbf{I}$ ir galiausiai gauname

\begin{equation}
\mathbf{V}=\sum^l_{r=0} \theta_r\mathbf{Q}_r.
\end{equation}

Tokiu būdu gavome dispersijos išskaidymą kaip ir Rao MINQUE atveju. Pagrindinį vaidmenį šioje vietoje atlieka \textit{a priori} reikšmių nustatymas, norint gauti $\mathbf{\hat{V}}$. Plačiau apie jas \ref{subsubsec:apriori} skyrelyje. 



\subsubsection{A priori}\label{subsubsec:apriori}
\indent Pagal \textit{a priori} reikšmes MINQUE metodas skaidomas į MINQUE(0), MINQUE(1) ir MINQUE($\theta$). Kai $\theta_1=0$, o visi kiti $\theta_r=0, r = 2,\dots,l$, tuomet metodas vadinamas MINQUE(0). Jei visi $\theta_r=1, r=1,\dots,l$, tuomet metodas vadinamas MINQUE(1). Jei apytiksliai žinome, ar nuspėjame $\theta_r$ reikšmes ar santykius, arba gauname įverčius kitu ne tokiu patikimu metodu, tuomet vadiname MINQUE($\theta$).

\indent Kai nagrinėjame tik atsitiktinio postūmio atvejį, galime pasitelkti tarpklasinės koreliacijos koeficientą ICC ir imti $\alpha_0=1-\frac{\tau_{00}}{\tau_{00}+\sigma^2}$, o $\alpha_1=\frac{\tau_{00}}{\tau_{00}+\sigma^2}$. Šis būdas veiks gerai, kai turėsime pakankamai tvirtas pradines žinias apie ICC\cite{delpish}.

\indent Kaip \textit{a priori} reikšmes galime naudoti dviejų žingsnių vertinimo metodu gautus dispersijos komponenčių įverčius. Dviejų žingsnių metodas (\textit{angl. two-stage method}) yra labiau skirtas HLM modelių fiksuotiems koeficientams $\gamma_{ij}$ gauti ir susideda iš dviejų žingsnių:
\begin{enumerate}
\item Tarkime turime modelį (\ref{eq:2lvl}). Paprastu OLS metodu gauname įverčius $\hat{\beta}_{pj}$ atskirai kiekvienai grupei $j,\ j=1,\dots,J$ vertindami pirmąją modelio lygtį $Y_{ij} = \beta_{0j}+\sum^P_{p = 1} \beta_{pj}\times X_{pij}+\varepsilon_{ij}$. Gauname $\hat{\beta}_{pj}, \ \forall p,\ p=1,\dots,P$ bei $\hat{\sigma}^2$.
\item Gauti $\hat{\beta}_{pj}$ naudojami kaip aiškinamasis kintamasis toliau vertinant antrąją modelio (\ref{eq:2lvl}) lygtį $\hat{\beta}_{pj} = \gamma_{p0} + \sum^{Q_p}_{q=1}\gamma_{pq}\times W_{pqj}+u_{pj}$ GLS metodu. Taip gaunami $\hat{\gamma}_{pq}, \ p=1,\dots,P,\  q=1,\dots,Q_P$. O kartu ir $\hat{\tau}_{pp}$ bei $\hat{u}_{pj}, \forall p,\ p=1,\dots,P$. Turint $\hat{u}_{pj}$, galime suskaičiuoti jų empirinę koreliaciją ir taip gauti $\hat{\tau}_{pp}$.
\end{enumerate}

\indent Aukščiau išvardintu būdu, gauti įverčiai $\hat{\sigma}^2,\ \hat{\tau}_{pp}, \forall p,\ p=1,\dots,P$ dalijami iš $\hat{\sigma}^2$ ir naudojami kaip \textit{a priori} reikšmės vertinant MINQUE($\theta$) metodu. Plačiau apie dviejų žingsnių metodą galima rasti Hanushek 1974\cite{hanushek}, Saxonhouse 1976\cite{saxonhouse}, Jusko ir Shively \cite{jusko},  Achen 2005\cite{achen} ir k.t. PWMINQUE($\theta$) atveju abiejuose aukščiau surašytuose žingsniuose naudojami imties svoriai.


\subsubsection{PWMINQUE}
\indent Literatūroje WMINQUE vadinamas metodas su \textit{a priori} reikšmėmis. Dėl šios priežasties šiame darbe MINQUE su imties svoriais vadinsime PWMINQUE -- tikimybėmis pasvertas MINQUE (\textit{angl. Probability weighted MINQUE}).

\indent Jokioje literūroje nepavyko rasti MINQUE metodo, kuris būtų tinkamas vertinti su imties tikimybėmis. Šiame darbe PWMINQUE įvertinys yra paremtas Pfeffermann ir k.t.\cite{pfeff} pasiūlytu PWIGLS metodu.

\indent Pagal Pfeffermann ir kt.t. tarkime turime $M$ antro lygio vienetų ir $N_j$ pirmo lygio subjektų $j$-tajame antro lygio vienete ($j=1,\dots,J$). Tegul $y_{ij}$ yra reikšmė atsako kintamojo susieto su $i$-tuoju pirmo lygio subjektu iš $j$-tojo antro lygio vieneto. Tegul $y_{ij}$ yra generuojamas proceso:
\begin{equation}\label{eq:pf}
y_{ij}=x_{ij}\beta+z_{ij}u_j+z_{0ij}\nu_{ij},
\end{equation} 
kur $x_{ij}$, $z_{ij}$ ir $z_{0ij}$ yra žinomi vektoriai-eilutės su dimensijomis $p$, $q$ ir 1 atitinkamai, o $\beta$ fiksuotas nežinomų paametrų vektorius su dimensija $p\times1$ ir $u_j\sim \mathcal{N}(0, \Omega),\ \nu_{ij}\sim \mathcal{N}(0, \sigma^2)$. Toliau bus aprašytas IGLS -- iteratybus apibendrintasis mažiausių kvadratų (\textit{angl. Iterative General Least Squares}) -- algoritmas. Tegu $Y_j = (y_{1j},\dots,y_{N_jj})'$, $X_j=(x_{1j},\dots,x_{N_jj})'$ ir $e_j=(e_{1j},\dots,e_{N_jj})'$, kur $e_{ij}=z_{ij}u_j+z_{0ij}\nu_{ij}$. Tuomet \ref{eq:pf} modelį galime užrašyti matricine forma kaip
\begin{equation}
Y_j=X_j\beta+e_j, \ e_j\sim \mathcal{N}(0, V_j),
\end{equation}
kur $V_j=Z_j\Omega Z_j'+\sigma^2D_j$, $Z_j=(z_{1j}',\dots,z_{N_jj}')'$ ir $D_j=diag(z_{01j}^2,\dots,z_{0N_jj}^2)$.

\indent Tegul $s=\frac{q(q+1)}{2}+1$ ir $\theta=(\theta_,\dots,\theta_s)'$ vektorius $s\times 1$ dimensijos sudarytas iš $\Omega$ elementų ir $\sigma^2$. Tada galima išreikšti $V_j$ tiesine kombinacija:
\begin{equation}
V_j(\theta)=\sum_{k=1}^s \theta_k G_{kj},
\end{equation}
kur $G_{kj}=Z_jH_{kj}Z_j'+\delta_{ks}D_j$, kur $H_{kj}$ yra žinoma $q\times q$ matrica sudaryta iš 0 ir 1, o $\delta_{ks}$ yra Kronkerio delta. Tegul $E_{jj}[\beta]=(Y_j-X_j\beta)(Y_j-X_j\beta)'$. IGLS algoritmas paremtas iteratyviu įverčių $\beta_c^{(r)}$ ir $\theta_c^{(r)}$ perskaičiavimu:
\begin{description}
\item[1 žingsnis:] $\hat{\beta}_c^{(r)}=\hat{P}^{(r)-1}\hat{Q}^{(r)}$,\\
kur $\hat{P}^{(r)}=\sum_jX_j'\hat{V}_{jr}^{-1}X_j$, $\hat{Q}^{(r)}=\sum_jX_j'\hat{V}_{jr}^{-1}Y_j$ ir $\hat{V}_{jr}=\hat{V}_j\left(\hat{\theta}_c^{(r)-1}\right)$
\item[2 žingsnis:] $\hat{\theta}_c^{(r)}=\hat{R}^{(r)-1}\hat{S}^{(r)}$,\\
kur $\hat{R}^{(r)}=\{\hat{r}_{kl}^{(r)}\}$, $\hat{r}_{kl}^{(r)}=\sum_jtr\left(\hat{V}_{jr}^{-1}G_{kj}\hat{V}_{jr}^{-1}G_{lj}\right)$ ir $\hat{S}^{(r)}=\hat{s}_k^{(r)}$, $\hat{s}_k^{(r)}=\sum_jtr\left(\hat{e}_{jr}'\hat{V}_{jr}^{-1}G_{kj}\hat{V}_{jr}^{-1}\hat{e}_{jr}\right)$, $\hat{e}_{jr}=Y_j - X_j\hat{\beta}_c^{(r)}$
\end{description}

\indent Pfeffermann ir k.t. siūlo metodą PWIGLS -- tikimybėmis pasvertą IGLS (\textit{angl. Probability Weighted IGLS}), kuris yra lengvai pritaikomas standartiniam IGLS metodui. Jei turime $\pi_j$ -- antro lygio subjekto patekimo į imtį tikimybę ir $\pi_{i|j}$ -- pirmo lygio objekto patekimo į imtį tikimybę, jei bus parinktas antro lygio subjektas $j$. Siūloma antojo lygio sumas keisti svertinėmis sumomis su svoriais $w_j=\pi_j^{-1}$ ir kiekvieną pirmo lygio sumą keisti svertine suma su svoriais $w_{i|j}=\pi_{i|j}^{-1}$. Autoriai suveda matricų $\hat{P}^{(r)}$, $\hat{Q}^{(r)}$, $\hat{S}^{(r)}$ ir $\hat{R}^{(r)}$ išraiškas į paprastesnes. Kadangi šiame darbe nagrinėjamas bendresnis variantas, šios išraiškos nebus pateiktos, plačiau  Pfeffermann ir k.t.\cite{pfeff}.

Procedūra susideda iš dviejų žingsnių:
\begin{description}
\item[A žingsnis:] Pakeisti kiekvieną $z_{ij}$ į $w_j^{-\frac{1}{2}}z_{ij}$ ir kiekvieną $z_{0ij}$ į $w_j^{-\frac{1}{2}}w_{i|j}^{-\frac{1}{2}}z_{0ij}=w_{ij}^{-\frac{1}{2}}z_{0ij}$
\item[B žingsnis:] \ 
\begin{description}
\item[a)] Į kiekvieną sumą $\sum_j$ $\hat{R}^{(r)}$ matricoje įstatyti $w_j$,
\item[b)] $n_j$ pakeisti į $\hat{N}_j=\sum_jw_{i|j}$ (išraiška čia nepateikta, plačiau  Pfeffermann ir k.t.\cite{pfeff}).
\end{description}
\end{description}

\indent Toliau siūloma turimus svorius normuoti. Pateikiami du variantai. Čia bus aprašytas tik vienas, kuris ir naudojamas šiame darbe.  Kiekvienas $w_{i|j}$ keičiamas į $w_{i|j}^*=\lambda_jw_{i|j}$, $\lambda_j=\bar{w}_j^{-1}$, $\bar{w}_j=\sum_jw_{i|j}/n_j$. Taip normavę svorius galime atsisakyti žingsnio $B$, plačiau Pfeffermann ir k.t.\cite{pfeff}.

\indent Jei atidžiau pažiūrėsime į matricų $\hat{S}^{(r)}$ ir $\hat{R}^{(r)}$ išraiškas, galime pastebėti panašumą į $S$ ir $q$ išraiškas pateiktas skyrelyje \ref{subsec:minque}, jos atrodo taip $S=\{s_{kl}\}$, $s_{kl}=tr(\mathbf{CQ}_k\mathbf{CQ}_l)$, o
$q=\{q_k\}$,

\noindent $q_k=\mathbf{Y'CQ}_k\mathbf{CY}$, $\mathbf{C} = \mathbf{\hat{V}}^{-1}\left(\mathbf{I}-\mathbf{X}\left(\mathbf{X' \hat{V}}^{-1}\mathbf{X}\right)^{-1}\mathbf{X \hat{V}}^{-1}\right)$, $\mathbf{\hat{V}}=\sum^l_{r=1}\alpha_r\mathbf{Q}_r$, $\alpha_r$ - \textit{a priori} reikšmės, o $\mathbf{Q}_k:= \mathbf{Z}T_k\mathbf{Z'}+\delta_{k0}\mathbf{I}=\sum_j(Z_jT_kZ_j'+\delta_{k0}I_{n_j})=\sum_j(Z_jH_{kj}Z_j'+\delta_{k0}D_j)=\sum_jG_{kj}$, kai $D_j=I_{n_j}$. Tad $\{s_{kl}\}=\sum_jtr(CG_{kj}CG_{lj})$ ir $\{q_k\}=\sum_jtr(Y'_jC_jG_{kj}C_jY_j)$. Vieninteliai skirtumai lieka matrica $C$ ir $Y_j$. Kadangi išreiškėme $S$ ir $q$ per sumas, galime pritaikyti  Pfeffermann ir k.t.\cite{pfeff} pasiūlytą svėrimą. Taigi, pirmu žingsiu keičiame $z_{ij}$ į $w_j^{-\frac{1}{2}}z_{ij}$ ir $z_{0ij}$ į $w_j^{-\frac{1}{2}}w_{i|j}^{-\frac{1}{2}}z_{0ij}=w_{ij}^{-\frac{1}{2}}z_{0ij}$, kur mūsų atveju $z_{0ij}=1$, pavadinkime gautą $q$ su svoriais $q^*$. Ir antru žingsniu įstatome $w_j$ į $\{s_{kl}\}$, $\{s^*_{kl}\}=\sum_jw_jtr(C_jG_{kj}C_jG_{lj})$. Tuomet $\hat{\theta}^*=S^{*-1}q^*$ ir bus PWMINQUE.

\subsection{Saviranka}

\indent Savirankos metodas pristatytas 1979 metais Efron \cite{efron} ir yra plačiai paplitęs modeliavime. Šio metodo esmė, perrinkti turimą imtį be galo daug kartų, kad būtų atspindėta populiacija, jos skirstinys. Kitaip: sakome, kad turima imtis yra mini populiacija ir iš jos traukiame be galo daug imčių, taip siekdami gauti stabilesnius įverčius. Tad šis metodas naudojamas poslinkio koregavimui, standartinėms paklaidoms bei pasikliautiniams intervalams gauti. Ir reikalauja iš turimos imties tik tiek, jog ji būtų atsitiktinai parinkta ir kuo geriau atspindėtų populiaciją. Standartiškai, iš turimos imties parenkama tokio paties dydžio imtis su grąžinimu ir skaičiuojami įverčiai ar kitos charakteristikos. Tai kartojama kažkokį didelį B kartų skaičių ir atliekami papildomi skaičiavimai, kaip kad randamos standartinės paklaidos. Tačiau turint kelių lygių arba hierarchinę struktūrą (tuo labiau lizdinę imtį), savirankos metodą reikia pritaikyti turimam atvejui, kadangi matavimai nėra nepriklausomi ir vienodai pasiskirstę.

\indent Hierarchiniams duomenims (kaip ir paprastai) taikomi parametriniai, neparametriniai ir pusiau parametriniai, atvejų ir paklaidų savirankos metodai. Leeden ir kiti \cite{bootML} savo 1997 metų straipsnyje Monte Carlo simuliacijų būdu tyrė tris metodus taikytus dviejų lygių duomenims: atvejų saviranką, paklaidų saviranką ir parametrinę saviranką, kai modeliai vertinami didžiausio tikėtinumo metodu (ML). Jų rezultatai parodė, jog fiksuotų parametrų įverčiai yra nepaslinkti ir saviranka neatneša jokios naudos, tačiau standartinės paklaidos, įvertintos ML metodu yra paslinktos į mažąją pusę ir atvejų saviranka čia duoda geriausius rezultatus. Kiek kitaip yra su atsitiktiniais efektais, čia mažiausią poslinkį turi, autorių vadinama, sutraukianti saviranka. Bet standartinių paklaidų atžvilgiu geriausia atvejų saviranka. Nors atvejų savirankos metodas nebuvo pripažintas geriausiu, autoriai rekomenduoja šį metodą, nes jis reikalauja mažiausiai prielaidų apie modelį ar turimų duomenų struktūrą. Taigi, neparametrinė atvejų saviranka bus naudojama šiame magistro darbe.

\indent Dėl hierarchinės struktūros sudėtingumo, neparametrinės atvejų savirankos imtys gali būti sudaromos įvairiai: perrenkant tik vieną iš lygių, kelis arba visus, perrenkant su grąžinimu ir be jo. Ren ir kiti \cite{bootNest} straipsnyje apie neparametrinę saviranką parodė, jog geriausia perrinkti su grąžinimu aukščiausiame lygyje, o visuose kituose lygiuose perrinkti be grąžinimo. Taip ir bus daroma šiame darbe. Toliau bus pateiktas naudojamas neparametrinės atvejų savirankos metodas.

\subparagraph{Neparametrinė atvejų saviranka.} Sakykime, jog turime $H$ lizdų, kiekviename iš jų turime po $n_h$ mokyklų, o $j$ - tojoje mokykloje iš $h$ - tojo lizdo mokosi $n_{hj}$ mokinių. Tuomet savirnaka atliekama taip:
\begin{enumerate}
\item Iš kiekvieno lizdo $h$ ($h=1,\dots,H$) parenkama $n_h-1$ mokyklų su grąžinimu. Kiekvienai parinktai mokyklai $j$ iš $h$ - joto lizdo paimame atitinkamą aiškinančiųjų kintamųjų rinkinį $\mathbf{W}^*_{jh}$.
\item Tuomet kiekvienoje parinktoje mokykloje $j$ (jei mokykla kartojasi, kiekvieną kart parenkama nepriklausomai) parenkama $n_{hj}-1$ mokinių be grąžinimo. Ir kiekvienam parinktam $i$ - tajam mokiniui iš $j$ - tosios mokyklos iš $h$ - jojo lizdo paimamas kintamųjų rinkinys ($\mathbf{Y}^*_{ijh}, \mathbf{Z}^*_{ijh}$). Kiekvieną pirmo lygio kintamąjį atitinkamai sujungus su antro lygio kintamuoju, gaunama savirankos imtis.
\item Gautai savirankos imčiai įvertinami norimi modelio parametrai.
\item Žingsniai 1-3 kartojami be galo daug kartų B.
\end{enumerate}
Taip gaunama B savirankos parametrų įverčių, kurie apdorojami toliau aprašytu būdu. 

\subparagraph{Savirankos metodas.} Sakykime, kad $\chi = \{X_1,\dots,X_n\}\stackrel{nvp}{\sim}F$, kur $F$ yra nežinoma pasiskirstymo f-ja. Statistikai $\hat{\theta}$ pasirinktai įvertinti pasiskirstymo $F$ parametrą $\theta$ gaunamas savirankos pasiskirstymas, perrenkant su grąžinimu iš $\chi$. Praktikoje pasirenkamas pakankamai didelis skaičius B savirnakos imčių ir gaunama $\hat{\theta}^*_b$ ($b=1,\dots,B$) savirankos įverčių, kurie atspindi $\hat{\theta}$ pasiskirstymą. Tuomet parametro $\theta$ savirankos įvertis gaunamas suvidurkinus visas $\hat{\theta}^*_b$, o standartinės paklaidos (\textit{s.e.}) taip:
\[
\hat{\theta}^*_{(.)}=\frac{1}{B}\sum^B_{b=1}\hat{\theta}^*_b; \
s.e.(\hat{\theta})=\left[\frac{1}{B-1}\sum^B_{b=1}(\hat{\theta}^*_b - \hat{\theta}^*_{(.)})^2\right]^{\frac{1}{2}}.
\]
Dar skaičiuojamas įverčio poslinkis $\widehat{bias}(\hat{\theta})=\hat{\theta}^*_{(.)}-\hat{\theta}$ ir gaunama parametro poslinkio korekcija $\hat{\theta}_{boot}=\hat{\theta}-\widehat{bias}(\hat{\theta})=2\hat{\theta}-\hat{\theta}^*_{(.)}$. Skaičiuojami ir savirankos pasikliautiniai intervalai, čia bus aprašytas ir naudojamas tik percentilių metodas, kuris nereikalauja žinių apie $\theta$ pasiskirstymą. Apskaičiuojami $d^*_b=\hat{\theta}^*_b-\hat{\theta}$ ir parenkamas $d_c$ toks, kad $(1-\alpha)100\%$ visų $d^*_b$ reikšmių patektų į intervalą $\pm d_c$. Tuomet $(1-\alpha)100\%$ savirankos pasikliautiniai intervalai gaunami iš $\hat{\theta}\pm d_c$, čia $\alpha$ - pasirinktas reikšmingumo lygmuo.




\newpage
\section{EMPIRINĖS SIMULIACIJOS} \label{sec:simul}
\indent Šiame skyriuje aprašomos vykdytos Monte Carlo simuliacijos, pateikiami generuotų modelių įverčiai bei empirinėmis simuliacijomis grįstos išvados.


\subsection{Monte Carlo simuliacijos}
\indent Šiame skyrelyje nusakomi du empirinių simuliacijų dizainai -- netaikant imties svorių ir taikant svorius MINQUE metodui. Iš pradžių MINQUE metodas detaliai lyginamas su REML. Vėliau tik parodoma, jog PWMINQUE metodas duoda tikslesnius įverčius nei nesvertinis MINQUE.

\subsubsection{Be imties svorių}\label{subsubsec:besvoriu}
\indent Šiame skyrelyje nusakomas simuliacijų dizainas, kuomet lyginami REML, MINQUE(0), MINQUE(1) ir MINQUE($\theta$) metodai.

\indent Stengtasi, kad sukurta populiacija kuo labiau atspindėtų TIMSS populiaciją bei imtį Lietuvos atveju. Lietuvos mokyklų 2011 metais aštuntokų populiacija siekia ko ne 40 000, o TIMSS imtis apima iki 5000 aštuntokų (Lietuvos statistikos departamento duomenimis). Ji apima vos 12\% visos aštuntokų populiacijos. Tokią procentinę dalį stengtasi atspindėti. Deja, didelė populiacija ir didelės imtys reikalauja ir daug kompiuterio resursų, todėl populiacijos dydis pasirinktas 300 mokyklų, o imamos imties - 35 mokyklos. Kad įsitikinti, jog šis procentas tinkamas, taip pat parenkama ir 20 bei 80 antro lygio subjectų. Šiame darbe lizdai nebuvo sudaryti. Taigi, iš pradžių sugeneruojama 300 mokyklų dydžio populiacija pagal paprastą hierarchinį modelį:
\begin{equation}\label{eq:simul}
\left\{
\begin{array}{l}
Y_{ij}=\beta_{0j}+\beta_{1j}X_{1ij}+\varepsilon_{ij}, \ \varepsilon_{ij}\sim (0, \sigma^2);\\
\beta_{0j}=\gamma_{00}+\gamma_{01}W_j+u_{0j}, \ u_{0j}\sim (0, \tau_{00});\\
\beta_{1j}=\gamma_{10}+\gamma_{11}W_j+u_{1j}, \ u_{1j}\sim (0, \tau_{11}).
\end{array} \right.
\end{equation}
čia $\varepsilon_{ij}$ -modelio paklaidos su vidurkiu $0$ ir dispersija $\sigma^2$; $\left(u_{0j}, u_{1j}\right)$ - atsitiktiniai efektai su nuliniais vidurkias ir kovariacijos matrica $\mathbf{T}=\begin{pmatrix}
\tau_{00} & \tau_{01} \\
\tau_{10} & \tau_{11} \\
\end{pmatrix}$; $\gamma_{pq},\ p,g = \{0,1\}$ - fiksuoti modelio efektai. $W_j$ - antrojo lygio aiškinantysis kintamasis, o $X_{ij}$ - pirmojo lygio aiškinantysis kintamasis. Šį pavidalą galima suvesti į:
\begin{equation} \label{eq:deq}
Y_{ij} = \gamma_{00} +\gamma_{01}\times W_{j}+ \gamma_{10}\times X_{ij}+\gamma_{11}\times W_{j}\times X_{ij}+u_{0j}+u_{1j}\times X_{ij}+\varepsilon_{ij};
\end{equation}

\indent Kiekvienai mokyklai $j =1,\dots,J=300$ sugeneruojamas aiškinamasis kintamasis $W_j$, kuris įgyja reikšmes atsitiktinai su lygiomis tikimybėmis iš intervalo $[1; 8]$ su žingsniu $\frac{1}{3}$. Tai galėtų būti indeksas žymintis mokykloje sudaromas sąlygas mokytis, kuo jis didesnis, tuo geresnės sąlygos. Pridedami atsitiktiniai efektai $u_{0j}$ ir $u_{1j}$. Antrojo lygio paklaidų koreliacija parenkama $\tau_{01} = \tau{10}=0,5$. O dispersijos $\tau_{00}=\tau_{11}$ parenkamos lygios paprastumo dėlei ir įgyja tris reikšmes (100; 800; 2000). Taip daroma pagal (bla bla!!!), kad būtų atspindėtas santykis $\frac{\tau_{00}}{\sigma^2}$ atitinkantis (0,05; 0,4; 1). Čia išskiriami du atvejai, $u_{0j}\sim \mathcal{N}(0; \tau_{00})$ ir $u_{1j}\sim \mathcal{N}(0; \tau_{11})$ arba $u_{0j}\sim \chi^2(0; \tau_{00})$ ir $u_{1j}\sim \chi^2(0; \tau_{11})$. Toks $\chi^2$ pasiskirstymas gaunamas sugeneravus $\tilde{u}_{0j}\sim\chi^2_1$, jį standartizavus ir padauginus iš $\sqrt{\tau_{pp}}$. Čia pasirinkta  $\gamma_{00}=450$, $\gamma_{01}=30$, $\gamma_{10}=10$ ir $\gamma_{11}=5$. Toliau kuriami mokinio (pirmojo) lygio kintamieji.

\indent TIMSS tyrime parinktoje mokykloje renkama klasė ir tiriami visi jos mokiniai. Kiekvienoje iš mokyklų, sugeneruojamas jos dydis, panašiai kaip daryta Vakilian daktaro disertacijoje \cite{mcmc}. $j$ - tosios mokyklos dydis gaunamas $N_j=\left[50\times\exp{(\tilde{u}_{0j})}\right]$, čia laužtiniai skliaustai žymi sveikąją dalį, o $\tilde{u}_{0j}$ sugeneruotas iš $\mathcal{N}(0; 0,2)$ skirstinio apriboto tarp $-1,5\sqrt{0,2}$ ir $1,5\sqrt{0,2}$.  $N_j$ įgyja reikšmes tarp kažkur tarp 11 ir 225. Toliau mokyklos suskirstomos į klases pagal formulę $c_j=\left[\frac{N_j}{30}\right]$, kur $c_j$ žymi klasių skaičių. Tai yra kiekvienas mokinys priskiriamas į vieną iš klasių atitiktinai su lygiomis tikimybėmis. Čia kiek. Tuomet $X_{1ij}\sim \mathcal{B}(1; 0,2)$. Jis gali būti interpretuojamas kaip žymimasis kintamasis, kuris įgyja reikšmę 1, jei mokinys mėgsta mokytis matematiką. Ir galiausiai pridedami atsitiktiniai svyravimai. Kaip ir anksčiau, išskiriami du atvejai: $\varepsilon_{ij}\sim \mathcal{N}(0; \sigma^2)$ arba $\varepsilon_{ij}\sim \chi^2(0; \sigma^2)$ (gautas kaip anksčiau). $\sigma^2$ čia parinktas 2000 pagal pradinius TIMSS modelius.

\indent Sudarius populiaciją, parenkama $m$ dydžio imtis. Kaip jau minėta iš 300 mokyklų populiacijos atsitiktinai parenkamos 20, 35 ir 80 mokyklų su tikimybėmis atvirkščiai proporcingomis mokyklos mokinių skaičiui. Kiekvienai patrinktai mokyklai atsitiktinai su lygiomis tikimybėmis parenkama viena klasė. Subalansuoto dizaino atveju, pirmojo lygio subjektai neskaidomi į klases, o tiesiog iš kiekvieno antrojo lygio subjekto su lygiomis tikimybėmis parenkama po 30 pirmo lygio subjektų. Visi simuliacijų parametrai pateikti lentelėse \ref{table:fixed} ir \ref{table:struct2}. Lentelėje \ref{table:struct1} pateikti simuliacijų struktūrų pažymėjimai. Viso 36 atvejai.


\begin{table}[ht]
\centering
\begin{tabular}{|c|r|}
\hline
Pavadinimas & Reikšmė\\
\hline
$\gamma_{00}$& 450  \\
$\gamma_{01}$& 10  \\
$\gamma_{10}$& 30 \\
$\gamma_{11}$& 5  \\
$X_{ij}$ &  $B\left(1; 0,2\right)$ \\
$W_{j}$ &  Indeksas \\
\hline
\end{tabular}
\caption{Lentelėje pateiktos fiksuotos modelio parametrų ir kintamųjų reikšmės.}
\label{table:fixed}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|cccc|}
\hline
 Pažymėjimas & $\sigma^2$&$\tau_{00}$&$\tau_{01}=\tau_{10}$&$\tau_{11}$\\
\hline
V1&2000&100&50&100\\
V2&2000&800&400&800\\
V3&2000&2000&1000&2000\\
\hline
\end{tabular}
\caption{Lentelėje pateikti pažymėjimai simuliacijose naudojamoms dispersijos komponenčių kombinacijoms.}
\label{table:struct2}
\end{table}

\begin{table}[ht]
\centering
\begin{tabular}{|c|cc|}
\hline
 & \multicolumn{2}{c|}{$n_j$}\\
\hline
$m$& Nesubalansuotas & \ \ \ \ \ \ \ \ \ \ 30\ \ \ \ \ \ \ \ \ \ \\
\hline
20& P1&P2\\
35&P3&P4\\
80& P5&P6\\
\hline
\end{tabular}
\caption{Lentelėje pateikti simuliacijų struktūrų pažymėjimai. Čia $m$ žymi antrojo lygio individų skaičių, $n_j$ žymi pirmojo lygio individų skaičių.}
\label{table:struct1}
\end{table}



\indent Šiame darbe atliekama 500 Monte Carlo simuliacijų kiekvienam iš 36 atvejų. Kiekvienos iš simuliacijų metu sugeneruojama populiacija aukščiau aprašytu būdu, tuomet traukiama imtis pagal anksčiau aprašytą metodą. Ir vertinamas modelis (\ref{eq:simul}) visais metodais (REML, MINQUE(0), MINQUE(1) ir MINQUE($\theta$)). Gauti parametrų įverčiai analizuojami toliau pateiktomis statistikomis. Sklaičiavimai atlikti su statistinės analizės programa Revolution $\R$ Open 3.2.2, naudotas keturių branduolių procesorius \textit{Intel(R) Core(TM) i7-3630QM CPU @ 2.40GHz}. Gauti rezultatai pateikti kitame skyrelyje.

\subparagraph{Vidutinis įvertis} gaunamas tiesiog suvidurkinus simuliacijų metu gautus parametro įverčius:
\[
\hat{\theta}_{jkl}=\frac{1}{S}\sum_{s=1}^S\hat{\theta}_{sjkl},
\]
kur \\
$\hat{\theta}_sjkl$ - $s$ - tosios simuliacijos $j$-tojo parametro gauto pagal $k$-tąjį metodą iš $l$-tosios duomenų struktūros $\theta_j$ įvertis,\\
$s$ - simuliacijos numeris, $s=1,\dots,S$,\\
$j$ - parametro pažymėjimas, įgyja reikšmes - $\gamma_{pq}$, $\sigma^2$ ir $\tau_{00}$,  $\tau_{01}$,  $\tau_{11}$\\
$k$ - metodo pažymėjimas, įgyja reikšmes - REML, MINQUE(0), MINQUE(1) ir MINQUE($\theta$),\\
$l$ - duomenų struktūros pažymėjimas, įgyja reikšmes pagal kombinacijas iš \ref{table:struct1} lentelės.\\

\subparagraph{Vidutinis santykinis poslinkis -- MRBIAS} (\textit{angl. Mean Relative Bias}) skaičiuojamas:
\[
MRBIAS_{jkl}=\frac{1}{S}\sum_{s=1}^S\frac{\hat{\theta}_{sjkl}-\theta_j}{\theta_j},
\]
kur \\
$\theta_j$ - tikroji $j$-tojo parametro reikšmė, \\
$\hat{\theta}_sjkl$ - $s$ - tosios simuliacijos $j$-tojo parametro gauto pagal $k$-tąjį metodą iš $l$-tosios duomenų struktūros $\theta_j$ įvertis,\\
$s$ - simuliacijos numeris, $s=1,\dots,S$,\\
$j$ - parametro pažymėjimas, įgyja reikšmes - $\gamma_{pq}$, $\sigma^2$ ir $\tau_{00}$,  $\tau_{01}$,  $\tau_{11}$\\
$k$ - metodo pažymėjimas, įgyja reikšmes - REML, MINQUE(0), MINQUE(1) ir MINQUE($\theta$),\\
$l$ - duomenų struktūros pažymėjimas, įgyja reikšmes pagal kombinacijas iš \ref{table:struct1} lentelės.\\
\indent Jei ši statistika yra mažesnė nei 0,05, tai sakome, jog poslinkio nėra. Jei tarp 0,05 ir 0,2, tai sakome, jog turime vidutinį poslinkį. Ir jei daugiau nei 0,2, tai sakome, jog poslinkis didelis. Taip pat skaičiuojama bendra statistika atskirai fiksuotiems ir atsitiktiniams dydžiams -- \textbf{CAMRBIAS} -- jungtinis absoliutus vidutinis santykinis poslinkis (\textit{angl. Compound Absolute Mean Relative Bias}), skaičiuojama:
\[
CAMRBIAS_{kl}=\frac{1}{n_{kl}}\sum_{j=1}^{n_{kl}}\left|MRBIAS_{jkl}\right|
\]


\subparagraph{Vidutinė santykinė kvadratinė paklaida -- MRSE } (\textit{angl.  Mean Relative Squared Error}) skaičiuojama: 
\[
MRSE_{jkl}=\frac{1}{S}\sum_{s=1}^S\left(\frac{\hat{\theta}_{sjkl}-\theta_j}{\theta_j}\right)^2,
\]
kur \\
$\theta_j$ - tikroji $j$-tojo parametro reikšmė, \\
$\hat{\theta}_sjkl$ - $s$ - tosios simuliacijos $j$-tojo parametro gauto pagal $k$-tąjį metodą iš $l$-tosios duomenų struktūros $\theta_j$ įvertis,\\
$s$ - simuliacijos numeris, $s=1,\dots,S$,\\
$j$ - parametro pažymėjimas, įgyja reikšmes - $\gamma_{pq}$, $\sigma^2$ ir $\tau_{00}$,  $\tau_{01}$,  $\tau_{11}$\\
$k$ - metodo pažymėjimas, įgyja reikšmes - REML, MINQUE(0), MINQUE(1) ir MINQUE($\theta$),\\
$l$ - duomenų struktūros pažymėjimas, įgyja reikšmes pagal kombinacijas iš \ref{table:struct1} lentelės.\\
\indent Jei statistika MRSE yra mažesnė už 0,5, tai laikysime, jog įverčiai išsibarstę nedaug. Taip pat skaičiuojama bendra statistika atskirai fiksuotiems ir atsitiktiniams parametrams -- CMRSE -- jungtinė vidutinė santykinė kvadratinė paklaida (\textit{angl. Coumpound Mean Relative Squared Absolute Bias}):
\[
CMRSE_{kl}=\frac{1}{n_{kl}}\sum_{j=1}^{n_{kl}}MRSE_{jkl}.
\]

\subparagraph{Empiriniai kvantilių sklaidos grafikai -- EQDG}(\textit{angl. Empirical Quantile Dispersion Graphs}) metodų palyginimui buvo pasiūlyti Lee ir Khuri\cite{eqdg1} ir panaudoti REML lyginimui su MINQUE ir kitais metodais Leithy ir kt.\cite{MMINQUE}. Toliau pateikiamas trumpas metodo aprašymas (plačiau pasiskaityti minėtuose straipsniuose):
\begin{enumerate}[a)] 
\item Tegu pasirenkamas specifinis parametrų vertinimo metodas (REML, MINQUE ir t.t.);
\item Sugeneruojamas $\mathbf{Y}$ pagal pasirinktą duomenis generuojantį procesą;
\item Gaunami parametrų įverčiai su a) žingsnyje pasirinktu metodu;
\item Žingsniai b) ir c) kartojami didelį skaičių kartų.
\item Pasirenkamas vienas iš vertintų parametrų, sakykime $\tau_{00}$ ir skaičiuojamas dydis $q_s=\frac{\hat{\tau}_{00}}{\tau_{00}}$, kur s žymi s-tąjį įvertį;
\item Su pasirinktomis percentilių reikšmėmis $p_h$ gaunami empiriniai kvantiliai $w_{h1}$ iš $q_s$, h -- indeksas žymintis percentilį.
\item Žingsniai e) ir f) kartojami kiekvienam parametrui;
\item Pasirenkama kita duomenų struktūrą ir atliekami žingsniai b) - g), taip ganaumas $w_{h2}$;
\item Žingsnis h) kartojamas įvairioms struktūroms, kol išsemiami visi taškai;
\item Susmaičiuojamas $\max (w_{h1},\dots,w_{hh^*})$, kur $h^*$ žymi skaičių taškų esančių nusakytame regione su $p_h$. Šis maksimumas yra EQM -- empinių kvantilių maksimumas (\textit{angl.Empirical Quantile Maximum});
\item Pasirenkamas kitas metodas ir kartojami ankstesni žingsniai, gaunami kiti EQM kiekvienam parametrui;
\item Kartojama tiek kartų, keik yra metodų;
\item Kiekvienam parametrui gaunamas grafikas, kur x ašyje yra $p_h$, o y ašyje -- EQM.
\end{enumerate}
\indent Kuo EQM arčiau vieneto tuo geriau. Aukštesnioji kreivė laikoma prastesne.

\subsubsection{Su imties svoriais}\label{subsubsec:susvoriais}
\indent Šiame skyrelyje nusakoma, kaip buvo sudaryta populiacija, imčių ėmimas ir svorių sudarymas. Kadangi informatyvų ėmimo dizainą gana sunku sudaryti, jis pasirinktas toks pat kaip Steele, Clarke ir Goldstein straipsnyje \textit{Weighting in MLwiN}\cite{mlwin}. 

\indent Sugeneruojama $M=300$ mokyklų dydžio populiacija pagal hierarchinį modelį:
\begin{equation}\label{eq:wsimul}
\left\{
\begin{array}{l}
Y_{ij}=\beta_{0j}+\beta_{1j}X_{1ij}+\varepsilon_{ij}, \ \varepsilon_{ij}\sim \mathcal{N}(0, \sigma^2);\\
\beta_{0j}=\gamma_{00}+\gamma_{01}X_{2j}+u_{0j}, \ u_{0j}\sim \mathcal{N}(0, \tau_{00});\\
\beta_{1j}=\gamma_{10}+u_{1j}, \ \ \ \ \ \ \ \ \ \ \  \ \  \ u_{1j}\sim \mathcal{N}(0, \tau_{11}).
\end{array} \right.
\end{equation}
čia $\varepsilon_{ij}$ -modelio paklaidos su vidurkiu $0$ ir dispersija $\sigma^2=1$; $\left(u_{0j}, u_{1j}\right)$ - atsitiktiniai efektai su nuliniais vidurkias ir kovariacijos matrica $\mathbf{T}=\begin{pmatrix}
\tau_{00} & \tau_{01} \\
\tau_{10} & \tau_{11} \\
\end{pmatrix}=\begin{pmatrix}
\frac{1}{4}& \frac{\sqrt{3}}{8} \\
 \frac{\sqrt{3}}{8} & \frac{3}{4}\\
\end{pmatrix}$; $\gamma_{pq}=1,\ p,g = \{0,1\}$ - fiksuoti modelio efektai. $X_{2j}$ - antrojo lygio aiškinantysis kintamasis, $X_2\sim \mathcal{B}(1;0,5)$, o $X_{ij}$ - pirmojo lygio aiškinantysis kintamasis, $X_1\sim \mathcal{N}(0;1)$ - nuvidurkintas pagal $j$. Šį pavidalą galima suvesti į:
\begin{equation} \label{eq:deq}
Y_{ij} = \gamma_{00} +\gamma_{01}\times X_{2j}+ \gamma_{10}\times X_{1ij}+u_{0j}+u_{1j}\times X_{1ij}+\varepsilon_{ij}.
\end{equation}

\indent Antro lygio subjektų parinkimo tikimybė yra susijusi su modelio atsitiktiniu posvyriu ir poslinkiu:
\begin{equation}
\pi_j=
\left\{
\begin{array}{l}
0,225, \text{ kai } u_{0j} \notin \left(\bar{u}_0-2\times sd_0; \bar{u}_0+2\times sd_0\right) \text{ ir } |u_{1j}| > 1;\\
0,425, \text{ kai } u_{0j} \in \left(\bar{u}_0-2\times sd_0; \bar{u}_0+2\times sd_0\right) \text{ ir } |u_{1j}| > 1;\\
0,525, \text{ kai } u_{0j} \notin \left(\bar{u}_0-2\times sd_0; \bar{u}_0+2\times sd_0\right) \text{ ir } |u_{1j}| \leq 1;\\
0,725, \text{ kai } u_{0j} \in \left(\bar{u}_0-2\times sd_0; \bar{u}_0+2\times sd_0\right) \text{ ir } |u_{1j}| \leq 1.
\end{array} \right.
\end{equation}
\noindent Čia $\bar{u}_0=\frac{1}{J}\sum_ju_{0j}$ ir $sd_0=\sqrt{\frac{1}{J}\sum_j(u_{0j}-\bar{u}_0)^2}$, atitinkamai $u_{0j}$ vidurkis ir standartinis nuokrypis. 

\indent Pirmo lygmens subjektai parenkami pagal modelio paklaidas $\varepsilon_{ij}$:
\begin{equation}
\pi_{i|j}=
\left\{
\begin{array}{l}
0,25, \text{ kai } \varepsilon_{ij}>0;\\
0,75, \text{ kai } \varepsilon_{ij}\leq0.\\

\end{array} \right.
\end{equation}

\indent Parenkama $m=35$ antrojo lygio subjektų ir $n_j=20$ pirmojo, tad patekimo į imtį svoriai yra $w_j=\frac{m}{\pi_j}$, $w_{i|j}=\frac{n_j}{\pi_{i|j}}$ ir $w_{ij}=w_j\times w_{i|j}$.

\indent Atliekama 1500 Monte Carlo simuliacijų kievienam iš metodų. Rezultatai pateikti toliau.


\subsection{Simuliacijų rezultatai}
\indent Šiame skyrelyje pateikiami anksčiau aprašytų Monte Carlo simuliacijų rezultatai. Rezultatai lyginami kaip anksčiau pateiktame skyrelyje. Žemiau esančiose lentelėse pateikti simuliacijų rezultatai visiems metodams.

\subsubsection{Be svorių}
 EQDM grafikai pateikti šio darbo \ref{sec:lenteles} priede. Fiksuotų efektų įverčių lentelėje praktiškai nėra jokio skirtumo tarp metodų. Atsitiktinių efektų parametrų įverčių lentelėje jau matyti nežymūs metodų skirtumai. Akivaizdžiai MINQUE(0) blogiausias $\sigma^2$. REML lyg ir kažkiek geriau $\tau_{01}$, tačiau prasčiau $\tau_{11}$, čia geriausias MINQUE(1). 

\newpage
% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:00:27 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|cc|cc|cc|cc|}
   & & \multicolumn{2}{c|}{REML}&\multicolumn{2}{c|}{MINQUE(0)}&\multicolumn{2}{c|}{MINQUE(1)}&\multicolumn{2}{c|}{MINQUE($\theta$)}\\ \hline
P & V & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & \textbf{0.01} & \textbf{0.128} & 0.031 & \framebox{0.573} & \textbf{0.01} & \textbf{0.13} & \textbf{0.008} & \textbf{0.127} \\ 
   &  & \textbf{0.011} & \textbf{0.118} & \textbf{0.009} & \textbf{0.12} & 0.047 & \framebox{3.299} & \textbf{0.012} & \textbf{0.113} \\ 
   & \multirow{2}{*}{V2} & 0.029 & \textbf{0.282} & 0.046 & 0.395 & 0.029 & \textbf{0.283} & \textbf{0.009} & \textbf{0.298} \\ 
   &  & \textbf{0.025} & \textbf{0.289} & \framebox{0.154} & \framebox{18.062} & \textbf{0.022} & \textbf{0.29} & \textbf{0.021} & \textbf{0.308} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.021} & \framebox{\textbf{0.521}} & \framebox{0.108} & \framebox{6.229} & \textbf{0.021} & \framebox{\textbf{0.521}} & \textbf{0.023} & \framebox{\textbf{0.51}} \\ 
   &  & \framebox{0.076} & \framebox{\textbf{0.512}} & \framebox{0.104} & \framebox{1.618} & \framebox{0.076} & \framebox{\textbf{0.511}} & \textbf{0.026} & \framebox{0.602} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & \textbf{0.012} & \textbf{0.12} & \textbf{0.013} & \textbf{0.122} & \textbf{0.012} & \textbf{0.121} & \textbf{0.013} & \textbf{0.122} \\ 
   &  & \textbf{0.007} & \textbf{0.131} & \textbf{0.005} & \textbf{0.134} & \textbf{0.002} & 0.17 & \textbf{0.007} & \textbf{0.136} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.023} & \textbf{0.267} & \textbf{0.022} & \textbf{0.273} & \textbf{0.023} & \textbf{0.267} & \textbf{0.023} & \textbf{0.268} \\ 
   &  & \textbf{0.01} & \textbf{0.275} & 0.023 & 0.457 & \textbf{0.01} & \textbf{0.275} & \textbf{0.011} & \textbf{0.275} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.009} & \framebox{\textbf{0.565}} & \textbf{0.007} & \framebox{\textbf{0.593}} & \textbf{0.009} & \framebox{\textbf{0.565}} & \textbf{0.009} & \framebox{\textbf{0.565}} \\ 
   &  & \textbf{0.029} & \framebox{\textbf{0.592}} & \framebox{0.138} & \framebox{12.971} & \textbf{0.03} & \framebox{\textbf{0.591}} & \textbf{0.029} & \framebox{\textbf{0.592}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & \textbf{0.006} & \textbf{0.062} & \textbf{0.006} & \textbf{0.062} & \textbf{0.006} & \textbf{0.062} & 0.014 & \textbf{0.065} \\ 
   &  & \textbf{0.012} & \textbf{0.064} & \textbf{0.012} & \textbf{0.064} & \textbf{0.012} & \textbf{0.065} & \textbf{0.013} & \textbf{0.069} \\ 
   & \multirow{2}{*}{V2} & 0.01 & \textbf{0.154} & 0.015 & \textbf{0.166} & 0.01 & \textbf{0.154} & \textbf{0.003} & \textbf{0.17} \\ 
   &  & \textbf{0.007} & \textbf{0.163} & \framebox{0.332} & \framebox{85.974} & \textbf{0.007} & \textbf{0.163} & \textbf{0.006} & \textbf{0.153} \\ 
   & \multirow{2}{*}{V3} & 0.023 & 0.354 & 0.023 & 0.353 & 0.023 & 0.353 & \textbf{0.003} & \textbf{0.312} \\ 
   &  & 0.026 & \textbf{0.298} & \framebox{0.052} & \framebox{0.519} & 0.026 & \textbf{0.298} & \textbf{0.013} & \textbf{0.306} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & \textbf{0.005} & \textbf{0.065} & \textbf{0.004} & \textbf{0.065} & \textbf{0.005} & \textbf{0.065} & \textbf{0.005} & \textbf{0.065} \\ 
   &  & \textbf{0.003} & \textbf{0.062} & \textbf{0.003} & \textbf{0.063} & \textbf{0.003} & \textbf{0.063} & \textbf{0.003} & \textbf{0.063} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.017} & \textbf{0.143} & \textbf{0.016} & \textbf{0.144} & \textbf{0.017} & \textbf{0.143} & \textbf{0.017} & \textbf{0.143} \\ 
   &  & \textbf{0.007} & \textbf{0.159} & \textbf{0.008} & 0.194 & \textbf{0.008} & \textbf{0.159} & \textbf{0.007} & \textbf{0.16} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.013} & \textbf{0.326} & \textbf{0.014} & \textbf{0.328} & \textbf{0.013} & \textbf{0.326} & \textbf{0.013} & \textbf{0.327} \\ 
   &  & \textbf{0.004} & \textbf{0.291} & \textbf{0.009} & 0.442 & \textbf{0.004} & \textbf{0.291} & \textbf{0.004} & \textbf{0.291} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & \textbf{0.003} & \textbf{0.027} & \textbf{0.003} & \textbf{0.027} & \textbf{0.003} & \textbf{0.027} & \textbf{0.005} & \textbf{0.029} \\ 
   &  & \textbf{0.003} & \textbf{0.027} & \textbf{0.003} & \textbf{0.027} & \textbf{0.003} & \textbf{0.028} & \textbf{0.002} & \textbf{0.026} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.007} & \textbf{0.072} & \textbf{0.007} & \textbf{0.072} & \textbf{0.007} & \textbf{0.072} & \textbf{0.008} & \textbf{0.067} \\ 
   &  & \textbf{0.008} & \textbf{0.063} & \framebox{0.051} & \framebox{1.969} & \textbf{0.008} & \textbf{0.063} & \textbf{0.013} & \textbf{0.071} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.009} & \textbf{0.131} & \textbf{0.009} & \textbf{0.132} & \textbf{0.009} & \textbf{0.131} & \textbf{0.004} & \textbf{0.145} \\ 
   &  & \textbf{0.01} & \textbf{0.146} & \textbf{0.007} & \framebox{0.901} & \textbf{0.009} & \textbf{0.146} & \textbf{0.008} & \textbf{0.116} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & \textbf{0.003} & \textbf{0.03} & \textbf{0.003} & \textbf{0.03} & \textbf{0.003} & \textbf{0.03} & \textbf{0.003} & \textbf{0.03} \\ 
   &  & \textbf{0.001} & \textbf{0.027} & \textbf{0.001} & \textbf{0.027} & \textbf{0.001} & \textbf{0.027} & \textbf{0.001} & \textbf{0.027} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.003} & \textbf{0.068} & \textbf{0.003} & \textbf{0.068} & \textbf{0.003} & \textbf{0.068} & \textbf{0.003} & \textbf{0.068} \\ 
   &  & \textbf{0.011} & \textbf{0.065} & \textbf{0.012} & \textbf{0.064} & \textbf{0.011} & \textbf{0.065} & \textbf{0.01} & \textbf{0.065} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.018} & \textbf{0.14} & \textbf{0.018} & \textbf{0.14} & \textbf{0.018} & \textbf{0.14} & \textbf{0.018} & \textbf{0.14} \\ 
   &  & 0.017 & \textbf{0.132} & \textbf{0.01} & 0.386 & 0.017 & \textbf{0.132} & 0.017 & \textbf{0.132} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) fiksuotų efektų įverčių jungtinės statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (CAMRBIAS ir CMRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (CAMRBIAS ir CMRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$.}
\end{sidewaystable}

\newpage 
% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 20:33:12 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|cc|cc|cc|cc|}
   & & \multicolumn{2}{c|}{REML}&\multicolumn{2}{c|}{MINQUE(0)}&\multicolumn{2}{c|}{MINQUE(1)}&\multicolumn{2}{c|}{MINQUE($\theta$)}\\ \hline
P & V & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE & CAMRBIAS & CMRSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & \framebox{0.206} & \framebox{\textbf{1.155}} & \framebox{\textbf{0.064}} & \framebox{1.294} & \framebox{\textbf{0.067}} & \framebox{1.235} & \framebox{0.111} & \framebox{1.4} \\ 
   &  & \framebox{0.254} & \framebox{1.968} & \framebox{\textbf{0.113}} & \framebox{2.387} & \framebox{\textbf{0.114}} & \framebox{1.998} & \framebox{0.121} & \framebox{\textbf{1.907}} \\ 
   & \multirow{2}{*}{V2} & 0.015 & \textbf{0.23} & \textbf{0.011} & 0.308 & 0.017 & \textbf{0.238} & \textbf{0.008} & \textbf{0.212} \\ 
   &  & 0.028 & \framebox{0.767} & 0.024 & \framebox{1.338} & 0.026 & \framebox{0.791} & \textbf{0.008} & \framebox{\textbf{0.71}} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.005} & \textbf{0.16} & 0.011 & 0.255 & \textbf{0.006} & \textbf{0.163} & \textbf{0.005} & \textbf{0.151} \\ 
   &  & 0.023 & \framebox{\textbf{0.625}} & \textbf{0.014} & \framebox{1.047} & 0.025 & \framebox{0.667} & 0.037 & \framebox{0.739} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & \framebox{0.246} & \framebox{\textbf{1.116}} & \framebox{\textbf{0.105}} & \framebox{1.233} & \framebox{0.111} & \framebox{1.2} & \framebox{0.132} & \framebox{1.272} \\ 
   &  & \framebox{0.249} & \framebox{\textbf{2.265}} & \framebox{0.169} & \framebox{2.947} & \framebox{\textbf{0.144}} & \framebox{\textbf{2.267}} & \framebox{0.161} & \framebox{2.485} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.01} & \textbf{0.212} & 0.015 & 0.32 & \textbf{0.007} & \textbf{0.215} & \textbf{0.009} & \textbf{0.214} \\ 
   &  & \textbf{0.014} & \framebox{\textbf{0.8}} & 0.022 & \framebox{1.621} & \textbf{0.015} & \framebox{\textbf{0.826}} & \textbf{0.018} & \framebox{\textbf{0.811}} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.018} & \textbf{0.171} & \textbf{0.014} & 0.249 & \textbf{0.018} & \textbf{0.174} & \textbf{0.019} & \textbf{0.171} \\ 
   &  & 0.029 & \framebox{\textbf{0.778}} & \textbf{0.018} & \framebox{1.19} & \textbf{0.021} & \framebox{\textbf{0.793}} & 0.029 & \framebox{\textbf{0.781}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & \framebox{0.109} & \framebox{\textbf{0.566}} & \textbf{0.026} & \framebox{0.695} & \textbf{0.026} & \framebox{0.666} & \framebox{0.06} & \framebox{0.663} \\ 
   &  & \framebox{0.102} & \framebox{\textbf{0.61}} & 0.035 & \framebox{0.778} & \textbf{0.029} & \framebox{0.703} & \framebox{0.087} & \framebox{1.187} \\ 
   & \multirow{2}{*}{V2} & 0.02 & \textbf{0.118} & \textbf{0.015} & 0.181 & 0.019 & \textbf{0.121} & \textbf{0.01} & \textbf{0.109} \\ 
   &  & 0.019 & \textbf{0.426} & 0.021 & \framebox{0.764} & 0.016 & \textbf{0.435} & \textbf{0.01} & \textbf{0.418} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.015} & \textbf{0.083} & \textbf{0.015} & 0.143 & 0.017 & \textbf{0.086} & \textbf{0.01} & \textbf{0.078} \\ 
   &  & 0.028 & \textbf{0.356} & \textbf{0.023} & \framebox{0.591} & 0.031 & \textbf{0.362} & 0.049 & \framebox{0.505} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & \framebox{0.109} & \framebox{\textbf{0.58}} & \textbf{0.032} & \framebox{0.701} & \textbf{0.032} & \framebox{0.665} & 0.041 & \framebox{0.675} \\ 
   &  & \framebox{0.129} & \framebox{\textbf{0.98}} & \framebox{\textbf{0.085}} & \framebox{1.189} & \framebox{\textbf{0.087}} & \framebox{1.069} & \framebox{0.098} & \framebox{1.081} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.014} & \textbf{0.108} & \textbf{0.014} & 0.151 & \textbf{0.013} & \textbf{0.11} & \textbf{0.015} & \textbf{0.108} \\ 
   &  & \textbf{0.027} & \framebox{\textbf{0.527}} & \textbf{0.025} & \framebox{0.892} & \textbf{0.029} & \framebox{\textbf{0.553}} & \textbf{0.029} & \framebox{\textbf{0.527}} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.003} & \textbf{0.083} & \textbf{0.006} & 0.134 & \textbf{0.003} & \textbf{0.083} & \textbf{0.003} & \textbf{0.083} \\ 
   &  & \textbf{0.012} & \textbf{0.354} & 0.018 & \framebox{0.581} & \textbf{0.014} & \textbf{0.371} & \textbf{0.013} & \textbf{0.356} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & \framebox{0.071} & \textbf{0.279} & 0.042 & 0.344 & 0.037 & 0.314 & \textbf{0.015} & \textbf{0.29} \\ 
   &  & \framebox{0.054} & \textbf{0.425} & 0.016 & \framebox{0.564} & \textbf{0.011} & 0.459 & 0.034 & 0.488 \\ 
   & \multirow{2}{*}{V2} & \textbf{0.004} & \textbf{0.049} & 0.011 & \textbf{0.076} & \textbf{0.005} & \textbf{0.051} & 0.011 & \textbf{0.047} \\ 
   &  & 0.034 & 0.245 & 0.045 & 0.46 & 0.032 & 0.252 & \textbf{0.008} & \textbf{0.195} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.009} & \textbf{0.035} & 0.016 & \textbf{0.057} & \textbf{0.009} & \textbf{0.035} & \textbf{0.005} & \textbf{0.037} \\ 
   &  & \textbf{0.008} & \textbf{0.172} & \textbf{0.009} & 0.287 & \textbf{0.009} & \textbf{0.184} & \textbf{0.007} & \textbf{0.169} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & \framebox{0.056} & \textbf{0.297} & \textbf{0.021} & 0.364 & \textbf{0.025} & 0.331 & 0.027 & 0.331 \\ 
   &  & \framebox{0.06} & \textbf{0.467} & 0.037 & \framebox{0.683} & \textbf{0.021} & \textbf{0.49} & 0.028 & \framebox{0.509} \\ 
   & \multirow{2}{*}{V2} & \textbf{0.002} & \textbf{0.044} & \textbf{0.006} & \textbf{0.067} & \textbf{0.001} & \textbf{0.046} & \textbf{0.003} & \textbf{0.044} \\ 
   &  & \textbf{0.014} & \textbf{0.169} & 0.024 & 0.274 & \textbf{0.012} & \textbf{0.172} & \textbf{0.013} & \textbf{0.169} \\ 
   & \multirow{2}{*}{V3} & \textbf{0.008} & \textbf{0.036} & \textbf{0.012} & \textbf{0.06} & \textbf{0.007} & \textbf{0.037} & \textbf{0.008} & \textbf{0.036} \\ 
   &  & \textbf{0.013} & \textbf{0.161} & \textbf{0.018} & 0.274 & \textbf{0.014} & \textbf{0.161} & \textbf{0.013} & \textbf{0.161} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) atsitiktinių efektų įverčių jungtinės statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (CAMRBIAS ir CMRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (CAMRBIAS ir CMRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}


\subsubsection{Su svoriais}
\indent Šiame skyrelyje pateikti skyrelyje \ref{subsubsec:susvoriais} aprašyto simuliacijų dizaino rezultatai. Jie pateikti \ref{table:wsimul} lentelėje. Šiuo atveju REML ir MINQUE(1) bei MINQUE($\theta$) įverčiai skiriasi labai neženkliai. Šiek tiek didesnį vidutitį santykinį poslinkį ir išsibarstymą turi $\tau_{01}$ ir $\tau_{11}$ įverčiai MINQUE(1) metodu. Mažiausias vidutinis santykinis poslinkis stebimas parametrams $\gamma_{01}$ ir $\gamma_{10}$. Tokio dydžio poslinkį laikome nereikšmingu. Parametrų $\sigma^2$ ir $\tau_{00}$ MRBIAS yra tarp 0,05 ir 0,2, todėl laikomas vidutiniu poslinkiu. Likusių parametrų -- $\gamma_{00}$, $\tau_{01}$ ir $\tau_{11}$ -- poslinkį laikome dideliu. Mažiausias išsibarstymas (MRSE) yra parametrui $\sigma^2$, didžiausias -- $\tau_{01}$. 

\indent Akivaizdžiai parametrų vertintų PWMINQUE poslinkis mažesnis nei nesvertinių metodų. Čia reikėtų pastebėti, jog įverčių išsibarstymas beveik visur didesnis vertinant su PWMINQUE, bet skirtumas nėra didelis palyginus su nauda gauta sumažėjus poslinkiui.    MRBIAS > 0,05 tik $\tau_{00}$ vertintam PWMINQUE(1) ir $\gamma_{00}$ abiems PWMINQUE. $\gamma_{00}$ poslinkis sumažėja, parametras yra pervertinamas, tačiau išsibarstymas mažesnis nei nesvertinių metodų. Šie rezultatai sutampa su gautais  Pfeffermann ir k.t.\cite{pfeff} bei Steele ir k.t.\cite{mlwin} PWIGLS metodui.

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Tue Dec 29 16:27:05 2015
\begin{sidewaystable}[H]
\footnotesize{
\begin{tabular}{|cc|ccc|ccc|ccc|}\cline{3-11}
\multicolumn{2}{c|}{ }&\multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{PWMINQUE(1)}\\ \hline
 Parametras & Tikroji & Vidurkis & MRBIAS & MRSE & Vidurkis & MRBIAS & MRSE & Vidurkis & MRBIAS & MRSE \\ 
  \hline
$\gamma_{00}$ & 1 & 0.781 & -0.219 & 0.063 & 0.782 & -0.218 & 0.063 & 1.165 & 0.165 & 0.048 \\ 
  $\gamma_{01}$ & 1 & 1.001 & 0.001 & 0.029 & 1.003 & 0.003 & 0.03 & 1.000 & 0.000 & 0.032  \\ 
  $\gamma_{10}$ & 1 & 1.002 & 0.002 & 0.018 & 1.005 & 0.005 & 0.018 & 1.001 & 0.001 & 0.025 \\ 
  $\sigma^2$ & 1 & 0.949 & -0.051 & 0.006 & 0.95 & -0.05 & 0.006 & 0.98 & -0.02 & 0.007 \\ 
  $\tau_{00}$ & $\frac{1}{4}$ & 0.221 & -0.115 & 0.086 & 0.221 & -0.115 & 0.091 & 0.264 & 0.054 & 0.113 \\ 
  $\tau_{01}$ & $\frac{\sqrt{3}}{8}\approx 0.217$ & 0.159 & -0.265 & 0.204 & 0.155 & -0.283 & 0.218 & 0.217 & 0.001 & 0.248  \\ 
  $\tau_{11}$ & $\frac{3}{4}$ & 0.583 & -0.223 & 0.1 & 0.574 & -0.235 & 0.108 & 0.746 & -0.005 & 0.112  \\ 
   \hline
\end{tabular}
\begin{tabular}{|cc|ccc|ccc|}\cline{3-8}
  & &\multicolumn{3}{c|}{MINQUE($\theta$)}&\multicolumn{3}{c|}{PWMINQUE($\theta$)}\\ \hline
Parametras & Tikroji &  Vidurkis & MRBIAS & MRSE & Vidurkis & MRBIAS & MRSE \\ 
  \hline
$\gamma_{00}$ & 1 &  0.781 & -0.219 & 0.063 & 1.166 & 0.166 & 0.048 \\ 
  $\gamma_{01}$ & 1 &  1.001 & 0.001 & 0.029 & 1.000 & 0.000 & 0.031 \\ 
  $\gamma_{10}$ & 1 &  1.002 & 0.002 & 0.018 & 1.002 & 0.002 & 0.026 \\ 
  $\sigma^2$ & 1 &  0.948 & -0.052 & 0.006 & 0.973 & -0.027 & 0.007 \\ 
  $\tau_{00}$ & $\frac{1}{4}$ & 0.221 & -0.115 & 0.086 & 0.261 & 0.044 & 0.116 \\ 
  $\tau_{01}$ & $\frac{\sqrt{3}}{8}\approx 0.217$ & 0.159 & -0.266 & 0.204 & 0.217 & 0.003 & 0.232 \\ 
  $\tau_{11}$ & $\frac{3}{4}$ & 0.584 & -0.222 & 0.1 & 0.762 & 0.017 & 0.116 \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:wsimul}) simuliacijų įverčių statistikos. Statistikos pračiau aprašytos skyrelyje \ref{subsubsec:besvoriu}.}
\label{table:wsimul}
\end{sidewaystable}

\newpage
\section{HLM MODELIS TIMSS DUOMENIMS} \label{sec:timss}
\indent Šiame skyriuje trumpai aprašomas TIMSS tyrmas bei hierarchinių tiesinių modelių TIMSS duomenims apžvalga. Atsižvelgiant į \ref{sec:simul} skyriaus rezultatus sudaromas ir įvertinamas modelis Lietuvos TIMSS duomenims.

\subsection{TIMSS tyrimo aprašymas} \label{subsec:timss1}

\indent Tyrimas TIMSS (\textit{angl.Trends in International Mathematics and Science Study}) – tai tarptautinis matematikos ir gamtos mokslų gebėjimų tyrimas. Šį tyrimą inicijuoja IEA (\textit{angl. International Association of the Evaluation of Educational Achievement}) - Tarptautinė švietimo pasiekimų vertinimo asociacija. Tyrime dalyvauja apie 70 pasaulio šalių. IEA vykdo ir kitus švietimo tyrimus: PIRLS, ICCS ir SITES, TEDS-M ir ICILS. TIMSS tyrimas pradėtas 1995 metais ir tęsiamas kas 4 metus. Tiriami ketvirtokų ir aštuntokų matematikos ir gamtos mokslų gebėjimai. Remiamasi tuo, jog tai yra paskutinės pradinės ir pagrindinės mokyklų pakopos. Šiuo metu jau yra įvykdyti 5 tokie tyrimai, paskutinis vyko 2011 metais. Lietuva dalyvavo visuose etapuose. Šiame darbe pasirinkti nagrinėti 2011 metų tyrimo aštuntos klasės Lietuvos duomenys. (Pagal \cite{timss2011lt})

\indent TIMSS tyrimas vykdomas šalies matematiniam raštingumui bei jį lemiantiems veiksniams nustatyti. Sudaromi 28 testo užduočių blokai. Vienam mokiniui skiriamas vienas testo sąsiuvinis, kurį sudaro 4 blokai, po du matematikos ir gamtos mokslų. Sąsiuviniai atrinktiems mokiniams paskirstomi pagal iš anksto numatytą tvarką (neatsitiktinai). Mokinys testą turi atlikti per tam tikrą laiką ir gali nespėti atlikti visų užduočių. Norėdama įvertinti bendrą rezultatą, TIMSS komanda sudaro matematinio testo rezultatus pagal moderniąją testų teoriją, apie tai plačiau galima rasti 1995 metų TIMSS vartotojo vadovo \cite{timss1995} 5 skyriuje. Kad rezultatai būtų palyginami, jie yra pernuormuojami taip, kad bendras visų tiriamųjų rezultatų vidurkis būtų 500, o standartinis nuokrypis 100. Kartu yra renkama informacija apie mokinį, jo klasę ir mokyklą. Kiekvienas lygmuo gauna po klausimyną, kurį užpildo. (Pagal \cite{timss2011lt})

\indent TIMSS tyrimas vykdomas ne visai populiacijai, o atrinktai jos daliai (imčiai). TIMSS imtys yra dviejų pakopų sluoksninės lizdinės imtys, kur pirmos pakopos elementai išrenkami su tikimybėmis proporcingomis dydžiui, o antros pakopos elementai išrenkami su lygiomis tikimybėmis. Pirmoje pakopoje išrenkamos mokyklos pagal aštuntokų skaičių mokykloje. Antroje pakopoje su lygiomis tikimybėmis parenkamos klasės. Išrinktoje klasėje apklausiami visi jos mokiniai. Stengiamasi imtį sudaryti taip, kad ji kuo labiau atspindėtų populiaciją. Daugiau apie tai TIMSS internetinėje nuorodoje \cite{2011Sample}. Dėl nelygių patekimo į imtį tikimybių sudaromi kiekvieno mokinio bei mokyklos svoriai, kurie vėliau naudojami tyrimuose.

\indent Kiekviena šalis sudaro imtį pagal savo poreikius ir TIMSS standartus. Lietuvoje mokyklų lizdai sudaromi pagal mokyklos vietovę (t.y. didmiestis, miestelis ar kaimas ir pan.), o paskui skirstoma pagal mokyklos tipą (t.y. pagrindinė, vidurinė ar gimnazija). Tuomet iš kiekvieno lizdo imama negrąžintinė imtis su tikimybėmis proporcingomis aštuntokų skaičiui mokykloje. Tegu turime $H$ lizdų. Tuomet mokyklos svoriai $h$-tajame lizde ($h=1,\dots,H$) gaunami pagal:
\begin{equation}
W^{sc}_{hj} = \frac{M_h}{m_{hj}n_h}; M_h=\sum^{N_h}_{j=1} m_{hj},
\end{equation}
kur $M_h$ - bendras aštuntokų skaičius $h$-tajame lizde, $m_{hj}$ - aštuntokų skaičius $j$-tojoje $h$-tojo lizdo mokykloje, $n_h$ - mokyklų, parinktų iš $h$-tojo lizdo skaičius ir $N_h$ - mokyklų skaičius $h$-tajame lizde. Iš kiekvienos parinktos mokyklos, atitinkamai pagal jos dydį, parenkamos klasės su lygiomis tikimybėmis. Klasės svoriai gaunami:
\begin{equation}
W^{cl}_{k|hj} = \frac{C_{hj}}{c_{hj}},
\end{equation}
čia $C_{hj}$ - klasių skaičius $j$-tojoje mokykloje, $c_{hj}$ - parinktų klasių skaičius $j$-tojoje mokykloje. Parinktose klasėse apklausiami visi mokiniai, todėl sąlyginis svoris yra $W^{st}_{i|hjk} = 1$. Galiausiai sudaromas bendras kiekvieno parinkto mokinio svoris:
\begin{equation}
W^{st}_{ikjh} = W^{sc}_{hj}\times W^{cl}_{k|hj}\times W^{st}_{i|hjk}.
\end{equation}
Čia pateikti svoriai nėra visiškai tikslūs, nes dar taikomi nedalyvavimo korekcijos faktoriai. Tačiau apie tai plačiau galima rasti \cite{2011Sample}.

\subsection{TIMSS tyrimų apžvalga}
TIMSS duomenys labai plačiai naudojami lyginamajai (bei kitoms) analizei atlikti. Kiekviena TIMSS tyrimo šalis turi instituciją, kuri atsakinga už ataskaitų paruošimą. Lietuvoje tai atlieka \textit{Nacionalinis egzaminų centras} (\textit{NEC}). Taip pat ir IEA organizcija išleidžia keletą leidinių, kuriuose galima rasti pagrindines ir platesnes TIMSS rezultatų statistikas bei išvadas. Visa informacija patalpinta oficialiame TIMSS tinklapyje (\url{http://timss.bc.edu}).

\indent Dažniausiai HLM modeliai TIMSS duomenims sudaromi, nustatyti mokyklos, mokytojo ar klasės bei mokinio aplinkos įtaką mokinio pasiekimams (pvz.: Fullarton \cite{timssSch1}, Chen \cite{timssSchool2} arba Afana ir Lietz \cite{timssCpalyg1}). Taip pat sudaromi modeliai kelioms šalims ar regionams palyginti (pvz.: Gustafsson \cite{timssCpalyg}, Kim ir kitų \cite{timssCpalyg2}, Phan ir kitų \cite{timssCpalyg3} arba Wiberb ir Andersson \cite{timssCpalyg4}). Buvo atlikta analizė net šalių lygio mastu (pvz.: Kyriakides ir Charalambous \cite{countryHLM}). Analizuota šalių politikos įtaka mokinio matematikos pasiekimams (Stidd \cite{timssPol}).

\indent HLM modeliai Lietuvos duomenims nebuvo labai plačiai kurti. Dažniausiai Lietuvos TIMSS duomenys modeliuoti bendrai su kitomis šalimis ar regionais kaip Akyuz ir Berberoglu \cite{2007All}. Autoriai sudarė modelį 1999 metų TIMSS tyrimo duomenims. Jų tikslas buvo palyginti Turkijos ir Europos sąjungos šalių mokytojo ir klasės įtaką mokinio matematinio raštingumo rezultatams. Buvo sudarytas bendras modelis visoms jų nagrinėjamoms šalims su vienu mokinio lygio aiškinančiuoju kintamuoju, tačiau į modelį buvo įtrauktas ir atsitiktinis posvyris. Deja, Lietuvos atveju atsitiktinis posvyris nebuvo įtrauktas. Žemiau pateikta minimo modelio išraiška:
\[ \left\{
\begin{array}{l}
Y_{ij} = \beta_{0j}+\beta_{1j}\ X_{ij}+\varepsilon_{ij}; \\
\beta_{0j} = \gamma_{00} + \gamma_{01} W_{1j}+\dots+\gamma_{0m} W_{mj}+u_{0j};\\
\beta_{1j} = \gamma_{10} + u_{1j};
\end{array} \right.
\]
\small
čia $i$ - žymi $i$-tajį mokinį,\\
$j$ - $j$-tają mokyklą/klasę/mokytoją,\\
$Y_{ij}$ - $i$-tojo mokinio iš $j$-tosios mokyklos/klasės/mokytojo matematinio raštingumo rezultatas,\\
$\beta_{0j}$ - $j$-tosios mokyklos/klasės/mokytojo įnašas,\\
$\beta_{1j}$ - atsitiktinis posvyris,\\
$X_{ij}$ - pirmo lygio kintamasis, šiuo atveju, namų edukaciniai ištekliai, \\
$\varepsilon_{ij}$ - pirmo lygio paklaidos,\\
$\gamma_{00}$ - vidutinis mokyklų/klasių/ mokytojų įnašas,\\
$\gamma_{01}$ - vidutinis mokyklų/klasių/ mokytojų nuolydis,\\
$W_{mj}$ - antro lygio kintamasis, \\
$u_{0j}$ - atsitiktinis efektas,\\
$u_{1j}$ - atsitiktinis efektas.\\
Šis modelis vertintas su \textit{HLM6} programa visoms 5 galimoms matematinio raštingumo reikšmėms ir su imties svoriais.\\
\indent Kitas pavyzdys, modelis sudarytas Robitaille ir Beaton \cite{timssLiet} 1995 metų TIMSS duomenims. Autoriai sudarė net trijų lygių modelį su atsitiktiniais postūmiais. Kaip antro ir trečio lygio kintamieji buvo naudoti suvidurkinti (atitinkamai pagal klases ir pagal mokyklas) mokinio lygio kintamieji. Čia vietoje anksčiau minėto modelio namų mokymosi išteklių imti atskiri kategoriniai kintamieji - tėvų išsilavinimas, mokinio turimi mokymosi reikmenys ir jo užklasinė veikla. Tačiau atsitiktiniai posvyriai neįtraukti, be to, nagrinėta visa šalių grupė, o ne atskiros šalys. Modeliai vertinti taip pat su \textit{HLM6} programa visoms 5 galimoms matematinio raštingumo reikšmėms ir su imties svoriais.

\indent Lietuvoje Lietuvos TIMSS duomenims sudarytų HLM modelių beveik nerasta. Galbūt dėl to, jog tokie modeliai sudaromi studijų baigiamuosiuose darbuose, kurie nėra viešinami. Vienintelis darbas, kuriame sudaromi HLM modeliai Lietuvos TIMSS duomenims, kurį pavyko gauti, tai Dudaitės daktaro laipsnio disertacija \cite{liet2003}. Savo darbe Dudaitė plačiai nagrinėja 1995, 1999 ir 2003 metų TIMSS tyrimo duomenis įvairiais aspektais, tačiau pagrindinis tikslas - nustatyti matematinio raštingumo kaitą, keičiantis Lietuvos mokymo aplinkai. HLM modeliai sudaryti 2003 metų duomenims ir tik su mažu kintamųjų kiekiu. Galima sakyti, jog beveik kiekvienam aiškinančiajam kintamajam sudarytas atskiras modelis. Modelio pavyzdys:
\begin{small}
\[
\left\{
\begin{array}{l l}
Y_{ij} = \beta_{0j}+\varepsilon_{ij}; \\
\beta_{0j} = \gamma_{00} + \sum^Q_{q=1}\gamma_{0q}W_{qj}+u_{0j};
\end{array} \right.
\text{arba}\
\left\{
\begin{array}{l l}
Y_{ij} = \beta_{0j}+\sum^P_{p=1}\beta_{pj}X_{pij}+\varepsilon_{ij}; \\
\beta_{0j} = \gamma_{00} + u_{0j};\\
\beta_{pj} = \gamma_{p0}; \ \forall q=1,\dots,P.
\end{array} \right.
\]
čia $i$ - žymi $i$-tajį mokinį,\\
$j$ - $j$-tają mokyklą/klasę/mokytoją,\\
$Y_{ij}$ - $i$-tojo mokinio iš $j$-tosios mokyklos/klasės/mokytojo matematinio raštingumo rezultatas,\\
$\beta_{0j}$ - $j$-tosios mokyklos/klasės/mokytojo įnašas,\\
$\varepsilon_{ij}$ - pirmo lygio paklaidos,\\
$\gamma_{00}$ - vidutinis mokyklų/klasių/ mokytojų įnašas,\\
$\gamma_{01}$ - vidutinis mokyklų/klasių/ mokytojų posvyris,\\
$X_{pij}$ - $p$ - tasis $i$ - tojo mokinio aiškinamasis kintamasis,\\
$W_{qj}$ - antro lygio kintamasis, \\
$u_{0j}$ - antro lygio paklaidos.
\end{small}

\indent Pasak autorės, platesnių modelių sudaryti nepavyko. Šio magistro darbo autorė įžvelgia dvi galimas priežastis. Pirmoji - modeliams vertinti buvo naudotasi specialiu HLM modelių vertinimo paketu \textit{HLM6}, ši programa mokama, tačiau akademinei visuomenei suteikiama nemokama versija, kuri vertina tik labai mažos apimties modelius. Antra - TIMSS duomenys (aiškinantieji kintamieji) yra labai koreliuoti, pavyzdžiui mokyklos vietovė ir mokyklos mokinių finansinė padėtis arba mokyklos dydis. Todėl norint pažiūrėti kiekvieno iš tokių kintamųjų įtaką, juos reiktų modeliuoti atskirai.

\subsection{TIMSS duomenys} \label{subsec:duom}
\indent Šiame skyrelyje pateikti modeliavime naudoti duomenys. Magistro darbe nagrinėjami 2011 metų Lietuvos duomenys, kurie pateikti oficialiame TIMSS tinklapyje (\url{http://timss.bc.edu}). Pavadinimai: BCGLTUM5 - mokyklos failas, BSGLTUM5 - mokinių failas, BSTLTUM5 - mokytojų ir mokinių ryšių failas ir BTMLTUM5 - matematikos mokytojų failas. Nors pateiktos visos 5 galimos mokinio testo atlikimo reikšmės, toliau analizėje bus naudojama tik pirmoji - BSMMAT01. Lentelėje \ref{table:duom} pateiktas originalus kintamojo pavadinamas, jo aprašymas bei pavadinimas naudojamas šiame darbe. Kai kurie kategoriniai kintamieji per ranguoti, o indeksai centruoti mokyklos vidurkiu bei suvidurkinti kiekvienai mokyklai. Simbolis "*" reiškia, jog kintamasis modifikuotas ir nuo originalaus skiriasi. Atliekant vidurkinimą naudoti svoriai. Mokyklos, klasės ir mokiniai identifikuojami pagal IDSCHOOL, IDCLASS ir IDSTUD atitinkamai. Mokyklos, klasės ir mokinio svoriai pateikti kaip WGTFAC3, WGTFAC2 ir WGTFAC1. Taip pat pateikiami ir neatsakymo į klausymus koregavimo faktoriai WGTADJ3, WGTADJ2 ir WGTADJ1. Toliau naudojamų pavadinimų pradžioje pridėta raidė C reiškia, jog kintamasis centruotas pagal mokyklą, o M - mokyklos vidurkis. Centruojant buvo naudoti imties svoriai.

\begin{small}
\begin{longtable}{| p{2,6cm} | p{5cm} | p{5cm} | p{2,5cm} |}
% \begin{tabular}{| p{2,5cm} | p{5cm} | p{5cm} | p{2,5cm} |}
\hline
Trumpinys & Aprašymas & Tipas/Skalė & Originalus pavadinimas \\ \hline
\multicolumn{4}{|c|}{Mokinio lygio kintamieji} \\
\hline
MatRes & Mokinio matematinio raštingumo testo rezultatas & Tolydus kintamasis, originalus & BSMMAT01\\ \hline
\multirow{2}{*}{SSEX*} & \multirow{2}{*}{Mokinio lytis} & 0 - Mergaitė; & \multirow{2}{*}{BSBG01}\\
& & 1 - Berniukas. & \\ \hline
\multirow{2}{*}{STHMWRK*} & Mokinio skiriamas laikas & 0 - 45 min ir mažiau; & \multirow{2}{*}{BSDMWKHW}\\
& namų darbams & 1 - daugiau nei 45 min. & \\ \hline
SMENG & Mokinio įsitraukimas į matematikos pamokas & Indeksas. Didesnė reikšmė - stipresnis įsitraukimas. & BSBGEML\\ \hline
SMCONF & Mokinio pasitikėjimas savimi atliekant matematikos užduotis & Indeksas. Didesnė reikšmė - stipresnis pasitikėjimas. & BSBGSCM\\ \hline
SMVALUE & Mokinys vertina matematikos žinias (pvz.: jos jam padės gauti trokštamą darbą) & Indeksas. Didesnė reikšmė - stipresnis vertinimas. & BSBGSVM\\ \hline
SMLIKE & Mokiniui patinka mokytis matematiką & Indeksas. Didesnė reikšmė - mėgsta labiau. &BSBGSLM\\ \hline
SBULLED & Mokinys yra engiamas mokykloje & Indeksas. Didesnė reikšmė - skriaudžiamas dažniau. &BSBGSBS\\ \hline
SHEDRES & Mokinio namų mokymosi ištekliai. Anksčiau vadinta namų socioekonominiu statusu. Įeina tėvų išsilavinimas, ar mokinys turi kompiuterį ir atskirą kambarį. & Indeksas. Didesnė reikšmė - daugiau išteklių. &BSBGHER\\ \hline
\multicolumn{4}{|c|}{Mokyklos lygio kintamieji} \\
\hline
MDYDIS & Mokyklos mokinių skaičius & Natūralusis skaičius. & BCBG01\\ \hline
MSUCCESS & Mokytojų teigimu mokykla skiria dėmesį akademinei sėkmei. & Indeksas. Didesnė reikšmė - labiau tiki. &BCBGEAS\\ \hline
MSUDET* & Mokyklos mokinių sudėtis & 1 - Daugiau vargšų; & \multirow{3}{*}{BCDG03}\\
MSUDET.1-3 & pagal finansinę padėtį & 2 - Apylygiai; & \\
& & 3 - Daugiau turtuolių. & \\ \hline
MDISSAFE & Saugi ir disciplinuota mokykla. & Indeksas. Didesnė reikšmė - daugiau saugumo ir disciplinos. &BCBGDAS\\ \hline
MINSTRHWR & Valandos, skiriamos instruktažui mokykloje per metus. & Valandos. &BCDG06HY\\ \hline
MMATSHORT & Mokytojai skundžiasi mokymo išteklių trūkumu. & Indeksas. Didesnė reikšmė - daugiau skundžiasi. &BCBGMRS\\ \hline
MAINCOME* & Mokyklos aplinkos pajamų & 1 - Žemas; & \multirow{3}{*}{BCBG05C}\\
MAINCOME.1& dydis. & 2 - Vidutinis; & \\
-3& & 3 - Aukštas. & \\ \hline
MVIETA* & Mokyklos vietovė. & 1 - Atokesnis kaimas; & \multirow{5}{*}{BCBG05B}\\
MVIETA.1-5& & 2 - Mažas miestelis; & \\
& & 3 - Vidutinis miestas; & \\
& & 4 - Didmiestis; & \\
& & 5 - Vilnius, & \\ \hline
MKITKALB* & Kitakalbių dalis & 1 - 10\% ir mažiau; & \multirow{3}{*}{BCBG05C}\\
MKITKALB.1& mokykloje. & 2 - 10\% - 50\%; & \\
-3& & 3 - daugiau nei 50\%. & \\ \hline
\caption{Magistro darbe naudotų TIMSS duomenų detalizavimas}
\label{table:duom}
\end{longtable}
\end{small}


\subsection{HLM modelis 2011 metų TIMSS duomenims}

\indent Šiame skyrelyje pateikiama detalesnė turimų ir nagrinėjamų TIMSS duomenų analizė, sudaromas nulinis modelis bei pateikiamas galutinis modelis ir jo statistikos. Nulinio ir galutinio modelio įverčiai pateikiami įvertinti visais nagrinėjamais metodais. Galiausiai aptariami rezultatai ir padaromos išvados.

\indent Pirmiausia, domina aiškinamasis kintamasis - matematinio raštingumo testo rezultatai. Kaip jau buvo minėta, TIMSS pateikia 5 galimas testo atlikimo reikšmes, tačiau šiame darbe naudojama tik viena - pirmoji. ???Taip daroma, dėl skaičiavimų sudėtingumo (tai nėra implementuota R statistinės analizės pakete) ir dėl to, jog vėliau rezultatus galima pritaikyti ir likusioms galimoms testo atlikimo reikšmėms. 
???Lieka klausimas, ar galime laikyti aiškinamąjį kintamąjį pasiskirsčiusiu pagal normalųjį skirstinį. Paveikslėlyje \ref{fig:y} pateiktas pirmosios galimos matematinio raštingumo testo atlikimo reikšmės teorinių kvantilių grafikas. Jame galime įžvelgti, jog turime sunkias uodegas. Aiškinančiajam kintamajam buvo atliktas Shapiro-Wilk normalumo testas. Gauta testo statistika $W = 0.9977$ ir $\text{p-value}<0,01$. Todėl hipotezė apie aiškinamojo kintamojo pasiskirstymą pagal normalųjį skirstinį atmetama.

\begin{figure}[H]
\centering
\includegraphics[height=7cm]{teorkv.pdf}
\caption{Mokinio matematinio raštingumo pirmos galimos testo atlikimo reikšmės teorinių kvantilių grafikas.}
\label{fig:y}
\end{figure}

\indent Aiškinantieji kintamieji šiame darbe negali būti laikomi pasiskirstę pagal normalųjį skirstinį, tačiau kategoriniai kintamieji nėra modeliuojami. Dudaitė savo daktaro disertacijoje \cite{liet2003} ne tik sudarinėjo labai menkus modelius, bet ir naudojo kategorinius kintamuosius (kurie įgyja iki 5 reikšmių) kaip regresorius. Šiame darbe kategoriniai kintamieji išskaidyti į fiktyvius kintamuosius. Tokių yra du mokinio lygyje ir keturi mokyklos lygyje. Pačiuose pateiktuose TIMSS duomenyse kategoriniai kintamieji suvesti į indeksus, kurie įgyja daugiau nei 5 reikšmes. Nors jie ir negali būti laikomi pasiskirstę pagal normalųjį dėsnį, modeliuojant nėra stipriai nusižengiama. Šeši indeksai yra imami kaip mokinio lygio aiškinantieji kintamieji ir 3 mokyklos lygio kintamieji. Detalesni kintamųjų aprašymai pateikti \ref{table:duom} lentelėje \ref{subsec:duom} skyrelyje. Modeliuoti ir suvidurkinti mokytojo bei klasės kintamieji, tačiau jie nepasirodė statistiškai reikšmingi, todėl apie šiuos kintamuosius šiame darbe nepasakojama.

\indent ??? HLM modelio sudarymas yra sudėtingas procesas. Kad modeliai būtų palyginami, jie turi būti sudaryti tiems patiems duomenims. Čia susiduriama su problema, jog TIMSS duomenys turi daug neatsakytų reikšmių, t.y. trūkstamų duomenų. Modeliuojant atsižvelgiama ne tik į tai, kiek kintamasis paaiškina dispersijos, bet ir į tai, ar jis neturi daug praleistų reikšmių. Šiame darbe modeliai sudaryti įtraukiant po vieną pirmo po to antro lygio kintamąjį ir lyginant su nuliniu ir prieš tai gautu modeliais, kiekvieną kartą perskaičiuojant pašalinus mokinį ar mokyklą su trūkstamais duomenimis. Gavus galutinį modelį, visi modelių įverčiai buvo pervertinti jau galutiniam duomenų kiekiui. Taip išvengiama per didelio duomenų pašalinimo pirmame etape. Modeliai parinkti vadovaujantis logika ir \ref{subsec:parink} skyrelyje pateiktais kriterijais. Toliau bus pateikti tik nulinis ir galutinis modeliai, o tarpiniai modeliai praleisti.

\indent Pagrindines 2011 metų TIMSS tyrimo suvestines galima rasti jau minėtoje Nacionalinio egzaminų cento ataskaitoje \cite{timss2011lt}. Todėl šiame darbe bus pateikti trumpi rezultatai po duomenų pašalinimo. Pašalinus mokyklas ir mokinius su trūkstamais duomenimis iš 141 tyrime dalyvavusios mokyklos liko 128 mokyklos, o iš 4747 mokinių liko 4167 mokiniai. Tai optimalus skaičius siekiant paaiškinti kuo daugiau kaitos su kuo mažesniu mokinių praradimu. Svertinis pirmos galimos matematinio raštingumo reikšmės vidurkis likusiems duomenims yra 504,57. Toliau pateikiama nulinio modelio išraiška ir gauti įverčiai.

\subparagraph{Nulinis modelis} aprašytas \ref{subsec:parink} skyrelyje sudarytas jau mažesnės apimties duomenims. Pakartota (\ref{eq:null}) modelio išraiška:
\begin{equation}
\left\{
\begin{array}{l}
\begin{split}
MatRes_{ij}&=\beta_{0j}+\varepsilon_{ij}, &\ \varepsilon_{ij}\sim (0, \sigma^2);\\
\beta_{0j}&=\gamma_{00}+u_{0j}, &\ u_{0j}\sim (0, \tau_{00}).
\end{split}
\end{array} \right.
\end{equation}
Tegul $Y_{ij}$ žymi $i$ - tojo mokinio iš $j$ - tosios mokyklos matematinio raštingumo testo rezultato pirmąją galimą reikšmę. Jungtinė modelio lygtis:
\[
MatRes_{ij}=\gamma_{00}+u_{0j}+\varepsilon_{ij}.
\]
\indent Šis modelis įvertintas REML, MINQUE(1), PWMINQUE(1), MINQUE($\theta$) ir PWMINQUE($\theta$) metodais. Rezutatai pateikti  \ref{table:null} lentelėje. 
Šio modelio $ICC \approx 0,15-0,2$. Tai rodo, jog apie 15\% -- 20\% mokinių rezutatų skirtumų lemia mokyklos. $DEFF$ yra labai aukštas visiems metodams, mažiausias PWMINQUE(1). Skyrelyje \ref{subsec:parink} minėta $R^2_1$ statistika yra apie 0,22 visais metodais. Čia reikėtų paminėti, jog PWMINQUE $R^2_1$ statistika skaičiuota $\bar{Y}$ keičiant į svertinį visos populiacijos vidurkį $\bar{Y}^*$.

\begin{small}
\begin{table}[H]

\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Parametras & REML & MINQUE(1) & PWMINQUE(1) & MINQUE($\theta$) & PWMINQUE($\theta$)\\
\hline
$\gamma_{00}$ &504.716 & 504.725 &491.867&504.716&491.689\\
$\sigma^2$ &4531.861& 4532.587 &4729.870&4531.806&4712.876 \\
$\tau_{00}$&1165.505& 1153.184 &852.302&1166.006&1006.284\\
\hline
$ICC$ & 0.205 & 0.203 & 0.153 & 0.205 & 0.176\\
$DEFF$ & 7.455& 7.399 & 5.818 &  7.457 & 6.552\\
$R_1^2$ & 0.223  & 0.223  & 0.224 & 0.223& 0.225\\
\hline
\end{tabular}
\caption{Nulinio modelio parametų įverčiai ir statistikos.}
\label{table:null}
\end{table}
\end{small}

\subparagraph{Galutinis modelis} sudarytas atsižvelgiant į kintamųjų multikoliniarumą, pasitelkiant logiką bei skyrelyje \ref{subsec:parink} pateiktus indeksus ir statistikas. Mokinio lygio kintamieji - indeksai SMCONF, SMLIKE, SMVALUE ir SMENG - sudaryti iš skirtingų mokinio klausimyno klausimų, tačiau tarpusavyje labai susiję. Į modelį įtraukus visus kintamuosius, koeficientų įverčiai prie šių kintamųjų tampa nebe paaiškinami. Atsižvelgiant į tai jog SMCONF paaiškino labai daug (apie 1000) pirmo lygio dispersijos, tik šis kintamasis buvo įtrauktas į galutinį modelį.

\indent Panaši situacija ir su mokyklos lygio fiktyviais kintamaisiais. Tad į galutinį modelį įtraukti tik keli iš jų. Galutinio modelio išraiška pateikta toliau:
\begin{small}
\begin{equation} \label{eq:timss2}
\left\{
\begin{array}{l}
\begin{split}
MatRes_{ij}&=\beta_{0j}+\beta_{1j}\times SSEX_{ij}+\beta_{2j} \times STHMWRK_{ij}+\beta_{3j}\times CSMCONF_{ij}+\\
&+\beta_{4j}\times CSHEDRES_{ij}+\varepsilon_{ij};\\
\beta_{0j}&=\gamma_{00}+\gamma_{01}\times MVIETA.2_j+\gamma_{02}\times MSUCCESS_j+\gamma_{03}\times MDYDIS_j+u_{0j};\\
\beta_{1j}& = \gamma_{10};\\
\beta_{2j}&=\gamma_{20};\\
\beta_{3j}&=\gamma_{30}+u_{3j};\\
\beta_{4j}&=\gamma_{40}.\\
\end{split}
\end{array} \right.
\end{equation}
\end{small}
Jungtinė \ref{eq:timss2} modelio lygtis yra:
\begin{small}
\begin{equation} \label{eq:timss3}
\begin{split}
MatRes_{ij}&=\gamma_{00}+\gamma_{01}\times MVIETA.2_j+\gamma_{02}\times MSUCCESS_j+\gamma_{03}\times MDYDIS_j+\\
&+ \gamma_{10}\times SSEX_{ij}+\gamma_{20} \times STHMWRK_{ij}+\gamma_{30}\times CSMCONF_{ij}+\\
&+ \gamma_{40}\times CSHEDRES_{ij}+u_{0j}+u_{3j}\times  CSMCONF_{ij} +\varepsilon_{ij}.
\end{split}
\end{equation}
\end{small}

\indent Modelis įvertintas visais aukščiau išvardintais metodais. Gauti parametrų įverčiai pateikti \ref{table:final} lentelėje. Prie fiksuotų koeficientų surašyti juos atitinkantys kintamieji, kad būtų paprasčiau atsirinkti ir interpretuoti įverčius. Įverčiai drastiškai nesiskiria, išskyrus  PWMINQUE(1) metodu gautus įverčius. Kaip jau buvo minėta, MINQUE metodas nėra apsaugotas nuo neigiamų atsitiktinių efektų kovariacijos matricos elementų įverčių. Šioje vietoje tai ir pastebime,  $\hat{\tau_{11}}^{PWMINQUE(1)}= -12.328$. Nors $\hat{\tau_{11}}^{MINQUE(1)}= 1.053$, atsitiktinių efektų kovariacijų matrica gaunama neigiamai apibrėžta. Taip nutiko, nes skirtumas tarp $\hat{\tau_{11}}$ ir $\hat{\sigma}^2$ labai didelis, o priskiriamos vienodos \textit{a priori} reikšmės.

\indent Palyginus su nulinio modelio įverčiais, $\hat{\sigma}^2$ ir $\hat{\tau_{00}}$ galutinio modelio įverčiai ženkliai mažesni, tai reikškia, jog įtraukti kintamieji paaiškina nemažai mokinių matematikos rezultatų kintamumo. Mažiausias $\hat{\tau_{00}}=704.666$ gautas PWMINQUE($\theta$) metodu. Kaip ir buvo galima tikėtis, REML ir MINQUE($\theta$) panašūs.

\begin{small}
\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|}
\hline
Parametras & REML & MINQUE(1) & PWMINQUE(1) & MINQUE($\theta$) & PWMINQUE($\theta$)\\
\hline
$\gamma_{00}$ & 471.913 & 481.680 & 399.091 & 471.271 & 444.265 \\ 
$\gamma_{01}$ {\footnotesize  (MVIETA.2)}& -27.960 & -29.294 & -80.377 & -27.889 & -26.661 \\ 
$\gamma_{02}$ {\footnotesize (MSUCCESS)} & 1.916 & 1.134 & 16.545 & 1.965 & 5.120 \\ 
$\gamma_{03}$  {\footnotesize(MDYDIS)}& 0.018 & 0.015 & -0.063 & 0.018 & 0.006 \\ 
$\gamma_{10}$ {\footnotesize (SSEX)} & 11.112 & 11.090 & 11.903 & 11.112 & 13.061 \\ 
$\gamma_{20}$  {\footnotesize(STHMWRK)}& 6.539 & 6.521 & -8.669 & 6.533 & 4.518 \\ 
$\gamma_{30}$  {\footnotesize(CSMCONF)}& 18.579 & 18.551 & 21.220 & 18.580 & 19.102 \\ 
$\gamma_{40}$  {\footnotesize(CSHEDRES)}& 9.518 & 9.328 & 11.168 & 9.525 & 10.951 \\ 
$\sigma^2$ &2843.308 & 2842.028 & 2858.521 & 2843.560 & 2890.473 \\
$\tau_{00}$ & 946.783 & 998.554 & 853.321 & 928.238 & 704.666 \\ 
$\tau_{01}$ & -92.772 & -82.178 & -141.233 & -91.622 & -106.479 \\ 
$\tau_{11}$ & 21.711 & 1.053 & -12.328 & 22.754 & 25.003 \\
\hline
$R_1^2$ & 0.516 & 0.504 & -12.251 & 0.517 & 0.515\\
\hline
\end{tabular}
\caption{Lentelėje pateikti modelio  \ref{eq:timss2} parametrų įverčiai bei statistikos $R_1^2$.}
\label{table:final}
\end{table}
\end{small}


\section{???IŠVADOS}
\indent Pagrindiniai šio magistro darbo rezultatai:
\begin{itemize}
\item Parašytos $\R$ funkcijos MINQUE su saviranka metodui, kuris skirtas HLM modelių parametrų bei jų pasikliautinių intervalų vertinimui.
\item Atliktos empirinės simuliacijos, kurios parodė, jog Delphish tirtas MINQUE metodas su saviranka nėra geresnis nei REML metodas su saviranka. Tikslesni pasikliautiniai intervalai savirankos būdu gaunami ir turint duomenis pasiskirsčiusius pagal normalųjį skirstinį, ir pagal Puasono (ar bet kokį kitą ???) skirstinį. To priežastys gali būti tai, jog Delpish netyrė REML su saviranka arba šiame darbe pristatytas MINQUE metodas nėra tapatus Bagaka's ir Delphish metodui.

\item Sudarytas sudėtingesnis hierarchinis tiesinis modelis (nei anksčiau buvę) Lietuvos matematinio raštingumo testo rezultatams.
\end{itemize}

\indent Tolimesnis tyrimas galėtų apimti daugiau metodų fiksuotiems ir atsitiktiniams efektams vertinti (pvz.: Hamilton'o III metodas). Sudėtingesni neparametrinės savirankos metodai taip pat galėtų pagerinti įvertinių tikslumą.


\newpage

 \renewcommand\refname{LITERATŪRA IR ŠALTINIAI}
\addcontentsline{toc}{section}{LITERATŪRA IR ŠALTINIAI}
\begin{thebibliography}{1}
\bibitem{achen} Achen, C., H., \textit{Two-Step Hierarchical Estimation: Beyond Regression Analysis},  Political Analysis (Autumn 2005) 13 (4): 447-456.
\bibitem{timssCpalyg1} Afana, Y., Lietz, P., \textit{The relationship between school resources and mathematics achievement at grade 8: A comparison of Israeli and Palestinian schools in TIMSS 2007}, Journal for Educational Research Online 5.1, 2013, 59-89.
\bibitem{2007All} Akyuz, G., Berberoglu, G., \textit{Teacher and Classroom Characteristics and Their Relations to Mathematics Achievement of the Students in the TIMSS}, New Horizons in Education, 2010.
\bibitem{bagaka} Bagaka's, J. G., \textit{Two level nested hierarchical linear model with random intercepts via the bootstrap}, Unpublished doctoral dissertation, Michigan State University, 1992.
\bibitem{MLtests} Berkhof, J., Snijders, T. A., \textit{Variance Component Testing in Multilevel Models}, Journal of Educational and Behavioral Statistics, Summer 2001, Vol. 26, Nr. 2, 133-152.
\bibitem{siaip1} Birenbaum, M., Tatsuoka, C., Yamada, T., \textit{Diagnostic Assesment in TIMSS-R: Comparison of Eight Graders Mathematics Knowladge States in The United States, Japan, Israel}, IRC, 2004.
\bibitem{siaip2} Brečuko, B., \textit{How Family Background Influences Student Achievement}, IRC, 2004.
\bibitem{siaip3} Campbell, J., Verna, M., Petruso, S., \textit{Gender Paradigms}, IRC, 2004.
\bibitem{cek} V. Čekanavičius, G. Murauskas, \textit{Statistika ir jos taikymai}, 3 dalis, TEV, 2009.
\bibitem{timssSchool2} Chen, Q., \textit{A Multilevel Analysis of Mathematically Low-Achieving Students in Singapore}, IRC, 2013.
\bibitem{hlmmixed} Davidian, M., and Giltinan, D., \textit{Nonlinear Models for Repeated Measurement Data}, New York: Chapman \& Hall/CRC, 1995.
\bibitem{delpish} Delpish, A., \textit{Comparison of Estimators in Hierarchical Linear Modeling: Restricted Maximum Likelihood Versus Bootstrap via Minimum Norm Quadratic Unbiased Estimators}, Electronic Theses, Treatises and Dissertations. Paper 771, 2006.
\bibitem{mixedR} Demidenko, E., \textit{Mixed Models– Theory and Applications with R}, 2nd Edition, Wiley Series in Probability and Statistics, John Wiley \& Sons, 2004.
\bibitem{liet2003} J. Dudaitė, A. Elijio, Ž. Urbienė, A. Zabulionis, \textit{Tarptautinis matematikos ir gamtos mokslų tyrimas. TIMSS 2003. Ataskaita}, NEC, 2004.
\bibitem{liet2003At} J. Dudaitė, \textit{Tarptautinis matematikos ir gamtos mokslų tyrimas TIMSS 2003. Rezultatų Analizė, matematika, viii klasė}. Nacionalinis egzaminų centras, 2004.
\bibitem{liet4} J. Dudaitė, A. Elijio, \textit{Change in Lithuanian Basic School Students’ Mathematics Achievement through 1995-2003}, Tarptautinė matematikos dėstymo konferencija – 2005, 57-62.
\bibitem{efron} Efron, B., \textit{Bootstrap Methods: Another Look at the Jackknife}, The Annals of Statistics 7 (1): 1–26, 1979.
\bibitem{liet6} A. Elijio, J Dudaitė, I. Mackevičienė, V. Trublenkovaitė, \textit{Tarptautinis matematikos ir gamtos mokslų tyrimas TIMSS 2007. Ataskaita. Matematika}, NEC, 2008.
\bibitem{liet2} A. Elijio, J. Dudaitė, \textit{Social, Economical, and Educational Factors in Relation to Mathematics Achievement}, Tarptautinė matematikos dėstymo konferencija – 2005, 62-67.
\bibitem{timssSch1} Fullarton, S., \textit{Closing the Gaps Between Schools: Accounting for Variation in Mathematics Achievment in Australian Schools Using TIMSS 95 and TIMSS 99}, IRC, 2004.
\bibitem{timss1995} Gonzalez, E., Smith, T., \textit{User Guide for the TIMSS International Database. Final Year of Secondary School}, IEA, 1998.
\bibitem{timssCpalyg} Gustafsson, A., M., \textit{School production modelling to strengthen government monitoring programmes in developing countries}, Thesis, University of Stellenbosch, 2006.
\bibitem{ml} Harley, H. 0., Rao, J., \textit{Maximum-likelihood estimation for the mixed analysis of variance model}, Biometrika, 54, 1967, 93.
\bibitem{AUE} Horn, S. D., R. A. Horn, and D. B. Duncan, \textit{Estimating hetero-scedastic variances in linear models}, Journal of the American Statistical Association, 70, 380 - 385, 1975.
\bibitem{hanushek} Hanushek, E., A., \textit{Efficient Estimators for Regressing Regression Coefficients}, The American Statistician, leidimas 28, Nr. 2 (gegužė, 1974), 66-67 psl.
\bibitem{minquereml1} Jarošova, E., \textit{Estimation with the Linear Mixed Effects Model}, Journal of Applied Mathematics, volume3, number 3, 2010.
\bibitem{jusko} Jusko, K., L., Shively, W., P., \textit{Applying a Two-Step Strategy to the Analysis of Cross-National Public Opinion Data}, Political Analysis (Ruduo 2005) 13 (4): 327-344. 
\bibitem{siaip4} Kiamanesh, A., \textit{Items Affecting Iranian Students' Achievment in Mathematics}, IRC, 2004.
\bibitem{countryHLM} Kyriakides, L., Charalambous, C., \textit{ Extending the Scope of Analysing Data of IEA Studies: Applying Multilevel Modeling Techniques to Analyse TIMSS Data}, IRC, 2004.
\bibitem{timssCpalyg2} Kim, S. J., Park, J. H., Park, S. W., Kim, S. S., \textit{The Effects of School and Students’ Educational Contexts in Korea, Singapore, and Finland using TIMSS 2011}, IRC, 2013.
\bibitem{siaip5} Kunter, M., Baumert, J., \textit{Constructivist Approches in the Secondary School Mathematics Classroom and Their Effects on Students' Learning, Interest and Sense of Challange: a Re-analysis of the German TIMSS Data}, IRC, 2004.
\bibitem{eqdg1}Lee, J., Khuri, A.I., \textit{Graphical technique for comparing designs for random models}, Journal of Statistical Planning and Inference, 91,  933–947, 2000.
\bibitem{bootML} Van der Leeden, R., Busing, F. M. T. A., and Meijer, E., \textit{Bootstrap methods for two-level models}, Technical Report PRM 97-04, Leiden University, Department of Psychology, Leiden, 1997.
\bibitem{EBi} Leeuw, J., Meijer, E., \textit{Handbook of Multilevel Analysis}, Springer, 2007.
\bibitem{shrinkage} Leeuw, J., Kreft, I., \textit{Questioning Multilevel Models}, Journal of Educational and Behavioral Statistics, Summer 1995, Vol. 20, No. 2, 171-189.
\bibitem{MMINQUE} El  Leithy,  H.A.,  Abdel  Wahed,  Z.A.,  Abdallah,  M.S.,  \textit{On  non-negative  estimation  of
variance components in mixed linear models}, Journal of Advanced Research, 2015 vasaris.
\bibitem{liu} Liu, Z., \textit{Next Generation Sequencing and Whole Genome Selection in Aquaculture}, John Wiley and Sons, 2010.
\bibitem{IAUE}Lucas, James R., \textit{A variance component estimation method for sparse matrix applications}, NOAA Technical Report NOS 111 NGS 33 , 1985.
\bibitem{sandwich} Maas, C., Hox, J., \textit{The influence of violations of assumptions on multilevel parameter estimates and their standard errors}, Computational Statistics \& Data Analysis 46, 2004, 427 – 440.
\bibitem{timss2011lt} Nacionalinio egzaminų centro Mokinių pasiekimų tyrimų ir analizės skyrius. \textit{TIMSS 2011 Ataskaita, Matematika, 8 klasė}, 2011
\bibitem{fixedTest} Orelien, J., Edwards, L., \textit{Fixed-effect variable selection in linear mixed models using R2 statistics}, Computational Statistics \& Data Analysis, 52, 2008, 896 – 1907.
\bibitem{pfeff} Pfeffermann, Skinner, D., C.J., Holmes, D.J., Goldstein, H., Rasbash, J., \textit{Weighting for unequal selection probabilities in multilevel models}, Journal of Royal Statistical Society, Series B, 1998, 60(l):23-40.
\bibitem{timssCpalyg3} Phan, H., Sentovich, C., Kromrey, J., Dedrick, R., Ferron, J., \textit{Correlates of Mathematics Achievement in Developed and Developing Countries: An HLM Analysis of TIMSS 2003 Eighth-grade Mathematics Scores}, pristatyma metiniame American Educational Research Association susitikime, Denver, Colorado, 2010.
\bibitem{rao1970}Rao, C. R., \textit{Estimation of heteroscedastic variances in linear models}, Journal of the American Statistical Association, 65, 1970, 161–172.
\bibitem{rao1971a} Rao, C. R., \textit{Estimation of variance and covariance components–MINQUE theory}, Journal of Multivariate Analysis, 1, 1971a, 257–275.
\bibitem{rao1971b} Rao, C. R., \textit{Minimum variance quadratic unbiased estimation of variance components}, Journal of Multivariate Analysis, 1, 1971b, 445–456.
\bibitem{rao1972} Rao, C. R., \textit{Estimation of variance and covariance components in linear models}, Journal of the American Statistical Association, 67, 1972, 112–115.
\bibitem{minquereml3} Rao, C.R., \textit{MINQUE theory and its relation to ML and MML estimation of variance components}, Sankhya 41, 1979, 138-153.
\bibitem{bootNest} Ren, S., Lai, H., Tong,W., Aminzadeh M., \textit{Nonparametric bootstrapping for hierarchical data}, Journal of Applied Statistics, 37:9, 1487-1498, 2010.
\bibitem{timssLiet} Robitaille, D., Beaton, A., \textit{Secondary Analysis of the TIMSS Data}, Kluwer Academic Publishers, 2002.
\bibitem{2011Sample} \textit{Sample Design and Implementation}, [žiūrėta 2015-11-23], prieiga per internetą : http://timssandpirls.bc.edu/methods/t-sample-design.html.
\bibitem{saxonhouse} Saxonhouse, G., R., \textit{Estimated Parameters as Dependent Variables}, The American Economic Review,
leidimas 66, Nr. 1 (balandis, 1976), psl. 178-183.
\bibitem{minquereml2} Searle, S. R., Casella, G., McCulloch, Ch.E., \textit{Variance Components}, John Wiley \& Sons, Inc., New York, 1992.
\bibitem{icc} Shackman, G., \textit{Developing Sample Sizes for New Surveys: Estimating the Design Effect Adjustment}, What’s Hot / What’s Next VI. Albany, 2001.
\bibitem{fixed} Snijders, T., Bosker, R., \textit{Multilevel Analysis: An introduction to basic and advanced multilevel modeling}, SAGE Publications, 1999.
\bibitem{mlwin} Steele, F., Clarke, P., Goldstein, H., \textit{Weighting in MLwiN}, Centre for Multilevel Modeling (CML), Bristol: University of Bristol, 2011, [žiūrėta 2015-10-20], prieiga per internetą: http://www.bristol.ac.uk/media-library/sites/cmm/migrated/documents/weighting.pdf
\bibitem{timssPol} Stidd, M., \textit{A Comparative Analysis of Freedom and Educational Outcomes Using TIMSS and PIRLS}, University of Colorado Colorado Springs, 2012.
\bibitem{MMIVQUE}Subramani J. \textit{On modified minimum variance quadratic unbiased estimation (MIVQUE) of variance components in mixed linear models}, Model Assis Stat, 7:179–200, 2012 birželis.
\bibitem{liet1} Švietimo ir mokslo ministerijos bei Atviros Lietuvos fondo spaudos konferencija, \textit{Tarptautinis matematikos ir gamtos mokslų tyrimas TIMSS – R}, 2000.
\bibitem{downwardbias}Timm, N.H., \textit{Applied Multivariate Analysis}, Springer Texts in Statistics, 2002.
\bibitem{mcmc} Vakilian, S., \textit{Simulation Studies on Estimation of Variance Components for Multilevel Models}, Theses and Dissertations (Comprehensive), paper 922, 2009.
\bibitem{MLbetterMINQUE} Tong, H., Kumar, K., Huang, Y., \textit{Developing Econometrics}, John Wiley \& Sons, 2011.
\bibitem{Rtest} Vonesh, E.F., Chinchilli, V.M., \textit{ Linear and Nonlinear Models for the Analysis of Repeated Measurements}, Marcel Dekker, 1997, 419–424.
\bibitem{pwigls2} Veiga, A., C., \textit{Methods for analysing complex panel data using multilevel models with an application to the Brazilian labour force survey}, Thesis for the degree of Doctor of Philosophy, University of Southampton, 2010.
\bibitem{timssCpalyg4} Wiberg, M., Andersson, E., \textit{School-Effectiveness in Mathematics in Sweden compared with countries in Europe and Asia-Pacific}, IRC, 2010.
\bibitem{zhu} Zhu, J,. \textit{Estimation of Genetic Variance Components in the General Mixed Model},  Ph.D.
Dissertation, NC State University, Raleigh, U.S.A, 1989.   
\bibitem{zhu2} Zhu, J.,  \textit{Mixed model approaches for estimating genetic variances and covariances}, Journal of Biomathe inatics 7( I ): 1 - 1 I, 1992.
\bibitem{siaip6} Zuzovsky, R., \textit{Grouping and Its effects on 8th Graders' Science and Mathematics Achievments}, IRC, 2004.
\end{thebibliography}

\newpage
\begin{appendix}

 \hypertarget{appendix}{\section*{PRIEDAS}}
\addcontentsline{toc}{section}{Priedas}
\begin{footnotesize}
\begin{verbatim}
rm(list = ls())
library(nlme)
library(plyr)
library(gdata)
library(lme4)
library(mitools)
library(lmerTest)
library(robustlmm)
library(foreach)
library(Matrix)
library(gtools)
library(snow)
library(matrixcalc)
library(mitools)
library(MASS)
library(snow)
library(boot)
library(plyr)
library(mvtnorm)
library(expm)
library(simFrame)
library(foreach)
library(msm)
library(gtools)
library(MASS)
library(lme4)
library(gdata)
library(Matrix)
#################################################################
# MINQUE funkcija HLM (arba misriu efektu) modeliams vertinti
#################################################################
myMINQUE <- function(dt, fixed, random1 = NULL, 
                       apriori = NULL) {
  # Kintamieji:
  #    dt - duomenys pateikti data.frame klaes objekte;
  #    fixed - fiksuotu efektu fomule pateikta character formatu;
  #    random1 - atsitiktiniu efektu formule pateikta character formatu;
  #    apriori - pradines dispersijos komponenciu reiksmes.

  N <- nrow(dt)
  # Suformuojam Y ir X matricas
  ff <- model.matrix(as.formula(fixed), model.frame(fixed, dt))
  Y <- as(as(model.frame(fixed, dt)[,1, drop = F], "matrix"), "Matrix")
  if (grepl("-1",fixed)) {
    X <- as(as(ff[,-1, drop = F], "matrix"), "Matrix")
  } else {
    X <- as(as(ff, "matrix"), "Matrix")
  }
  
  # Suformuojamos atsitiktiniu effektu matricos
  if (!is.null(random1)) {
    id1 <- strsplit(random1, "\\|")
    random1 <- unlist(id1)[1]
    nmid1 <- unlist(id1)[2]
    rr1 <- model.frame(random1, dt)
    id1 <- model.frame(paste("~", nmid1), dt)[,1]
    if (grepl("-1",random1)) {
      Z1 <- as(as( rr1, "matrix"), "Matrix")
    } else {
      Z1 <- as(as(cbind(matrix(1, ncol = 1, nrow = nrow(rr1),
                               dimnames = list(NULL, "(Intercept)")), rr1), 
                              "matrix"),  "Matrix")
    }
    q <- ncol(Z1)
    colnames(Z1) <- paste(nmid1, colnames(Z1), sep = ".")
    clnms1 <- colnames(Z1)
    Z1 <- foreach(i = unique(id1)) %do% {Z1[id1 %in% i, ,drop = F]}
    Z <- bdiag(Z1)
    n1 <- length(unique(id1))
    l <- q*(q+1)/2
    TT1 <- formTT(q)
    QI <- llply(TT1, function(tt) llply(Z1, function(z) z%*%tt%*%t(z)))
  } else {
    Z1 <- NULL
    clnms1 <- NULL
    n1 <- NULL
    QI <- NULL
  }

  l <- l+1
  Qj <- c(list(llply(QI[[1]], function(zj) diag(nrow(zj)))), QI)
  QI <- llply(Qj, function(x) bdiag(x))
  Xj <- foreach(i = unique(id1)) %do% {X[id1 %in% i, ,drop = F]}
  X <- as(foreach(ii = 1:length(Xj), .combine = rbind) %do% 
                            as.matrix(Xj[[ii]]), "Matrix")
  Yj <- foreach(i = unique(id1)) %do% {Y[id1 %in% i,,drop = F]}
  Y <- as(foreach(ii = 1:length(Xj), .combine = rbind) %do% 
                            as.matrix(Yj[[ii]]), "Matrix")
  
  if (is.null(apriori)) apriori <- rep(1, length(QI))
  
  Vj <- foreach(i = 1:length(unique(id1))) %do% 
                 solve(Reduce("+", mapply(function(qj, th) th*qj[[i]], Qj, 
	            apriori))) 
  V <- bdiag(Vj)

  iM <- iMINQUE(V, X, Y, QI, wgt2i)
  gc()
  theta <- iM$theta
  print(theta)
  iM <- iMINQUE(iM$V, X, Y, QI, wgt2i)

  P <- ginv(as.matrix((t(X)%*%iM$V%*%X)))
  iM$beta <- P%*%t(X)%*%iM$V%*%Y
  gc()
  sigma2 <- iM$theta[1]
  names(sigma2) <- "sigma2"
  TT <- fillT(iM$theta[-1])
  dimnames(TT) <- list(clnms1, clnms1)
  beta <- as.numeric(iM$beta)
  names(beta) <- colnames(X)
  return(list(sigma2 = sigma2, TT = TT, beta = beta, N = N, n1 = n1))
}

# S matricos uzpildymui
fillSMINQUE2 <- function(CQ) {
  # Kintamieji:
  #    CQ - matricu C ir Qi sandaugu sarasas (list).

  x <- matrix(0, ncol = length(CQ), nrow = length(CQ))
  ns <- nrow(x)
  cc <- combinations(ns,2,1:ns, repeats.allowed = T)
  foreach(ii = 1:nrow(cc)) %do% {
    k <- cc[ii, 1]
    l <- cc[ii, 2]
    s <- sum(diag(CQ[[k]]%*%CQ[[l]]))
    x[k,l] <- s
    x[l, k] <- s
    gc()
  }
  gc()
  return(x)
}

# MINQUE iteracijai
iMINQUE <- function(V, X, Y, QI) {
  XVX <- ginv(as.matrix((t(X)%*%V%*%X)))
  Cjj <- V-V%*%X%*%XVX%*%t(X)%*%V#(V*unlist(wgt2i))
  CQ <- llply(QI, function(qi) Cjj%*%qi)
  
  S <- fillSMINQUE2(CQ)
  WI <- laply(CQ, function(cq) sum(diag(t(Y)%*%cq%*%Cjj%*%Y)))

  theta0 <- ginv(S)%*%matrix(WI, ncol = 1)

  V <- ginv(as.matrix(Reduce("+", mapply(function(qi, th)
                {qi*th}, QI, theta0))))
  return(list(theta = theta0, V = V, P = XVX))
}

#################################################################
# MINQUE su saviranka
#################################################################
bootMINQUE <- function(data = data.2011, FUN  = myMINQUE, B = 5,
                        fixed = "BSMMAT01 ~ 1+SSEX", 
                        random = "~1|IDSCHOOL",
                        idstrata = "IDSTRATE", idschool = "IDSCHOOL",
                        idstud = "IDSTUD", apriori = NULL,
                        BFUN = bootSample) {
  # Kintamieji:
  #    data - duomenys pateikti data.frame klaes objekte;
  #    FUN - MINQUE f-jos pavadinimas;
  #    B - savirankos iteraciju skaicius;
  #    fixed - fiksuotu efektu fomule pateikta character formatu;
  #    random - atsitiktiniu efektu formule pateikta character formatu;
  #    idstrata - data stulpelio pavadinimas, kuriame identifikuojami lizdai;
  #    idschool - stulpelio pavadinimas, kuriame identifikuojama klasė;
  #    idstud - stulpelio pavadinimas, kuriame identifikuojamas individas;
  #    apriori - pradines dispersijos komponenciu reiksmes;
  #    BFUN - f-jos pavadinimas savirankoms imtims.

  print("Iteration:")
  t0 <- FUN(data, fixed = fixed, random = random)
  
  bootRes <- foreach(ii = 1:B, .combine = rbind) %do% {
    print(paste("boot", ii))
    smpldt <- try(BFUN(data, idstrata, idschool,
                             idstud, wgt))
    if(class(smpldt) == "try-error") return(NULL)
    res <- try(FUN(smpldt, fixed = fixed, random = random, apriori = apriori))
    if(class(res) == "try-error") return(NULL)
    cc <- c(res$beta, res$sigma2, unlist(res$TT))
    names(cc) <- c("beta", "sigma2", "")
    return(cc)
  }
  print("Collect")
  
  # Rezultatų suvedimas

  tt <- bootRes
  # Fiksuoti efektai
  beta0 <- t0$beta
  beta  <- tt[,1:length(beta0), drop = F]
  colnames(beta) <- rownames(beta0)
  Bcov <- cov(beta)
  Bint <- t(t(beta)-as.numeric(beta0))
  Bint <- apply(Bint, 2, function(x) quantile(x, probs=c(0.025,0.975)))
  Bint <- rbind((t(beta0)-Bint[2,]), (t(beta0)-Bint[1,]))
  rownames(Bint) <- c("2.5%", "97.5%")
  beta <- apply(beta, 2, mean)
  Bbias <- beta - beta0
  beta <- beta0-Bbias
  beta <- cbind(Coefficient = beta, St.err = sqrt(diag(Bcov)), 
                 Bias = Bbias, t(Bint))
  colnames(beta)[1:3] <- c("Coeff", "St.err", "Bias")
  attr(beta, "cov") <- Bcov
  
  tt <- tt[,-1:-length(beta0), drop = F]
 
  # Sigma
  sigma0 <- t0$sigma2
  sigma  <- tt[,1, drop = F]
  colnames(sigma) <- "sigma2"
  Scov <- cov(sigma)
  #Sint <- apply(sigma, 2, function(x) quantile(x, c(.025, .975)) )
  Sint <- t(t(sigma)-(sigma0))
  Sint <- apply(Sint, 2, function(x) quantile(x, probs=c(0.025,0.975)))
  Sint <- rbind((t(sigma0)-Sint[2,]), (t(sigma0)-Sint[1,]))
  rownames(Sint) <- c("2.5%", "97.5%")
  sigma <- apply(sigma, 2, mean)
  Sbias <- sigma - sigma0
  sigma <- sigma0 - Sbias
  sigma <- cbind(Coefficient = sigma, St.err = sqrt(diag(Scov)), 
                 Bias = Sbias, t(Sint))
  attr(sigma, "cov") <- Scov
  
  tt <- tt[,-1, drop = F]
  
  # Atsitiktiniai efektai
  TT0 <- as.numeric(t0$TT)
  TT  <- tt
  TTcov <- cov(TT)
  TTint <- t(t(TT)-(TT0))
  TTint <- apply(TTint, 2, function(x) quantile(x, probs=c(0.025,0.975)))
  TTint <- rbind((t(TT0)-TTint[2,]), (t(TT0)-TTint[1,]))
  rownames(TTint) <- c("2.5%", "97.5%")
  
  TT <- apply(TT, 2, mean)
  TTbias <- TT - TT0
  TT <- TT0 - TTbias
  TT <- cbind(Coefficient = TT, St.err = sqrt(diag(TTcov)), Bias = TTbias,
                  t(TTint))
  
  return(list(beta = beta, sigma2 = sigma, TT = TT, t0 = t0, result = bootRes))
}

bootSample <- function(dt, idstrata = "IDSTRATE", idschool = "IDSCHOOL",
                       idstud = "IDSTUD")) {
  strata <- dt[, idstrata]
  sd <- foreach(ii = unique(strata), .combine = rbind) %do% {
    sdata <- dt[strata %in% ii, ,drop = F]
    sch <- unique(sdata[,idschool])
    nh <- length(sch)
    if (nh == 1) nh <- 2
    smSCH <- as.numeric(sample(as.character(sch), nh, replace = T))
    smSCH <- sch
    std <- foreach(jj = smSCH, .combine = rbind) %do% {
      studdt <- sdata[sch %in% jj,,drop = F]
      idst <- studdt[, idstud]
      nhc <- length(idst)
      smplStud <- sample(idst, nhc, replace = T)
      studdt1 <- foreach(kk = smplStud, .combine = rbind) %do% 
                          studdt[idst %in% kk,,drop = F]
      studdt1$nhc <- nhc
      return(studdt1)
    }
    return(std)
  }
  return(sd)
}

#################################################################
# Naudojimosi pavyzdys
#################################################################
n1 <- 10
beta0 <- 50+rnorm(n1, 0, sqrt(0.25))
df <- data.frame(IDCLASS = 1:10, beta0 = beta0)
df <- foreach(ii = 1:10, .combine = rbind) %do% {data.frame(df[ii,],
              IDINDIV = paste(ii, 1:5, sep = ""))}
df$X <- rnorm(nrow(df), 10, sqrt(50))
df$e <- rnorm(nrow(df), 0, sqrt(0.5))
df$y <- df$beta0+4*df$X+df$e

min1 <- myMINQUE(dt = df,
                  fixed = " y~ 1+X",
                  random1 = "~1|IDCLASS")

min1$beta
min1$TT
min1$sigma

df$idstrata  <-  1
bb <- bootMINQUE(fixed = "y ~ 1+X", idschool = "IDCLASS",
                  idstud = "IDINDIV", random = "~1|IDCLASS", wgt = NULL,
                  idstrata = "idstrata", R = 100, data = df)
bb$beta
bb$TT
bb$sigma
\end{verbatim}
\end{footnotesize}
\end{appendix}

\newpage

%\begin{appendix}
\addcontentsline{toc}{section}{Lentelių sąrašas}
\listoftables
%\end{appendix}
 %\begin{appendix}
 \addcontentsline{toc}{section}{Iliustracijų sąrašas}
 \listoffigures
 %\end{appendix}
  

\newpage
\section{Simuliacijų rezultatai}\label{sec:lenteles}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:31:41 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\gamma}_{00}$ & MRBIAS & MRMSE & $\hat{\gamma}_{00}$ & MRBIAS & MRMSE & $\hat{\gamma}_{00}$ & MRBIAS & MRMSE & $\hat{\gamma}_{00}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 449.561 & \textbf{-0.001} & \textbf{0.000} & 449.508 & \textbf{-0.001} & \textbf{0.000} & 449.559 & \textbf{-0.001} & \textbf{0.000} & 449.992 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 450.045 & \textbf{0.000} & \textbf{0.000} & 450.057 & \textbf{0.000} & \textbf{0.000} & 450.129 & \textbf{0.000} & \textbf{0.000} & 450.062 & \textbf{0.000} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 449.008 & \textbf{-0.002} & \textbf{0.001} & 448.909 & \textbf{-0.002} & \textbf{0.001} & 449.007 & \textbf{-0.002} & \textbf{0.001} & 449.003 & \textbf{-0.002} & \textbf{0.001} \\ 
   &  & 451.113 & \textbf{0.002} & \textbf{0.001} & 450.051 & \textbf{0.000} & \textbf{0.002} & 451.102 & \textbf{0.002} & \textbf{0.001} & 450.693 & \textbf{0.002} & \textbf{0.001} \\ 
   & \multirow{2}{*}{V3} & 449.851 & \textbf{0.000} & \textbf{0.003} & 451.542 & \textbf{0.003} & \textbf{0.011} & 449.847 & \textbf{0.000} & \textbf{0.003} & 449.560 & \textbf{-0.001} & \textbf{0.003} \\ 
   &  & 447.870 & \textbf{-0.005} & \textbf{0.003} & 447.111 & \textbf{-0.006} & \textbf{0.004} & 447.873 & \textbf{-0.005} & \textbf{0.003} & 448.858 & \textbf{-0.003} & \textbf{0.003} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 449.671 & \textbf{-0.001} & \textbf{0.000} & 449.660 & \textbf{-0.001} & \textbf{0.000} & 449.669 & \textbf{-0.001} & \textbf{0.000} & 449.666 & \textbf{-0.001} & \textbf{0.000} \\ 
   &  & 450.285 & \textbf{0.001} & \textbf{0.000} & 450.289 & \textbf{0.001} & \textbf{0.000} & 450.269 & \textbf{0.001} & \textbf{0.000} & 450.289 & \textbf{0.001} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 449.466 & \textbf{-0.001} & \textbf{0.001} & 449.425 & \textbf{-0.001} & \textbf{0.001} & 449.466 & \textbf{-0.001} & \textbf{0.001} & 449.466 & \textbf{-0.001} & \textbf{0.001} \\ 
   &  & 450.094 & \textbf{0.000} & \textbf{0.001} & 450.057 & \textbf{0.000} & \textbf{0.001} & 450.095 & \textbf{0.000} & \textbf{0.001} & 450.092 & \textbf{0.000} & \textbf{0.001} \\ 
   & \multirow{2}{*}{V3} & 450.511 & \textbf{0.001} & \textbf{0.003} & 450.492 & \textbf{0.001} & \textbf{0.003} & 450.510 & \textbf{0.001} & \textbf{0.003} & 450.511 & \textbf{0.001} & \textbf{0.003} \\ 
   &  & 452.401 & \textbf{0.005} & \textbf{0.003} & 453.921 & \textbf{0.009} & \textbf{0.009} & 452.403 & \textbf{0.005} & \textbf{0.003} & 452.400 & \textbf{0.005} & \textbf{0.003} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 450.151 & \textbf{0.000} & \textbf{0.000} & 450.151 & \textbf{0.000} & \textbf{0.000} & 450.157 & \textbf{0.000} & \textbf{0.000} & 450.411 & \textbf{0.001} & \textbf{0.000} \\ 
   &  & 450.005 & \textbf{0.000} & \textbf{0.000} & 450.008 & \textbf{0.000} & \textbf{0.000} & 450.000 & \textbf{0.000} & \textbf{0.000} & 450.106 & \textbf{0.000} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 449.851 & \textbf{0.000} & \textbf{0.001} & 449.901 & \textbf{0.000} & \textbf{0.001} & 449.852 & \textbf{0.000} & \textbf{0.001} & 450.384 & \textbf{0.001} & \textbf{0.001} \\ 
   &  & 449.639 & \textbf{-0.001} & \textbf{0.001} & 447.495 & \textbf{-0.006} & \textbf{0.009} & 449.638 & \textbf{-0.001} & \textbf{0.001} & 450.571 & \textbf{0.001} & \textbf{0.001} \\ 
   & \multirow{2}{*}{V3} & 449.846 & \textbf{0.000} & \textbf{0.002} & 449.848 & \textbf{0.000} & \textbf{0.002} & 449.845 & \textbf{0.000} & \textbf{0.002} & 449.814 & \textbf{0.000} & \textbf{0.002} \\ 
   &  & 448.798 & \textbf{-0.003} & \textbf{0.002} & 448.938 & \textbf{-0.002} & \textbf{0.002} & 448.798 & \textbf{-0.003} & \textbf{0.002} & 450.991 & \textbf{0.002} & \textbf{0.002} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 450.011 & \textbf{0.000} & \textbf{0.000} & 450.006 & \textbf{0.000} & \textbf{0.000} & 450.010 & \textbf{0.000} & \textbf{0.000} & 450.009 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 450.272 & \textbf{0.001} & \textbf{0.000} & 450.269 & \textbf{0.001} & \textbf{0.000} & 450.275 & \textbf{0.001} & \textbf{0.000} & 450.274 & \textbf{0.001} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 449.071 & \textbf{-0.002} & \textbf{0.001} & 449.078 & \textbf{-0.002} & \textbf{0.001} & 449.071 & \textbf{-0.002} & \textbf{0.001} & 449.071 & \textbf{-0.002} & \textbf{0.001} \\ 
   &  & 450.354 & \textbf{0.001} & \textbf{0.001} & 450.416 & \textbf{0.001} & \textbf{0.001} & 450.355 & \textbf{0.001} & \textbf{0.001} & 450.353 & \textbf{0.001} & \textbf{0.001} \\ 
   & \multirow{2}{*}{V3} & 451.424 & \textbf{0.003} & \textbf{0.002} & 451.430 & \textbf{0.003} & \textbf{0.002} & 451.423 & \textbf{0.003} & \textbf{0.002} & 451.424 & \textbf{0.003} & \textbf{0.002} \\ 
   &  & 450.358 & \textbf{0.001} & \textbf{0.002} & 450.367 & \textbf{0.001} & \textbf{0.002} & 450.359 & \textbf{0.001} & \textbf{0.002} & 450.358 & \textbf{0.001} & \textbf{0.002} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 450.038 & \textbf{0.000} & \textbf{0.000} & 450.042 & \textbf{0.000} & \textbf{0.000} & 450.039 & \textbf{0.000} & \textbf{0.000} & 449.944 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 449.943 & \textbf{0.000} & \textbf{0.000} & 449.936 & \textbf{0.000} & \textbf{0.000} & 449.945 & \textbf{0.000} & \textbf{0.000} & 449.738 & \textbf{-0.001} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 450.369 & \textbf{0.001} & \textbf{0.000} & 450.367 & \textbf{0.001} & \textbf{0.000} & 450.368 & \textbf{0.001} & \textbf{0.000} & 450.055 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 449.826 & \textbf{0.000} & \textbf{0.000} & 450.014 & \textbf{0.000} & \textbf{0.000} & 449.827 & \textbf{0.000} & \textbf{0.000} & 449.836 & \textbf{0.000} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V3} & 449.608 & \textbf{-0.001} & \textbf{0.001} & 449.606 & \textbf{-0.001} & \textbf{0.001} & 449.608 & \textbf{-0.001} & \textbf{0.001} & 450.293 & \textbf{0.001} & \textbf{0.001} \\ 
   &  & 450.034 & \textbf{0.000} & \textbf{0.001} & 450.256 & \textbf{0.001} & \textbf{0.001} & 450.033 & \textbf{0.000} & \textbf{0.001} & 448.844 & \textbf{-0.003} & \textbf{0.001} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 450.084 & \textbf{0.000} & \textbf{0.000} & 450.083 & \textbf{0.000} & \textbf{0.000} & 450.083 & \textbf{0.000} & \textbf{0.000} & 450.083 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 449.984 & \textbf{0.000} & \textbf{0.000} & 449.981 & \textbf{0.000} & \textbf{0.000} & 449.984 & \textbf{0.000} & \textbf{0.000} & 449.983 & \textbf{0.000} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V2} & 450.153 & \textbf{0.000} & \textbf{0.000} & 450.154 & \textbf{0.000} & \textbf{0.000} & 450.153 & \textbf{0.000} & \textbf{0.000} & 450.153 & \textbf{0.000} & \textbf{0.000} \\ 
   &  & 449.785 & \textbf{0.000} & \textbf{0.000} & 449.769 & \textbf{-0.001} & \textbf{0.000} & 449.786 & \textbf{0.000} & \textbf{0.000} & 449.785 & \textbf{0.000} & \textbf{0.000} \\ 
   & \multirow{2}{*}{V3} & 449.954 & \textbf{0.000} & \textbf{0.001} & 449.955 & \textbf{0.000} & \textbf{0.001} & 449.954 & \textbf{0.000} & \textbf{0.001} & 449.954 & \textbf{0.000} & \textbf{0.001} \\ 
   &  & 449.391 & \textbf{-0.001} & \textbf{0.001} & 449.426 & \textbf{-0.001} & \textbf{0.001} & 449.391 & \textbf{-0.001} & \textbf{0.001} & 449.390 & \textbf{-0.001} & \textbf{0.001} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\gamma_{00}=450$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:36:45 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\gamma}_{01}$ & MRBIAS & MRMSE & $\hat{\gamma}_{01}$ & MRBIAS & MRMSE & $\hat{\gamma}_{01}$ & MRBIAS & MRMSE & $\hat{\gamma}_{01}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 10.117 & 0.012 & \textbf{0.021} & 10.107 & 0.011 & \textbf{0.022} & 10.113 & 0.011 & \textbf{0.022} & 9.999 & \textbf{0.000} & \textbf{0.025} \\ 
   &  & 9.990 & \textbf{-0.001} & \textbf{0.023} & 9.986 & \textbf{-0.001} & \textbf{0.023} & 9.965 & \textbf{-0.003} & \textbf{0.024} & 9.990 & \textbf{-0.001} & \textbf{0.022} \\ 
   & \multirow{2}{*}{V2} & 10.207 & \textbf{0.021} & \textbf{0.108} & 10.206 & \textbf{0.021} & \textbf{0.111} & 10.207 & \textbf{0.021} & \textbf{0.108} & 10.225 & \textbf{0.023} & \textbf{0.111} \\ 
   &  & 9.769 & -0.023 & \textbf{0.109} & 9.871 & \textbf{-0.013} & \textbf{0.129} & 9.771 & -0.023 & \textbf{0.109} & 9.893 & \textbf{-0.011} & \textbf{0.116} \\ 
   & \multirow{2}{*}{V3} & 10.022 & \textbf{0.002} & \textbf{0.213} & 9.722 & -0.028 & \framebox{0.665} & 10.022 & \textbf{0.002} & \textbf{0.213} & 10.140 & 0.014 & \textbf{0.225} \\ 
   &  & 10.389 & 0.039 & 0.295 & 10.474 & 0.047 & 0.319 & 10.388 & 0.039 & 0.295 & 10.304 & \textbf{0.03} & \textbf{0.258} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 10.056 & \textbf{0.006} & \textbf{0.022} & 10.058 & \textbf{0.006} & \textbf{0.022} & 10.056 & \textbf{0.006} & \textbf{0.022} & 10.057 & \textbf{0.006} & \textbf{0.022} \\ 
   &  & 9.980 & \textbf{-0.002} & \textbf{0.023} & 9.980 & \textbf{-0.002} & \textbf{0.023} & 9.983 & \textbf{-0.002} & \textbf{0.023} & 9.980 & \textbf{-0.002} & \textbf{0.023} \\ 
   & \multirow{2}{*}{V2} & 10.019 & \textbf{0.002} & \textbf{0.119} & 10.025 & \textbf{0.002} & \textbf{0.119} & 10.019 & \textbf{0.002} & \textbf{0.119} & 10.018 & \textbf{0.002} & \textbf{0.119} \\ 
   &  & 9.997 & \textbf{0.000} & \textbf{0.107} & 9.996 & \textbf{0.000} & \textbf{0.106} & 9.998 & \textbf{0.000} & \textbf{0.107} & 9.998 & \textbf{0.000} & \textbf{0.107} \\ 
   & \multirow{2}{*}{V3} & 9.791 & \textbf{-0.021} & \textbf{0.235} & 9.795 & \textbf{-0.021} & \textbf{0.235} & 9.792 & \textbf{-0.021} & \textbf{0.235} & 9.791 & \textbf{-0.021} & \textbf{0.235} \\ 
   &  & 9.444 & \textbf{-0.056} & \textbf{0.268} & 9.120 & -0.088 & \framebox{0.71} & 9.444 & \textbf{-0.056} & \textbf{0.268} & 9.444 & \textbf{-0.056} & \textbf{0.268} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 9.988 & \textbf{-0.001} & \textbf{0.013} & 9.988 & \textbf{-0.001} & \textbf{0.013} & 9.987 & \textbf{-0.001} & \textbf{0.013} & 9.913 & -0.009 & \textbf{0.012} \\ 
   &  & 9.989 & \textbf{-0.001} & \textbf{0.014} & 9.988 & \textbf{-0.001} & \textbf{0.014} & 9.989 & \textbf{-0.001} & \textbf{0.014} & 9.985 & \textbf{-0.001} & \textbf{0.014} \\ 
   & \multirow{2}{*}{V2} & 10.090 & \textbf{0.009} & \textbf{0.057} & 10.091 & \textbf{0.009} & \textbf{0.057} & 10.090 & \textbf{0.009} & \textbf{0.057} & 9.931 & \textbf{-0.007} & \textbf{0.058} \\ 
   &  & 10.055 & \textbf{0.005} & \textbf{0.058} & 10.437 & 0.044 & \framebox{0.626} & 10.055 & \textbf{0.006} & \textbf{0.058} & 9.923 & \textbf{-0.008} & \textbf{0.058} \\ 
   & \multirow{2}{*}{V3} & 10.017 & \textbf{0.002} & \textbf{0.137} & 10.016 & \textbf{0.002} & \textbf{0.137} & 10.017 & \textbf{0.002} & \textbf{0.137} & 9.965 & \textbf{-0.004} & \textbf{0.163} \\ 
   &  & 10.241 & 0.024 & \textbf{0.134} & 10.209 & 0.021 & \textbf{0.155} & 10.241 & 0.024 & \textbf{0.134} & 9.911 & \textbf{-0.009} & \textbf{0.161} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 9.982 & \textbf{-0.002} & \textbf{0.012} & 9.982 & \textbf{-0.002} & \textbf{0.012} & 9.982 & \textbf{-0.002} & \textbf{0.012} & 9.982 & \textbf{-0.002} & \textbf{0.012} \\ 
   &  & 9.963 & \textbf{-0.004} & \textbf{0.013} & 9.963 & \textbf{-0.004} & \textbf{0.013} & 9.963 & \textbf{-0.004} & \textbf{0.013} & 9.963 & \textbf{-0.004} & \textbf{0.013} \\ 
   & \multirow{2}{*}{V2} & 10.189 & \textbf{0.019} & \textbf{0.059} & 10.187 & \textbf{0.019} & \textbf{0.059} & 10.189 & \textbf{0.019} & \textbf{0.059} & 10.189 & \textbf{0.019} & \textbf{0.059} \\ 
   &  & 9.974 & \textbf{-0.003} & \textbf{0.057} & 9.971 & \textbf{-0.003} & \textbf{0.057} & 9.974 & \textbf{-0.003} & \textbf{0.057} & 9.974 & \textbf{-0.003} & \textbf{0.057} \\ 
   & \multirow{2}{*}{V3} & 9.646 & \textbf{-0.035} & \textbf{0.139} & 9.645 & \textbf{-0.036} & \textbf{0.139} & 9.646 & \textbf{-0.035} & \textbf{0.139} & 9.646 & \textbf{-0.035} & \textbf{0.139} \\ 
   &  & 9.982 & \textbf{-0.002} & \textbf{0.131} & 9.971 & \textbf{-0.003} & \textbf{0.133} & 9.982 & \textbf{-0.002} & \textbf{0.131} & 9.982 & \textbf{-0.002} & \textbf{0.131} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 9.995 & \textbf{-0.001} & \textbf{0.005} & 9.994 & \textbf{-0.001} & \textbf{0.005} & 9.995 & \textbf{-0.001} & \textbf{0.005} & 10.020 & \textbf{0.002} & \textbf{0.005} \\ 
   &  & 10.014 & \textbf{0.001} & \textbf{0.005} & 10.014 & \textbf{0.001} & \textbf{0.005} & 10.014 & \textbf{0.001} & \textbf{0.005} & 10.058 & \textbf{0.006} & \textbf{0.005} \\ 
   & \multirow{2}{*}{V2} & 9.961 & \textbf{-0.004} & \textbf{0.026} & 9.962 & \textbf{-0.004} & \textbf{0.026} & 9.962 & \textbf{-0.004} & \textbf{0.026} & 9.966 & \textbf{-0.003} & \textbf{0.026} \\ 
   &  & 10.020 & \textbf{0.002} & \textbf{0.025} & 9.950 & \textbf{-0.005} & \textbf{0.049} & 10.020 & \textbf{0.002} & \textbf{0.025} & 10.048 & \textbf{0.005} & \textbf{0.025} \\ 
   & \multirow{2}{*}{V3} & 10.114 & \textbf{0.011} & \textbf{0.054} & 10.114 & \textbf{0.011} & \textbf{0.054} & 10.114 & \textbf{0.011} & \textbf{0.054} & 9.909 & \textbf{-0.009} & \textbf{0.061} \\ 
   &  & 9.997 & \textbf{0.000} & \textbf{0.06} & 9.943 & \textbf{-0.006} & \textbf{0.077} & 9.997 & \textbf{0.000} & \textbf{0.06} & 10.187 & 0.019 & \textbf{0.06} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 9.961 & \textbf{-0.004} & \textbf{0.006} & 9.961 & \textbf{-0.004} & \textbf{0.006} & 9.961 & \textbf{-0.004} & \textbf{0.006} & 9.961 & \textbf{-0.004} & \textbf{0.006} \\ 
   &  & 10.004 & \textbf{0.000} & \textbf{0.006} & 10.004 & \textbf{0.000} & \textbf{0.006} & 10.004 & \textbf{0.000} & \textbf{0.006} & 10.004 & \textbf{0.000} & \textbf{0.006} \\ 
   & \multirow{2}{*}{V2} & 9.949 & \textbf{-0.005} & \textbf{0.025} & 9.948 & \textbf{-0.005} & \textbf{0.025} & 9.949 & \textbf{-0.005} & \textbf{0.025} & 9.949 & \textbf{-0.005} & \textbf{0.025} \\ 
   &  & 10.074 & \textbf{0.007} & \textbf{0.023} & 10.076 & \textbf{0.008} & \textbf{0.023} & 10.074 & \textbf{0.007} & \textbf{0.023} & 10.074 & \textbf{0.007} & \textbf{0.023} \\ 
   & \multirow{2}{*}{V3} & 9.937 & \textbf{-0.006} & \textbf{0.062} & 9.936 & \textbf{-0.006} & \textbf{0.062} & 9.937 & \textbf{-0.006} & \textbf{0.062} & 9.937 & \textbf{-0.006} & \textbf{0.062} \\ 
   &  & 10.159 & \textbf{0.016} & \textbf{0.06} & 10.141 & \textbf{0.014} & \textbf{0.062} & 10.159 & \textbf{0.016} & \textbf{0.06} & 10.159 & \textbf{0.016} & \textbf{0.06} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\gamma_{01}=10$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:38:47 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\gamma}_{10}$ & MRBIAS & MRMSE & $\hat{\gamma}_{10}$ & MRBIAS & MRMSE & $\hat{\gamma}_{10}$ & MRBIAS & MRMSE & $\hat{\gamma}_{10}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 30.594 & 0.02 & \textbf{0.2} & 31.752 & \framebox{0.058} & \framebox{0.795} & 30.662 & 0.022 & \textbf{0.204} & 29.974 & \textbf{-0.001} & \textbf{0.195} \\ 
   &  & 30.706 & 0.024 & \textbf{0.183} & 30.503 & \textbf{0.017} & \textbf{0.187} & 29.123 & -0.029 & \framebox{1.119} & 30.661 & \textbf{0.022} & \textbf{0.17} \\ 
   & \multirow{2}{*}{V2} & 28.592 & -0.047 & \textbf{0.398} & 27.584 & -0.081 & \framebox{0.664} & 28.614 & -0.046 & \textbf{0.398} & 29.914 & \textbf{-0.003} & 0.44 \\ 
   &  & 28.779 & -0.041 & \textbf{0.418} & 37.559 & \framebox{0.252} & \framebox{23.546} & 28.967 & \textbf{-0.034} & \textbf{0.418} & 28.962 & \textbf{-0.035} & 0.465 \\ 
   & \multirow{2}{*}{V3} & 29.046 & \textbf{-0.032} & \framebox{\textbf{0.754}} & 24.048 & -0.198 & \framebox{13.709} & 29.047 & \textbf{-0.032} & \framebox{0.755} & 28.985 & \textbf{-0.034} & \framebox{\textbf{0.725}} \\ 
   &  & 26.581 & -0.114 & \framebox{\textbf{0.662}} & 25.246 & -0.158 & \framebox{1.86} & 26.572 & -0.114 & \framebox{\textbf{0.66}} & 31.067 & \textbf{0.036} & \framebox{0.884} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 29.391 & \textbf{-0.02} & \textbf{0.182} & 29.318 & \textbf{-0.023} & \textbf{0.186} & 29.386 & \textbf{-0.02} & \textbf{0.184} & 29.359 & \textbf{-0.021} & \textbf{0.185} \\ 
   &  & 30.314 & 0.01 & \textbf{0.197} & 30.180 & \textbf{0.006} & \textbf{0.204} & 29.904 & \textbf{-0.003} & 0.295 & 30.341 & 0.011 & \textbf{0.208} \\ 
   & \multirow{2}{*}{V2} & 31.203 & \textbf{0.04} & \textbf{0.386} & 31.115 & \textbf{0.037} & \textbf{0.394} & 31.221 & \textbf{0.041} & \textbf{0.386} & 31.214 & \textbf{0.04} & \textbf{0.386} \\ 
   &  & 29.372 & \textbf{-0.021} & \textbf{0.41} & 28.415 & -0.053 & \framebox{0.695} & 29.426 & \textbf{-0.019} & \textbf{0.409} & 29.365 & \textbf{-0.021} & \textbf{0.411} \\ 
   & \multirow{2}{*}{V3} & 30.114 & \textbf{0.004} & \framebox{\textbf{0.802}} & 29.908 & \textbf{-0.003} & \framebox{0.854} & 30.112 & \textbf{0.004} & \framebox{\textbf{0.802}} & 30.118 & \textbf{0.004} & \framebox{\textbf{0.802}} \\ 
   &  & 31.250 & \textbf{0.042} & \framebox{\textbf{0.876}} & 36.108 & \framebox{0.204} & \framebox{20.655} & 31.274 & \textbf{0.042} & \framebox{\textbf{0.875}} & 31.240 & \textbf{0.041} & \framebox{\textbf{0.876}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 29.847 & \textbf{-0.005} & \textbf{0.094} & 29.848 & \textbf{-0.005} & \textbf{0.095} & 29.847 & \textbf{-0.005} & \textbf{0.095} & 29.174 & -0.028 & \textbf{0.099} \\ 
   &  & 29.335 & \textbf{-0.022} & \textbf{0.1} & 29.339 & \textbf{-0.022} & \textbf{0.1} & 29.350 & \textbf{-0.022} & \textbf{0.101} & 30.923 & 0.031 & \textbf{0.104} \\ 
   & \multirow{2}{*}{V2} & 29.909 & \textbf{-0.003} & \textbf{0.232} & 29.642 & -0.012 & \textbf{0.255} & 29.908 & \textbf{-0.003} & \textbf{0.232} & 29.997 & \textbf{0.000} & \textbf{0.245} \\ 
   &  & 30.015 & \textbf{0.000} & \textbf{0.245} & 47.684 & \framebox{0.589} & \framebox{152.789} & 30.025 & \textbf{0.001} & \textbf{0.245} & 29.631 & -0.012 & \textbf{0.233} \\ 
   & \multirow{2}{*}{V3} & 28.750 & -0.042 & \framebox{0.534} & 28.744 & -0.042 & \framebox{0.534} & 28.745 & -0.042 & \framebox{0.534} & 29.986 & \textbf{0.000} & \textbf{0.425} \\ 
   &  & 28.612 & -0.046 & \textbf{0.439} & 26.555 & -0.115 & \framebox{0.896} & 28.628 & -0.046 & \textbf{0.438} & 31.154 & \textbf{0.038} & \textbf{0.438} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 30.133 & \textbf{0.004} & \textbf{0.101} & 30.105 & \textbf{0.003} & \textbf{0.102} & 30.129 & \textbf{0.004} & \textbf{0.101} & 30.129 & \textbf{0.004} & \textbf{0.101} \\ 
   &  & 30.178 & \textbf{0.006} & \textbf{0.097} & 30.135 & \textbf{0.004} & \textbf{0.098} & 30.218 & \textbf{0.007} & \textbf{0.097} & 30.214 & \textbf{0.007} & \textbf{0.098} \\ 
   & \multirow{2}{*}{V2} & 29.448 & \textbf{-0.018} & \textbf{0.21} & 29.507 & \textbf{-0.016} & \textbf{0.211} & 29.443 & \textbf{-0.019} & \textbf{0.21} & 29.446 & \textbf{-0.018} & \textbf{0.21} \\ 
   &  & 30.388 & \textbf{0.013} & \textbf{0.239} & 30.586 & 0.02 & 0.319 & 30.417 & \textbf{0.014} & \textbf{0.239} & 30.383 & \textbf{0.013} & \textbf{0.239} \\ 
   & \multirow{2}{*}{V3} & 30.215 & \textbf{0.007} & \textbf{0.464} & 30.260 & \textbf{0.009} & \textbf{0.466} & 30.209 & \textbf{0.007} & \textbf{0.464} & 30.215 & \textbf{0.007} & \textbf{0.464} \\ 
   &  & 29.909 & \textbf{-0.003} & \textbf{0.408} & 29.485 & -0.017 & \framebox{0.562} & 29.928 & \textbf{-0.002} & \textbf{0.407} & 29.899 & \textbf{-0.003} & \textbf{0.408} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 30.162 & \textbf{0.005} & \textbf{0.043} & 30.151 & \textbf{0.005} & \textbf{0.043} & 30.155 & \textbf{0.005} & \textbf{0.043} & 30.181 & \textbf{0.006} & \textbf{0.045} \\ 
   &  & 29.891 & \textbf{-0.004} & \textbf{0.041} & 29.855 & \textbf{-0.005} & \textbf{0.041} & 29.909 & \textbf{-0.003} & \textbf{0.041} & 29.952 & \textbf{-0.002} & \textbf{0.039} \\ 
   & \multirow{2}{*}{V2} & 29.623 & \textbf{-0.013} & \textbf{0.108} & 29.626 & \textbf{-0.012} & \textbf{0.108} & 29.619 & \textbf{-0.013} & \textbf{0.108} & 29.619 & \textbf{-0.013} & \textbf{0.097} \\ 
   &  & 29.684 & \textbf{-0.011} & \textbf{0.092} & 27.831 & -0.072 & \framebox{1.867} & 29.696 & \textbf{-0.01} & \textbf{0.092} & 29.451 & -0.018 & \textbf{0.106} \\ 
   & \multirow{2}{*}{V3} & 29.894 & \textbf{-0.004} & \textbf{0.187} & 29.906 & \textbf{-0.003} & \textbf{0.187} & 29.898 & \textbf{-0.003} & \textbf{0.187} & 29.984 & \textbf{-0.001} & \textbf{0.208} \\ 
   &  & 29.483 & -0.017 & 0.212 & 30.076 & \textbf{0.003} & \framebox{1.85} & 29.510 & -0.016 & 0.212 & 29.926 & \textbf{-0.002} & \textbf{0.173} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 29.961 & \textbf{-0.001} & \textbf{0.047} & 29.958 & \textbf{-0.001} & \textbf{0.047} & 29.963 & \textbf{-0.001} & \textbf{0.047} & 29.961 & \textbf{-0.001} & \textbf{0.047} \\ 
   &  & 29.956 & \textbf{-0.001} & \textbf{0.043} & 29.936 & \textbf{-0.002} & \textbf{0.043} & 29.978 & \textbf{-0.001} & \textbf{0.043} & 29.965 & \textbf{-0.001} & \textbf{0.042} \\ 
   & \multirow{2}{*}{V2} & 29.933 & \textbf{-0.002} & \textbf{0.103} & 29.949 & \textbf{-0.002} & \textbf{0.103} & 29.931 & \textbf{-0.002} & \textbf{0.103} & 29.933 & \textbf{-0.002} & \textbf{0.103} \\ 
   &  & 29.434 & \textbf{-0.019} & \textbf{0.095} & 29.295 & \textbf{-0.023} & \textbf{0.095} & 29.439 & \textbf{-0.019} & \textbf{0.095} & 29.435 & \textbf{-0.019} & \textbf{0.095} \\ 
   & \multirow{2}{*}{V3} & 29.278 & \textbf{-0.024} & \textbf{0.197} & 29.290 & \textbf{-0.024} & \textbf{0.198} & 29.280 & \textbf{-0.024} & \textbf{0.197} & 29.279 & \textbf{-0.024} & \textbf{0.197} \\ 
   &  & 29.283 & -0.024 & \textbf{0.185} & 29.717 & \textbf{-0.009} & 0.344 & 29.290 & -0.024 & \textbf{0.185} & 29.279 & -0.024 & \textbf{0.185} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\gamma_{10}=30$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:41:32 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\gamma}_{11}$ & MRBIAS & MRMSE & $\hat{\gamma}_{11}$ & MRBIAS & MRMSE & $\hat{\gamma}_{11}$ & MRBIAS & MRMSE & $\hat{\gamma}_{11}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 4.970 & \textbf{-0.006} & \textbf{0.291} & 4.730 & -0.054 & \framebox{1.474} & 4.970 & \textbf{-0.006} & \textbf{0.293} & 5.155 & 0.031 & \textbf{0.288} \\ 
   &  & 4.902 & \textbf{-0.02} & \textbf{0.268} & 4.915 & \textbf{-0.017} & \textbf{0.27} & 5.776 & \framebox{0.155} & \framebox{12.053} & 4.882 & -0.024 & \textbf{0.259} \\ 
   & \multirow{2}{*}{V2} & 5.237 & 0.047 & \framebox{\textbf{0.622}} & 5.404 & \framebox{0.081} & \framebox{0.803} & 5.233 & 0.047 & \framebox{\textbf{0.624}} & 5.033 & \textbf{0.007} & \framebox{\textbf{0.641}} \\ 
   &  & 5.167 & \textbf{0.033} & \framebox{\textbf{0.63}} & 3.238 & -0.352 & \framebox{48.573} & 5.143 & \textbf{0.029} & \framebox{\textbf{0.633}} & 5.183 & 0.037 & \framebox{\textbf{0.65}} \\ 
   & \multirow{2}{*}{V3} & 5.255 & \framebox{\textbf{0.051}} & \framebox{\textbf{1.112}} & 6.010 & \framebox{0.202} & \framebox{10.534} & 5.255 & \framebox{\textbf{0.051}} & \framebox{\textbf{1.114}} & 5.223 & \textbf{0.045} & \framebox{\textbf{1.086}} \\ 
   &  & 5.733 & \framebox{0.147} & \framebox{\textbf{1.086}} & 6.025 & \framebox{0.205} & \framebox{4.288} & 5.737 & \framebox{0.147} & \framebox{\textbf{1.083}} & 4.825 & \textbf{-0.035} & \framebox{1.262} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 5.109 & \textbf{0.022} & \textbf{0.276} & 5.119 & \textbf{0.024} & \textbf{0.28} & 5.111 & \textbf{0.022} & \textbf{0.279} & 5.115 & \textbf{0.023} & \textbf{0.28} \\ 
   &  & 4.923 & -0.015 & \textbf{0.304} & 4.945 & -0.011 & \textbf{0.308} & 4.990 & \textbf{-0.002} & 0.36 & 4.928 & -0.014 & \textbf{0.314} \\ 
   & \multirow{2}{*}{V2} & 4.759 & \textbf{-0.048} & \framebox{\textbf{0.562}} & 4.774 & \textbf{-0.045} & \framebox{\textbf{0.578}} & 4.755 & \textbf{-0.049} & \framebox{\textbf{0.563}} & 4.757 & \textbf{-0.049} & \framebox{\textbf{0.564}} \\ 
   &  & 5.102 & \textbf{0.02} & \framebox{\textbf{0.582}} & 5.186 & 0.037 & \framebox{1.025} & 5.098 & \textbf{0.02} & \framebox{\textbf{0.581}} & 5.105 & \textbf{0.021} & \framebox{\textbf{0.582}} \\ 
   & \multirow{2}{*}{V3} & 4.952 & -0.01 & \framebox{\textbf{1.22}} & 4.984 & \textbf{-0.003} & \framebox{1.281} & 4.953 & \textbf{-0.009} & \framebox{\textbf{1.22}} & 4.951 & -0.01 & \framebox{\textbf{1.22}} \\ 
   &  & 4.924 & \textbf{-0.015} & \framebox{\textbf{1.22}} & 3.746 & -0.251 & \framebox{30.511} & 4.919 & \textbf{-0.016} & \framebox{\textbf{1.218}} & 4.924 & \textbf{-0.015} & \framebox{\textbf{1.22}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 5.087 & \textbf{0.017} & \textbf{0.139} & 5.087 & \textbf{0.017} & \textbf{0.14} & 5.083 & \textbf{0.017} & \textbf{0.14} & 5.093 & \textbf{0.019} & \textbf{0.151} \\ 
   &  & 5.121 & \textbf{0.024} & \textbf{0.143} & 5.125 & \textbf{0.025} & \textbf{0.143} & 5.118 & \textbf{0.024} & \textbf{0.146} & 4.898 & \textbf{-0.02} & \textbf{0.158} \\ 
   & \multirow{2}{*}{V2} & 5.143 & 0.029 & \textbf{0.325} & 5.197 & 0.039 & \textbf{0.351} & 5.143 & 0.029 & \textbf{0.325} & 5.023 & \textbf{0.005} & 0.375 \\ 
   &  & 4.893 & -0.021 & \textbf{0.348} & 1.560 & -0.688 & \framebox{190.472} & 4.898 & -0.02 & \textbf{0.349} & 5.008 & \textbf{0.002} & \textbf{0.322} \\ 
   & \multirow{2}{*}{V3} & 5.241 & 0.048 & \framebox{0.742} & 5.237 & 0.047 & \framebox{0.741} & 5.243 & 0.049 & \framebox{0.741} & 4.957 & \textbf{-0.009} & \framebox{\textbf{0.657}} \\ 
   &  & 5.152 & 0.03 & \framebox{\textbf{0.617}} & 5.355 & \framebox{0.071} & \framebox{1.023} & 5.151 & 0.03 & \framebox{\textbf{0.617}} & 5.020 & \textbf{0.004} & \framebox{\textbf{0.622}} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 4.940 & \textbf{-0.012} & \textbf{0.145} & 4.945 & \textbf{-0.011} & \textbf{0.145} & 4.940 & \textbf{-0.012} & \textbf{0.145} & 4.940 & \textbf{-0.012} & \textbf{0.145} \\ 
   &  & 4.992 & \textbf{-0.002} & \textbf{0.14} & 4.990 & \textbf{-0.002} & \textbf{0.14} & 4.995 & \textbf{-0.001} & \textbf{0.14} & 4.990 & \textbf{-0.002} & \textbf{0.14} \\ 
   & \multirow{2}{*}{V2} & 5.142 & \textbf{0.028} & \textbf{0.304} & 5.134 & \textbf{0.027} & \textbf{0.303} & 5.143 & \textbf{0.029} & \textbf{0.304} & 5.143 & \textbf{0.029} & \textbf{0.304} \\ 
   &  & 4.935 & \textbf{-0.013} & \textbf{0.342} & 4.964 & \textbf{-0.007} & 0.4 & 4.934 & \textbf{-0.013} & \textbf{0.342} & 4.936 & \textbf{-0.013} & \textbf{0.342} \\ 
   & \multirow{2}{*}{V3} & 4.963 & \textbf{-0.007} & \framebox{\textbf{0.701}} & 4.957 & \textbf{-0.009} & \framebox{\textbf{0.703}} & 4.964 & \textbf{-0.007} & \framebox{\textbf{0.701}} & 4.963 & \textbf{-0.007} & \framebox{\textbf{0.701}} \\ 
   &  & 5.050 & \textbf{0.01} & \framebox{\textbf{0.624}} & 5.078 & \textbf{0.016} & \framebox{1.073} & 5.048 & \textbf{0.01} & \framebox{\textbf{0.624}} & 5.050 & \textbf{0.01} & \framebox{\textbf{0.624}} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 4.974 & \textbf{-0.005} & \textbf{0.06} & 4.975 & \textbf{-0.005} & \textbf{0.06} & 4.976 & \textbf{-0.005} & \textbf{0.06} & 4.943 & \textbf{-0.011} & \textbf{0.065} \\ 
   &  & 5.037 & 0.007 & \textbf{0.063} & 5.038 & 0.008 & \textbf{0.063} & 5.038 & 0.008 & \textbf{0.063} & 4.999 & \textbf{0.000} & \textbf{0.061} \\ 
   & \multirow{2}{*}{V2} & 5.044 & \textbf{0.009} & \textbf{0.155} & 5.044 & \textbf{0.009} & \textbf{0.155} & 5.044 & \textbf{0.009} & \textbf{0.155} & 5.070 & \textbf{0.014} & \textbf{0.144} \\ 
   &  & 5.091 & \textbf{0.018} & \textbf{0.136} & 5.623 & \framebox{0.125} & \framebox{5.958} & 5.092 & \textbf{0.018} & \textbf{0.136} & 5.149 & 0.03 & \textbf{0.154} \\ 
   & \multirow{2}{*}{V3} & 5.104 & 0.021 & \textbf{0.284} & 5.102 & 0.02 & \textbf{0.284} & 5.103 & 0.021 & \textbf{0.284} & 5.021 & \textbf{0.004} & \textbf{0.311} \\ 
   &  & 5.109 & 0.022 & 0.311 & 5.089 & 0.018 & \framebox{1.676} & 5.105 & 0.021 & 0.311 & 4.966 & \textbf{-0.007} & \textbf{0.232} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 4.972 & \textbf{-0.006} & \textbf{0.067} & 4.972 & \textbf{-0.006} & \textbf{0.067} & 4.971 & \textbf{-0.006} & \textbf{0.067} & 4.972 & \textbf{-0.006} & \textbf{0.067} \\ 
   &  & 5.019 & \textbf{0.004} & \textbf{0.061} & 5.016 & \textbf{0.003} & \textbf{0.061} & 5.018 & \textbf{0.004} & \textbf{0.061} & 5.018 & \textbf{0.004} & \textbf{0.061} \\ 
   & \multirow{2}{*}{V2} & 4.972 & \textbf{-0.006} & \textbf{0.144} & 4.968 & \textbf{-0.006} & \textbf{0.145} & 4.972 & \textbf{-0.006} & \textbf{0.144} & 4.972 & \textbf{-0.006} & \textbf{0.144} \\ 
   &  & 5.076 & \textbf{0.015} & \textbf{0.141} & 5.084 & \textbf{0.017} & \textbf{0.139} & 5.077 & \textbf{0.015} & \textbf{0.141} & 5.076 & \textbf{0.015} & \textbf{0.141} \\ 
   & \multirow{2}{*}{V3} & 5.209 & \textbf{0.042} & \textbf{0.301} & 5.207 & \textbf{0.041} & \textbf{0.301} & 5.209 & \textbf{0.042} & \textbf{0.301} & 5.209 & \textbf{0.042} & \textbf{0.301} \\ 
   &  & 5.141 & 0.028 & \textbf{0.281} & 4.931 & \textbf{-0.014} & \framebox{1.137} & 5.140 & 0.028 & \textbf{0.281} & 5.141 & 0.028 & \textbf{0.281} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\gamma_{11}=5$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:43:44 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\sigma}^2$ & MRBIAS & MRMSE & $\hat{\sigma}^2$ & MRBIAS & MRMSE & $\hat{\sigma}^2$ & MRBIAS & MRMSE & $\hat{\sigma}^2$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 1996.607 & \textbf{-0.002} & \textbf{0.004} & 2004.224 & \textbf{0.002} & \textbf{0.004} & 2004.382 & \textbf{0.002} & \textbf{0.004} & 2004.455 & \textbf{0.002} & \textbf{0.004} \\ 
   &  & 1981.233 & \textbf{-0.009} & \textbf{0.013} & 1989.807 & \textbf{-0.005} & \textbf{0.013} & 1989.655 & \textbf{-0.005} & \textbf{0.013} & 2009.143 & \textbf{0.005} & \textbf{0.014} \\ 
   & \multirow{2}{*}{V2} & 1997.989 & \textbf{-0.001} & \textbf{0.003} & 2001.083 & \textbf{0.001} & \textbf{0.005} & 1998.573 & \textbf{-0.001} & \textbf{0.003} & 2006.393 & \textbf{0.003} & \textbf{0.003} \\ 
   &  & 1988.793 & \textbf{-0.006} & \textbf{0.013} & 1990.061 & \textbf{-0.005} & \textbf{0.019} & 1990.138 & \textbf{-0.005} & \textbf{0.013} & 1977.546 & \textbf{-0.011} & \textbf{0.012} \\ 
   & \multirow{2}{*}{V3} & 2001.695 & \textbf{0.001} & \textbf{0.004} & 2007.577 & \textbf{0.004} & \textbf{0.009} & 2002.119 & \textbf{0.001} & \textbf{0.004} & 2007.656 & \textbf{0.004} & \textbf{0.003} \\ 
   &  & 1997.795 & \textbf{-0.001} & \textbf{0.015} & 1994.662 & \textbf{-0.003} & 0.054 & 1996.349 & \textbf{-0.002} & \textbf{0.015} & 2005.585 & \textbf{0.003} & \textbf{0.012} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 1980.177 & \textbf{-0.01} & \textbf{0.004} & 1986.030 & \textbf{-0.007} & \textbf{0.004} & 1985.792 & \textbf{-0.007} & \textbf{0.004} & 1985.123 & \textbf{-0.007} & \textbf{0.004} \\ 
   &  & 2001.383 & \textbf{0.001} & \textbf{0.014} & 2008.628 & \textbf{0.004} & \textbf{0.015} & 2009.247 & \textbf{0.005} & \textbf{0.015} & 2008.908 & \textbf{0.004} & \textbf{0.015} \\ 
   & \multirow{2}{*}{V2} & 1998.845 & \textbf{-0.001} & \textbf{0.003} & 1997.329 & \textbf{-0.001} & \textbf{0.004} & 1999.504 & \textbf{0.000} & \textbf{0.003} & 1999.238 & \textbf{0.000} & \textbf{0.003} \\ 
   &  & 2008.461 & \textbf{0.004} & \textbf{0.013} & 2009.068 & \textbf{0.005} & \textbf{0.017} & 2010.514 & \textbf{0.005} & \textbf{0.013} & 2010.203 & \textbf{0.005} & \textbf{0.013} \\ 
   & \multirow{2}{*}{V3} & 1995.438 & \textbf{-0.002} & \textbf{0.003} & 1997.463 & \textbf{-0.001} & \textbf{0.006} & 1994.914 & \textbf{-0.003} & \textbf{0.003} & 1995.173 & \textbf{-0.002} & \textbf{0.003} \\ 
   &  & 1986.212 & \textbf{-0.007} & \textbf{0.012} & 2009.359 & \textbf{0.005} & \textbf{0.021} & 1986.772 & \textbf{-0.007} & \textbf{0.011} & 1986.264 & \textbf{-0.007} & \textbf{0.012} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 1998.073 & \textbf{-0.001} & \textbf{0.002} & 2002.603 & \textbf{0.001} & \textbf{0.002} & 2002.662 & \textbf{0.001} & \textbf{0.002} & 1999.254 & \textbf{0.000} & \textbf{0.002} \\ 
   &  & 1994.226 & \textbf{-0.003} & \textbf{0.002} & 1997.437 & \textbf{-0.001} & \textbf{0.002} & 1998.287 & \textbf{-0.001} & \textbf{0.002} & 2001.022 & \textbf{0.001} & \textbf{0.007} \\ 
   & \multirow{2}{*}{V2} & 1997.519 & \textbf{-0.001} & \textbf{0.002} & 2000.362 & \textbf{0.000} & \textbf{0.003} & 1997.596 & \textbf{-0.001} & \textbf{0.002} & 2003.567 & \textbf{0.002} & \textbf{0.002} \\ 
   &  & 2007.124 & \textbf{0.004} & \textbf{0.009} & 2001.054 & \textbf{0.001} & \textbf{0.014} & 2007.773 & \textbf{0.004} & \textbf{0.009} & 2000.092 & \textbf{0.000} & \textbf{0.007} \\ 
   & \multirow{2}{*}{V3} & 1992.513 & \textbf{-0.004} & \textbf{0.002} & 1991.452 & \textbf{-0.004} & \textbf{0.008} & 1992.026 & \textbf{-0.004} & \textbf{0.002} & 1996.014 & \textbf{-0.002} & \textbf{0.002} \\ 
   &  & 2009.008 & \textbf{0.005} & \textbf{0.007} & 1998.932 & \textbf{-0.001} & \textbf{0.029} & 2007.891 & \textbf{0.004} & \textbf{0.007} & 2003.804 & \textbf{0.002} & \textbf{0.008} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 1993.519 & \textbf{-0.003} & \textbf{0.002} & 1997.646 & \textbf{-0.001} & \textbf{0.002} & 1997.037 & \textbf{-0.001} & \textbf{0.002} & 1996.942 & \textbf{-0.002} & \textbf{0.002} \\ 
   &  & 1999.995 & \textbf{0.000} & \textbf{0.008} & 2004.941 & \textbf{0.002} & \textbf{0.008} & 2004.566 & \textbf{0.002} & \textbf{0.008} & 2004.330 & \textbf{0.002} & \textbf{0.008} \\ 
   & \multirow{2}{*}{V2} & 1999.895 & \textbf{0.000} & \textbf{0.002} & 2003.581 & \textbf{0.002} & \textbf{0.002} & 1999.923 & \textbf{0.000} & \textbf{0.002} & 1999.849 & \textbf{0.000} & \textbf{0.002} \\ 
   &  & 1997.716 & \textbf{-0.001} & \textbf{0.007} & 1998.592 & \textbf{-0.001} & \textbf{0.008} & 1997.677 & \textbf{-0.001} & \textbf{0.007} & 1997.707 & \textbf{-0.001} & \textbf{0.007} \\ 
   & \multirow{2}{*}{V3} & 2001.893 & \textbf{0.001} & \textbf{0.002} & 2003.526 & \textbf{0.002} & \textbf{0.004} & 2001.668 & \textbf{0.001} & \textbf{0.002} & 2001.797 & \textbf{0.001} & \textbf{0.002} \\ 
   &  & 1992.430 & \textbf{-0.004} & \textbf{0.008} & 1987.691 & \textbf{-0.006} & \textbf{0.015} & 1991.973 & \textbf{-0.004} & \textbf{0.008} & 1992.055 & \textbf{-0.004} & \textbf{0.008} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 1998.631 & \textbf{-0.001} & \textbf{0.001} & 2000.621 & \textbf{0.000} & \textbf{0.001} & 2000.182 & \textbf{0.000} & \textbf{0.001} & 2003.485 & \textbf{0.002} & \textbf{0.001} \\ 
   &  & 1999.691 & \textbf{0.000} & \textbf{0.003} & 2002.250 & \textbf{0.001} & \textbf{0.003} & 2001.786 & \textbf{0.001} & \textbf{0.003} & 2002.041 & \textbf{0.001} & \textbf{0.003} \\ 
   & \multirow{2}{*}{V2} & 1999.101 & \textbf{0.000} & \textbf{0.001} & 1998.493 & \textbf{-0.001} & \textbf{0.001} & 1998.988 & \textbf{-0.001} & \textbf{0.001} & 1998.251 & \textbf{-0.001} & \textbf{0.001} \\ 
   &  & 1997.849 & \textbf{-0.001} & \textbf{0.003} & 1989.342 & \textbf{-0.005} & \textbf{0.006} & 1997.504 & \textbf{-0.001} & \textbf{0.003} & 2009.037 & \textbf{0.005} & \textbf{0.003} \\ 
   & \multirow{2}{*}{V3} & 1998.931 & \textbf{-0.001} & \textbf{0.001} & 2005.829 & \textbf{0.003} & \textbf{0.003} & 1998.778 & \textbf{-0.001} & \textbf{0.001} & 1996.699 & \textbf{-0.002} & \textbf{0.001} \\ 
   &  & 2000.688 & \textbf{0.000} & \textbf{0.004} & 2002.146 & \textbf{0.001} & \textbf{0.018} & 2000.943 & \textbf{0.000} & \textbf{0.004} & 1995.200 & \textbf{-0.002} & \textbf{0.003} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 1997.572 & \textbf{-0.001} & \textbf{0.001} & 1998.746 & \textbf{-0.001} & \textbf{0.001} & 1998.575 & \textbf{-0.001} & \textbf{0.001} & 1998.453 & \textbf{-0.001} & \textbf{0.001} \\ 
   &  & 2002.691 & \textbf{0.001} & \textbf{0.003} & 2003.897 & \textbf{0.002} & \textbf{0.003} & 2004.093 & \textbf{0.002} & \textbf{0.003} & 2003.995 & \textbf{0.002} & \textbf{0.003} \\ 
   & \multirow{2}{*}{V2} & 1998.763 & \textbf{-0.001} & \textbf{0.001} & 1998.299 & \textbf{-0.001} & \textbf{0.001} & 1998.621 & \textbf{-0.001} & \textbf{0.001} & 1998.678 & \textbf{-0.001} & \textbf{0.001} \\ 
   &  & 1998.356 & \textbf{-0.001} & \textbf{0.004} & 1998.981 & \textbf{-0.001} & \textbf{0.005} & 1998.338 & \textbf{-0.001} & \textbf{0.004} & 1998.184 & \textbf{-0.001} & \textbf{0.004} \\ 
   & \multirow{2}{*}{V3} & 2001.971 & \textbf{0.001} & \textbf{0.001} & 2003.516 & \textbf{0.002} & \textbf{0.002} & 2001.998 & \textbf{0.001} & \textbf{0.001} & 2001.973 & \textbf{0.001} & \textbf{0.001} \\ 
   &  & 2006.417 & \textbf{0.003} & \textbf{0.003} & 2010.368 & \textbf{0.005} & \textbf{0.008} & 2006.149 & \textbf{0.003} & \textbf{0.003} & 2006.259 & \textbf{0.003} & \textbf{0.003} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\sigma^2=2000$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:45:50 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\tau}_{00}$ & MRBIAS & MRMSE & $\hat{\tau}_{00}$ & MRBIAS & MRMSE & $\hat{\tau}_{00}$ & MRBIAS & MRMSE & $\hat{\tau}_{00}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 105.688 & \framebox{0.057} & \textbf{0.332} & 101.236 & \textbf{0.012} & 0.367 & 101.556 & \textbf{0.016} & \textbf{0.351} & 103.382 & 0.034 & 0.442 \\ 
   &  & 106.848 & \framebox{0.068} & \framebox{\textbf{0.878}} & 102.815 & \textbf{0.028} & \framebox{1.002} & 104.005 & 0.04 & \framebox{\textbf{0.904}} & 102.744 & \textbf{0.027} & \framebox{1.036} \\ 
   & \multirow{2}{*}{V2} & 813.820 & 0.017 & \textbf{0.139} & 806.666 & \textbf{0.008} & \textbf{0.147} & 813.681 & 0.017 & \textbf{0.138} & 784.561 & -0.019 & \textbf{0.127} \\ 
   &  & 779.879 & -0.025 & \framebox{0.774} & 781.195 & -0.024 & \framebox{0.872} & 779.301 & -0.026 & \framebox{0.773} & 797.975 & \textbf{-0.003} & \framebox{\textbf{0.619}} \\ 
   & \multirow{2}{*}{V3} & 2019.621 & \textbf{0.01} & \textbf{0.126} & 2018.781 & \textbf{0.009} & \textbf{0.132} & 2019.443 & \textbf{0.01} & \textbf{0.125} & 1989.357 & \textbf{-0.005} & \textbf{0.113} \\ 
   &  & 1989.975 & \textbf{-0.005} & \framebox{\textbf{0.714}} & 2001.573 & \textbf{0.001} & \framebox{0.8} & 1990.859 & \textbf{-0.005} & \framebox{\textbf{0.71}} & 2137.521 & \framebox{0.069} & \framebox{0.812} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 104.265 & 0.043 & \textbf{0.375} & 102.209 & \textbf{0.022} & \textbf{0.375} & 102.313 & \textbf{0.023} & \textbf{0.368} & 102.172 & \textbf{0.022} & \textbf{0.37} \\ 
   &  & 103.130 & 0.031 & \framebox{\textbf{0.961}} & 99.719 & \textbf{-0.003} & \framebox{\textbf{0.933}} & 100.203 & \textbf{0.002} & \framebox{\textbf{0.956}} & 100.199 & \textbf{0.002} & \framebox{\textbf{0.953}} \\ 
   & \multirow{2}{*}{V2} & 797.038 & \textbf{-0.004} & \textbf{0.137} & 795.638 & \textbf{-0.005} & \textbf{0.139} & 796.711 & \textbf{-0.004} & \textbf{0.137} & 796.552 & \textbf{-0.004} & \textbf{0.137} \\ 
   &  & 806.851 & \textbf{0.009} & \framebox{\textbf{0.714}} & 804.989 & \textbf{0.006} & \framebox{\textbf{0.721}} & 805.850 & \textbf{0.007} & \framebox{\textbf{0.712}} & 805.893 & \textbf{0.007} & \framebox{\textbf{0.714}} \\ 
   & \multirow{2}{*}{V3} & 1978.445 & \textbf{-0.011} & \textbf{0.129} & 1980.723 & \textbf{-0.01} & \textbf{0.132} & 1978.533 & \textbf{-0.011} & \textbf{0.129} & 1978.446 & \textbf{-0.011} & \textbf{0.129} \\ 
   &  & 2001.602 & \textbf{0.001} & \framebox{\textbf{0.759}} & 1987.639 & \textbf{-0.006} & \framebox{\textbf{0.749}} & 1997.727 & \textbf{-0.001} & \framebox{\textbf{0.754}} & 2000.789 & \textbf{0.000} & \framebox{\textbf{0.757}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 102.729 & 0.027 & \textbf{0.202} & 100.334 & \textbf{0.003} & \textbf{0.219} & 99.990 & \textbf{0.000} & \textbf{0.214} & 105.808 & \framebox{0.058} & \textbf{0.219} \\ 
   &  & 105.096 & \framebox{0.051} & \textbf{0.225} & 103.388 & 0.034 & \textbf{0.247} & 102.809 & 0.028 & \textbf{0.237} & 100.354 & \textbf{0.004} & \framebox{0.582} \\ 
   & \multirow{2}{*}{V2} & 809.436 & 0.012 & \textbf{0.081} & 806.277 & \textbf{0.008} & \textbf{0.097} & 809.243 & 0.012 & \textbf{0.082} & 797.396 & \textbf{-0.003} & \textbf{0.081} \\ 
   &  & 784.184 & \textbf{-0.02} & \textbf{0.404} & 785.728 & \textbf{-0.018} & 0.452 & 784.962 & \textbf{-0.019} & \textbf{0.403} & 829.332 & 0.037 & 0.434 \\ 
   & \multirow{2}{*}{V3} & 1968.909 & -0.016 & \textbf{0.058} & 1965.347 & -0.017 & \textbf{0.069} & 1969.448 & \textbf{-0.015} & \textbf{0.058} & 1981.284 & \textbf{-0.009} & \textbf{0.061} \\ 
   &  & 1932.005 & -0.034 & \textbf{0.36} & 1952.211 & \textbf{-0.024} & 0.408 & 1934.263 & -0.033 & \textbf{0.362} & 2126.034 & \framebox{0.063} & \framebox{0.523} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 102.810 & 0.028 & \textbf{0.223} & 100.864 & \textbf{0.009} & \textbf{0.211} & 101.185 & \textbf{0.012} & \textbf{0.219} & 101.353 & \textbf{0.014} & \textbf{0.219} \\ 
   &  & 104.152 & 0.042 & \framebox{\textbf{0.536}} & 101.773 & \textbf{0.018} & \framebox{\textbf{0.529}} & 101.895 & \textbf{0.019} & \framebox{\textbf{0.54}} & 102.037 & \textbf{0.02} & \framebox{\textbf{0.538}} \\ 
   & \multirow{2}{*}{V2} & 805.014 & \textbf{0.006} & \textbf{0.067} & 806.653 & \textbf{0.008} & \textbf{0.069} & 805.085 & \textbf{0.006} & \textbf{0.067} & 805.077 & \textbf{0.006} & \textbf{0.067} \\ 
   &  & 836.041 & \textbf{0.045} & \framebox{\textbf{0.572}} & 838.135 & \textbf{0.048} & \framebox{0.629} & 835.967 & \textbf{0.045} & \framebox{\textbf{0.574}} & 836.021 & \textbf{0.045} & \framebox{\textbf{0.573}} \\ 
   & \multirow{2}{*}{V3} & 2006.086 & \textbf{0.003} & \textbf{0.067} & 2003.499 & \textbf{0.002} & \textbf{0.07} & 2005.447 & \textbf{0.003} & \textbf{0.067} & 2005.873 & \textbf{0.003} & \textbf{0.067} \\ 
   &  & 2034.770 & \textbf{0.017} & \textbf{0.418} & 2039.521 & \textbf{0.02} & \textbf{0.439} & 2037.131 & \textbf{0.019} & \textbf{0.421} & 2035.177 & \textbf{0.018} & \textbf{0.419} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 101.334 & 0.013 & \textbf{0.084} & 100.009 & \textbf{0.000} & \textbf{0.088} & 100.638 & \textbf{0.006} & \textbf{0.087} & 99.458 & \textbf{-0.005} & \textbf{0.087} \\ 
   &  & 102.418 & 0.024 & \textbf{0.216} & 100.749 & \textbf{0.007} & \textbf{0.237} & 101.446 & 0.014 & \textbf{0.22} & 99.175 & \textbf{-0.008} & 0.255 \\ 
   & \multirow{2}{*}{V2} & 800.327 & \textbf{0.000} & \textbf{0.031} & 797.354 & \textbf{-0.003} & \textbf{0.036} & 799.802 & \textbf{0.000} & \textbf{0.031} & 817.064 & 0.021 & \textbf{0.035} \\ 
   &  & 830.806 & 0.039 & 0.23 & 842.918 & \framebox{0.054} & 0.278 & 831.968 & 0.04 & 0.233 & 803.306 & \textbf{0.004} & \textbf{0.169} \\ 
   & \multirow{2}{*}{V3} & 1971.108 & -0.014 & \textbf{0.028} & 1968.910 & -0.016 & \textbf{0.032} & 1971.801 & -0.014 & \textbf{0.028} & 2006.175 & \textbf{0.003} & \textbf{0.028} \\ 
   &  & 2019.907 & 0.01 & \textbf{0.185} & 2019.624 & 0.01 & 0.229 & 2021.628 & 0.011 & \textbf{0.19} & 1998.285 & \textbf{-0.001} & \textbf{0.171} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 100.414 & \textbf{0.004} & \textbf{0.094} & 99.814 & \textbf{-0.002} & \textbf{0.09} & 100.049 & \textbf{0.000} & \textbf{0.091} & 100.049 & \textbf{0.000} & \textbf{0.091} \\ 
   &  & 99.860 & \textbf{-0.001} & \textbf{0.282} & 99.135 & -0.009 & \textbf{0.278} & 99.544 & \textbf{-0.005} & \textbf{0.277} & 99.503 & \textbf{-0.005} & \textbf{0.279} \\ 
   & \multirow{2}{*}{V2} & 800.628 & \textbf{0.001} & \textbf{0.028} & 799.170 & \textbf{-0.001} & \textbf{0.029} & 800.439 & \textbf{0.001} & \textbf{0.028} & 800.594 & \textbf{0.001} & \textbf{0.028} \\ 
   &  & 803.935 & \textbf{0.005} & \textbf{0.175} & 807.913 & \textbf{0.01} & \textbf{0.187} & 804.585 & \textbf{0.006} & \textbf{0.176} & 804.056 & \textbf{0.005} & \textbf{0.175} \\ 
   & \multirow{2}{*}{V3} & 2009.818 & \textbf{0.005} & \textbf{0.027} & 2006.040 & \textbf{0.003} & \textbf{0.027} & 2009.016 & \textbf{0.005} & \textbf{0.027} & 2009.621 & \textbf{0.005} & \textbf{0.027} \\ 
   &  & 1981.275 & \textbf{-0.009} & \textbf{0.155} & 1982.068 & \textbf{-0.009} & \textbf{0.154} & 1981.281 & \textbf{-0.009} & \textbf{0.154} & 1981.274 & \textbf{-0.009} & \textbf{0.155} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\tau_{00}=100,\ 800,\ 2000$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:47:53 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\tau}_{01}$ & MRBIAS & MRMSE & $\hat{\tau}_{01}$ & MRBIAS & MRMSE & $\hat{\tau}_{01}$ & MRBIAS & MRMSE & $\hat{\tau}_{01}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 33.939 & -0.321 & \framebox{\textbf{2.037}} & 49.055 & \textbf{-0.019} & \framebox{2.591} & 48.103 & -0.038 & \framebox{2.479} & 47.186 & -0.056 & \framebox{2.494} \\ 
   &  & 35.382 & -0.292 & \framebox{\textbf{3.084}} & 50.015 & \textbf{0.000} & \framebox{4.089} & 50.612 & 0.012 & \framebox{3.555} & 51.662 & 0.033 & \framebox{3.12} \\ 
   & \multirow{2}{*}{V2} & 392.823 & -0.018 & \framebox{0.504} & 396.408 & \textbf{-0.009} & \framebox{0.685} & 392.406 & -0.019 & \framebox{0.528} & 397.782 & \textbf{-0.006} & \textbf{0.428} \\ 
   &  & 381.967 & -0.045 & \framebox{1.374} & 400.355 & \textbf{0.001} & \framebox{2.898} & 387.429 & -0.031 & \framebox{1.441} & 402.987 & \textbf{0.007} & \framebox{\textbf{1.324}} \\ 
   & \multirow{2}{*}{V3} & 1002.361 & \textbf{0.002} & \textbf{0.334} & 990.420 & -0.01 & \framebox{0.536} & 1005.486 & \textbf{0.005} & \textbf{0.345} & 1006.940 & \textbf{0.007} & \textbf{0.323} \\ 
   &  & 931.880 & -0.068 & \framebox{\textbf{1.099}} & 975.248 & \textbf{-0.025} & \framebox{1.931} & 918.458 & -0.082 & \framebox{1.166} & 1043.207 & 0.043 & \framebox{1.437} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 30.270 & -0.395 & \framebox{\textbf{1.823}} & 45.226 & \textbf{-0.095} & \framebox{2.466} & 44.594 & -0.108 & \framebox{2.251} & 44.505 & -0.11 & \framebox{2.233} \\ 
   &  & 37.676 & -0.246 & \framebox{\textbf{2.766}} & 54.001 & \framebox{0.08} & \framebox{4.328} & 52.403 & \textbf{0.048} & \framebox{3.19} & 53.277 & \framebox{0.066} & \framebox{3.235} \\ 
   & \multirow{2}{*}{V2} & 397.798 & \textbf{-0.006} & \textbf{0.417} & 401.880 & \textbf{0.005} & \framebox{0.637} & 399.295 & \textbf{-0.002} & \textbf{0.417} & 399.315 & \textbf{-0.002} & \textbf{0.419} \\ 
   &  & 403.924 & \textbf{0.01} & \framebox{\textbf{1.465}} & 409.681 & 0.024 & \framebox{2.398} & 409.369 & 0.023 & \framebox{1.51} & 410.400 & 0.026 & \framebox{\textbf{1.481}} \\ 
   & \multirow{2}{*}{V3} & 1049.577 & \framebox{0.05} & \textbf{0.356} & 1039.029 & \textbf{0.039} & 0.498 & 1048.002 & 0.048 & \textbf{0.363} & 1050.146 & \framebox{0.05} & \textbf{0.356} \\ 
   &  & 1025.434 & 0.025 & \framebox{\textbf{1.347}} & 1053.486 & \framebox{0.053} & \framebox{2.18} & 1009.490 & \textbf{0.009} & \framebox{\textbf{1.366}} & 1026.367 & 0.026 & \framebox{\textbf{1.354}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 41.911 & -0.162 & \framebox{\textbf{1.014}} & 50.079 & \textbf{0.002} & \framebox{1.342} & 50.298 & \textbf{0.006} & \framebox{1.295} & 45.323 & -0.094 & \framebox{1.291} \\ 
   &  & 41.271 & -0.175 & \framebox{\textbf{1.056}} & 49.481 & \textbf{-0.01} & \framebox{1.46} & 49.165 & -0.017 & \framebox{1.287} & 53.034 & \framebox{0.061} & \framebox{1.897} \\ 
   & \multirow{2}{*}{V2} & 415.199 & 0.038 & \textbf{0.236} & 413.536 & 0.034 & 0.35 & 415.497 & 0.039 & 0.24 & 392.598 & \textbf{-0.019} & \textbf{0.208} \\ 
   &  & 380.592 & -0.049 & \framebox{\textbf{0.773}} & 392.766 & -0.018 & \framebox{1.483} & 383.888 & -0.04 & \framebox{\textbf{0.779}} & 398.802 & \textbf{-0.003} & \framebox{\textbf{0.763}} \\ 
   & \multirow{2}{*}{V3} & 957.982 & -0.042 & \textbf{0.173} & 970.396 & -0.03 & 0.278 & 952.974 & -0.047 & \textbf{0.177} & 987.873 & \textbf{-0.012} & \textbf{0.164} \\ 
   &  & 964.472 & -0.036 & \framebox{\textbf{0.67}} & 980.203 & \textbf{-0.02} & \framebox{1.158} & 953.136 & -0.047 & \framebox{\textbf{0.696}} & 1070.785 & \framebox{0.071} & \framebox{0.973} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 41.775 & -0.164 & \framebox{\textbf{0.966}} & 52.009 & 0.04 & \framebox{1.308} & 50.348 & \textbf{0.007} & \framebox{1.207} & 51.415 & 0.028 & \framebox{1.188} \\ 
   &  & 45.192 & -0.096 & \framebox{\textbf{1.56}} & 55.102 & \framebox{0.102} & \framebox{2.135} & 54.346 & \framebox{\textbf{0.087}} & \framebox{1.79} & 55.147 & \framebox{0.103} & \framebox{1.785} \\ 
   & \multirow{2}{*}{V2} & 414.486 & 0.036 & \textbf{0.225} & 409.451 & \textbf{0.024} & 0.299 & 414.258 & 0.036 & \textbf{0.231} & 415.200 & 0.038 & \textbf{0.225} \\ 
   &  & 423.353 & \framebox{0.058} & \framebox{\textbf{1.059}} & 419.180 & \textbf{0.048} & \framebox{1.79} & 424.678 & \framebox{0.062} & \framebox{1.13} & 425.286 & \framebox{0.063} & \framebox{\textbf{1.053}} \\ 
   & \multirow{2}{*}{V3} & 1005.846 & \textbf{0.006} & \textbf{0.177} & 1010.438 & 0.01 & 0.274 & 1003.282 & \textbf{0.003} & \textbf{0.177} & 1005.976 & \textbf{0.006} & \textbf{0.177} \\ 
   &  & 1025.176 & \textbf{0.025} & \framebox{\textbf{0.616}} & 1023.066 & \textbf{0.023} & \framebox{0.983} & 1028.881 & 0.029 & \framebox{0.655} & 1027.534 & \textbf{0.028} & \framebox{\textbf{0.617}} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 42.971 & -0.141 & \textbf{0.437} & 45.473 & -0.091 & \framebox{0.547} & 46.486 & -0.07 & \framebox{0.503} & 48.955 & \textbf{-0.021} & \framebox{0.506} \\ 
   &  & 45.197 & -0.096 & \framebox{\textbf{0.72}} & 49.279 & -0.014 & \framebox{0.97} & 49.876 & \textbf{-0.002} & \framebox{0.775} & 49.783 & \textbf{-0.004} & \framebox{\textbf{0.726}} \\ 
   & \multirow{2}{*}{V2} & 398.760 & \textbf{-0.003} & \textbf{0.107} & 407.665 & 0.019 & 0.16 & 397.203 & \textbf{-0.007} & \textbf{0.111} & 404.229 & 0.011 & \textbf{0.093} \\ 
   &  & 424.967 & \framebox{0.062} & 0.467 & 428.380 & \framebox{0.071} & \framebox{0.84} & 422.347 & \framebox{0.056} & 0.485 & 399.876 & \textbf{0.000} & \textbf{0.372} \\ 
   & \multirow{2}{*}{V3} & 984.158 & -0.016 & \textbf{0.072} & 970.755 & -0.029 & 0.108 & 983.909 & -0.016 & \textbf{0.073} & 1006.057 & \textbf{0.006} & \textbf{0.082} \\ 
   &  & 988.375 & \textbf{-0.012} & \textbf{0.324} & 986.641 & \textbf{-0.013} & 0.489 & 988.322 & \textbf{-0.012} & 0.345 & 986.155 & \textbf{-0.014} & \textbf{0.308} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 46.536 & -0.069 & \framebox{\textbf{0.53}} & 50.367 & \textbf{0.007} & \framebox{0.65} & 49.160 & -0.017 & \framebox{0.613} & 49.651 & \textbf{-0.007} & \framebox{0.608} \\ 
   &  & 45.926 & -0.081 & \framebox{\textbf{0.802}} & 51.736 & 0.035 & \framebox{1.295} & 49.935 & \textbf{-0.001} & \framebox{\textbf{0.815}} & 50.501 & 0.01 & \framebox{0.849} \\ 
   & \multirow{2}{*}{V2} & 402.488 & \textbf{0.006} & \textbf{0.089} & 406.870 & 0.017 & 0.125 & 401.320 & \textbf{0.003} & \textbf{0.092} & 402.729 & \textbf{0.007} & \textbf{0.088} \\ 
   &  & 394.858 & \textbf{-0.013} & \textbf{0.304} & 382.479 & -0.044 & \framebox{0.513} & 397.244 & \textbf{-0.007} & \textbf{0.316} & 395.280 & \textbf{-0.012} & \textbf{0.305} \\ 
   & \multirow{2}{*}{V3} & 1017.313 & \textbf{0.017} & \textbf{0.08} & 1028.545 & 0.029 & 0.12 & 1013.803 & \textbf{0.014} & \textbf{0.081} & 1017.511 & \textbf{0.018} & \textbf{0.08} \\ 
   &  & 977.147 & \textbf{-0.023} & \textbf{0.297} & 971.612 & \textbf{-0.028} & \framebox{0.519} & 974.976 & \textbf{-0.025} & \textbf{0.295} & 977.126 & \textbf{-0.023} & \textbf{0.299} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\tau_{01}=50,\ 400,\ 1000$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

% latex table generated in R 3.2.2 by xtable 1.7-4 package
% Mon Dec 28 21:49:13 2015
\begin{sidewaystable}[H]
\centering
{\footnotesize
\begin{tabular}{cc|ccc|ccc|ccc|ccc|}
   & & \multicolumn{3}{c|}{REML}&\multicolumn{3}{c|}{MINQUE(0)}&\multicolumn{3}{c|}{MINQUE(1)}&\multicolumn{3}{c|}{MINQUE($\theta$)}\\ \hline
 &  & $\hat{\tau}_{11}$ & MRBIAS & MRMSE & $\hat{\tau}_{11}$ & MRBIAS & MRMSE & $\hat{\tau}_{11}$ & MRBIAS & MRMSE & $\hat{\tau}_{11}$ & MRBIAS & MRMSE \\ 
  \hline
\multirow{6}{*}{P1} & \multirow{2}{*}{V1} & 144.598 & \framebox{0.446} & \framebox{2.246} & 122.079 & \framebox{0.221} & \framebox{2.213} & 121.365 & \framebox{\textbf{0.214}} & \framebox{\textbf{2.105}} & 135.316 & \framebox{0.353} & \framebox{2.659} \\ 
   &  & 164.384 & \framebox{0.644} & \framebox{3.899} & 141.686 & \framebox{0.417} & \framebox{4.445} & 139.994 & \framebox{\textbf{0.4}} & \framebox{3.518} & 141.776 & \framebox{0.418} & \framebox{\textbf{3.46}} \\ 
   & \multirow{2}{*}{V2} & 781.820 & -0.023 & \textbf{0.272} & 778.788 & -0.027 & 0.397 & 775.563 & -0.031 & \textbf{0.28} & 797.741 & \textbf{-0.003} & \textbf{0.289} \\ 
   &  & 772.163 & -0.035 & \framebox{\textbf{0.907}} & 748.038 & -0.065 & \framebox{1.563} & 766.189 & -0.042 & \framebox{0.936} & 790.999 & \textbf{-0.011} & \framebox{\textbf{0.883}} \\ 
   & \multirow{2}{*}{V3} & 1986.543 & \textbf{-0.007} & \textbf{0.176} & 1958.306 & -0.021 & 0.342 & 1981.925 & \textbf{-0.009} & \textbf{0.18} & 1993.994 & \textbf{-0.003} & \textbf{0.166} \\ 
   &  & 1965.874 & \textbf{-0.017} & \framebox{\textbf{0.671}} & 1943.067 & -0.028 & \framebox{1.401} & 1974.015 & \textbf{-0.013} & \framebox{0.775} & 2068.485 & 0.034 & \framebox{\textbf{0.694}} \\ 
   \hline \hline\multirow{6}{*}{P2} & \multirow{2}{*}{V1} & 153.495 & \framebox{0.535} & \framebox{2.263} & 129.369 & \framebox{\textbf{0.294}} & \framebox{\textbf{2.088}} & 130.613 & \framebox{0.306} & \framebox{2.179} & 139.044 & \framebox{0.39} & \framebox{2.48} \\ 
   &  & 171.845 & \framebox{0.718} & \framebox{5.321} & 158.770 & \framebox{0.588} & \framebox{6.512} & 152.291 & \framebox{\textbf{0.523}} & \framebox{\textbf{4.908}} & 157.169 & \framebox{0.572} & \framebox{5.738} \\ 
   & \multirow{2}{*}{V2} & 823.218 & 0.029 & \textbf{0.292} & 837.521 & 0.047 & \framebox{0.502} & 818.573 & \textbf{0.023} & \textbf{0.302} & 823.890 & 0.03 & \textbf{0.298} \\ 
   &  & 828.260 & 0.035 & \framebox{\textbf{1.006}} & 842.944 & \framebox{0.054} & \framebox{3.35} & 819.397 & \textbf{0.024} & \framebox{1.067} & 826.711 & 0.033 & \framebox{1.037} \\ 
   & \multirow{2}{*}{V3} & 2018.278 & \textbf{0.009} & \textbf{0.194} & 2008.950 & \textbf{0.004} & 0.361 & 2024.893 & 0.012 & \textbf{0.2} & 2024.943 & 0.012 & \textbf{0.195} \\ 
   &  & 2162.150 & \framebox{0.081} & \framebox{\textbf{0.993}} & 1981.057 & \textbf{-0.009} & \framebox{1.811} & 2132.741 & \framebox{0.066} & \framebox{1.04} & 2163.350 & \framebox{0.082} & \framebox{\textbf{1.001}} \\ 
   \hline \hline\multirow{6}{*}{P3} & \multirow{2}{*}{V1} & 124.432 & \framebox{0.244} & \framebox{\textbf{1.044}} & 109.864 & \framebox{0.099} & \framebox{1.215} & 109.752 & \framebox{0.098} & \framebox{1.153} & 108.736 & \framebox{\textbf{0.087}} & \framebox{1.138} \\ 
   &  & 118.025 & \framebox{0.18} & \framebox{\textbf{1.156}} & 109.386 & \framebox{0.094} & \framebox{1.402} & 107.157 & \framebox{\textbf{0.072}} & \framebox{1.287} & 128.156 & \framebox{0.282} & \framebox{2.262} \\ 
   & \multirow{2}{*}{V2} & 821.782 & 0.027 & \textbf{0.154} & 815.132 & \textbf{0.019} & 0.275 & 821.140 & 0.026 & \textbf{0.161} & 787.735 & \textbf{-0.015} & \textbf{0.146} \\ 
   &  & 803.341 & \textbf{0.004} & \framebox{0.517} & 838.186 & 0.048 & \framebox{1.108} & 799.367 & \textbf{-0.001} & \framebox{0.547} & 798.569 & \textbf{-0.002} & \textbf{0.468} \\ 
   & \multirow{2}{*}{V3} & 2000.239 & \textbf{0.000} & \textbf{0.101} & 2013.815 & 0.007 & 0.218 & 1998.839 & \textbf{-0.001} & \textbf{0.106} & 1964.929 & -0.018 & \textbf{0.086} \\ 
   &  & 1921.306 & \textbf{-0.039} & \textbf{0.386} & 1902.369 & -0.049 & \framebox{0.768} & 1917.738 & \textbf{-0.041} & \textbf{0.383} & 2118.324 & \framebox{0.059} & \framebox{0.517} \\ 
   \hline \hline\multirow{6}{*}{P4} & \multirow{2}{*}{V1} & 124.196 & \framebox{0.242} & \framebox{\textbf{1.128}} & 107.755 & \framebox{\textbf{0.078}} & \framebox{1.284} & 110.623 & \framebox{0.106} & \framebox{1.231} & 112.254 & \framebox{0.123} & \framebox{1.293} \\ 
   &  & 137.637 & \framebox{0.376} & \framebox{\textbf{1.817}} & 121.739 & \framebox{\textbf{0.217}} & \framebox{2.082} & 123.961 & \framebox{0.24} & \framebox{1.938} & 126.811 & \framebox{0.268} & \framebox{1.994} \\ 
   & \multirow{2}{*}{V2} & 810.196 & \textbf{0.013} & \textbf{0.137} & 783.467 & -0.021 & 0.236 & 809.532 & \textbf{0.012} & \textbf{0.141} & 812.332 & \textbf{0.015} & \textbf{0.138} \\ 
   &  & 802.337 & \textbf{0.003} & \textbf{0.471} & 803.570 & \textbf{0.004} & \framebox{1.143} & 805.577 & \textbf{0.007} & \textbf{0.499} & 806.525 & \textbf{0.008} & \textbf{0.475} \\ 
   & \multirow{2}{*}{V3} & 1992.481 & \textbf{-0.004} & \textbf{0.085} & 1981.730 & \textbf{-0.009} & 0.189 & 1992.432 & \textbf{-0.004} & \textbf{0.088} & 1994.906 & \textbf{-0.003} & \textbf{0.085} \\ 
   &  & 1996.526 & \textbf{-0.002} & \textbf{0.373} & 2048.387 & 0.024 & \framebox{0.888} & 2010.575 & \textbf{0.005} & \textbf{0.398} & 2008.312 & \textbf{0.004} & \textbf{0.379} \\ 
   \hline \hline\multirow{6}{*}{P5} & \multirow{2}{*}{V1} & 112.945 & \framebox{0.129} & \framebox{\textbf{0.592}} & 107.799 & \framebox{0.078} & \framebox{0.739} & 107.252 & \framebox{0.073} & \framebox{0.667} & 103.005 & \textbf{0.03} & \framebox{\textbf{0.564}} \\ 
   &  & 109.710 & \framebox{0.097} & \framebox{\textbf{0.761}} & 103.930 & 0.039 & \framebox{1.047} & 102.722 & \textbf{0.027} & \framebox{0.839} & 112.052 & \framebox{0.121} & \framebox{0.968} \\ 
   & \multirow{2}{*}{V2} & 810.594 & \textbf{0.013} & \textbf{0.058} & 815.361 & 0.019 & 0.108 & 810.587 & \textbf{0.013} & \textbf{0.06} & 792.511 & \textbf{-0.009} & \textbf{0.061} \\ 
   &  & 826.023 & 0.033 & 0.278 & 839.646 & \framebox{0.05} & \framebox{0.715} & 826.001 & 0.033 & 0.285 & 819.700 & \textbf{0.025} & \textbf{0.237} \\ 
   & \multirow{2}{*}{V3} & 1991.213 & \textbf{-0.004} & \textbf{0.038} & 1964.346 & -0.018 & 0.085 & 1992.041 & \textbf{-0.004} & \textbf{0.04} & 1984.226 & \textbf{-0.008} & \textbf{0.038} \\ 
   &  & 1979.241 & \textbf{-0.01} & \textbf{0.176} & 1978.970 & \textbf{-0.011} & 0.411 & 1973.469 & \textbf{-0.013} & \textbf{0.196} & 1975.107 & \textbf{-0.012} & \textbf{0.193} \\ 
   \hline \hline\multirow{6}{*}{P6} & \multirow{2}{*}{V1} & 114.788 & \framebox{0.148} & \framebox{\textbf{0.565}} & 107.382 & \framebox{\textbf{0.074}} & \framebox{0.714} & 108.274 & \framebox{0.083} & \framebox{0.619} & 109.935 & \framebox{0.099} & \framebox{0.623} \\ 
   &  & 115.418 & \framebox{0.154} & \framebox{\textbf{0.78}} & 110.247 & \framebox{0.102} & \framebox{1.156} & 107.439 & \framebox{\textbf{0.074}} & \framebox{0.864} & 109.419 & \framebox{0.094} & \framebox{0.903} \\ 
   & \multirow{2}{*}{V2} & 800.029 & \textbf{0.000} & \textbf{0.06} & 803.531 & \textbf{0.004} & 0.113 & 800.573 & \textbf{0.001} & \textbf{0.062} & 801.637 & \textbf{0.002} & \textbf{0.06} \\ 
   &  & 770.297 & \textbf{-0.037} & \textbf{0.191} & 765.837 & -0.043 & 0.391 & 772.872 & \textbf{-0.034} & \textbf{0.191} & 773.491 & \textbf{-0.033} & \textbf{0.192} \\ 
   & \multirow{2}{*}{V3} & 1985.114 & \textbf{-0.007} & \textbf{0.037} & 1972.723 & -0.014 & 0.091 & 1980.349 & \textbf{-0.01} & \textbf{0.038} & 1985.331 & \textbf{-0.007} & \textbf{0.037} \\ 
   &  & 1963.645 & \textbf{-0.018} & \textbf{0.189} & 1937.728 & -0.031 & 0.415 & 1964.085 & \textbf{-0.018} & \textbf{0.189} & 1966.953 & \textbf{-0.017} & \textbf{0.189} \\ 
   \hline
\end{tabular}
}
\caption{Lentelėje pateiktos modelio (\ref{eq:simul}) $\tau_{11}=100,\ 800,\ 2000$ vidutinis įvertis ir statistikos, kurių išraiškos pateiktos skyrelyje \ref{subsubsec:besvoriu}. Patamsintos statistikos tos, kurios nuo minimalios eilutės reikšmės skiriasi mažiau nei 0,005 arba 0,03 (MRBIAS ir MRSE atitinkamai). Stačiakampių apvestos statistikos, kurios viršyja 0,05 ir 0,5 (MRBIAS ir MRSE atitinkamai). Pirmoje eilutėje paklaidos normaliosios, antroje $\chi^2$}
\end{sidewaystable}

\begin{sidewaysfigure}
\centering
\includegraphics[height=18cm]{Ngammaseqdg.pdf}
\caption{Lentelėje pateikti modelio (\ref{eq:simul}) su normaliosiomis paklaidomis fiksuotų efektų įverčių empiriniai kvantilių grafikai.}
\label{fig:Nf}
\end{sidewaysfigure}

\begin{sidewaysfigure}
\centering
\includegraphics[height=18cm]{Nraneqdg.pdf}
\caption{Lentelėje pateikti modelio (\ref{eq:simul}) su normaliosiomis paklaidomis atsitiktinių efektų įverčių empiriniai kvantilių grafikai.}
\label{fig:Nr}
\end{sidewaysfigure}

\begin{sidewaysfigure}
\centering
\includegraphics[height=18cm]{Xfixeqdg.pdf}
\caption{Lentelėje pateikti modelio (\ref{eq:simul}) su $\chi^2$ paklaidomis fiksuotų efektų įverčių empiriniai kvantilių grafikai.}
\label{fig:Xf}
\end{sidewaysfigure}

\begin{sidewaysfigure}
\centering
\includegraphics[height=18cm]{Xraneqdg.pdf}
\caption{Lentelėje pateikti modelio (\ref{eq:simul}) su $\chi^2$ paklaidomis atsitiktinių efektų įverčių empiriniai kvantilių grafikai.}
\label{fig:Xr}
\end{sidewaysfigure}

\end{document}